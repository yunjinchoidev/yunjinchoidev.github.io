var store = [{
        "title": "[a01_study tech 5기] [회고] 온보딩을 보내며...",
        "excerpt":"[온보딩기간을 보내며] 3월 1일 부터 3월 5일까지 온보딩 기간을 보내며 설레는 마음으로 공부를 했다. 파이썬, ai math, pytorch 강의를 들었다. 수학과를 다니면서 선형대수학을 과연 사용할 일이 있을까 생각을 했었는데 딥러닝에서 매우 중요하다고 한다. 통계학도 중요하다. 선형대수, 수리통계 책을 구입했고 심기일전해서 다시 공부해보려고 한다. ai tech 5기는 3월 6일 부터 8월...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-%EC%98%A8%EB%B3%B4%EB%94%A9/",
        "teaser": null
      },{
        "title": "a01_study tech - Day01",
        "excerpt":"   오늘 무엇을 했나?     OT 참여   python 강의 수강   파이토치 강의 1~5강 수강  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day01/",
        "teaser": null
      },{
        "title": "[이코테] 1장, 2장",
        "excerpt":"이코테 1 장 시간 복잡도 알고리즘을 위해 필요한 연산의 횟수 시간 복잡도는 알고리즘이 문제를 해결하는 데 걸리는 시간을 측정한 것입니다. 일반적으로 입력 크기의 함수로 표현되며 알고리즘이 문제를 해결하는 데 필요한 기본 작업(또는 단계)의 수를 나타냅니다. 알고리즘의 시간 복잡도는 특정 문제를 해결하기 위해 서로 다른 알고리즘 중에서 선택할 때 고려해야 할...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C1,2%EC%9E%A5/",
        "teaser": null
      },{
        "title": "[이코테] 3장(그리디 알고리즘)",
        "excerpt":"그리디 알고리즘 자, 그리디 알고리즘을 공부합시다. 그리디 알고리즘은 지금 당장 최적인 답을 선택하는 과정을 반복하여 결과를 도출하는 알고리즘을 말합니다. 일반적으로 그리디 알고리즘은 최적의 해를 보장할 수 없는 경우가 많다. 역으로, 그리디 알고리즘을 사용해야 해야 하는 경우는 탐욕적으로 찾은 해가 최적의 해라는 뜻이다. 코딩테스트 환경에서 그리디 알고리즘으로 풀 수 있는 경우는...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C3%EC%9E%A5-%EA%B7%B8%EB%A6%AC%EB%94%94%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/",
        "teaser": null
      },{
        "title": "a01_study tech - Day02 ",
        "excerpt":"   오늘 무엇을 했나?  - numpy, pandas  를 집중 분석했다. - 공부하는 것과 실제 적용하는 것에는 큰 차이가 있는 거 같다. - 경사하강법, 오차 역전파에서 스칼라가 텐서로 바뀔 때의 상황이 직관적으로 와닿지가 않아서 공부했다. - 최대 우도법을 공부.  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day02/",
        "teaser": null
      },{
        "title": "딥러닝에 필요한 수학적 지식",
        "excerpt":"벡터 벡터란 뭡니까? 스칼라 다음의 차원을 표시하기 위한 수학 도구입니다. $ L_1$ 노름은 변화량읠 절대값을, $L_2$ 노름은 유클리드 거리를 말합니다 행렬 행렬에 대해서 알아봅시다. 행렬곱은 행과 열의 조건을 맞춰야 연산가능합니다. 행렬의 곱은 교환법칙이 성립하지 않으니 유의해야 합니다. 파이썬에서는 @ 기호를 통해 행렬의 곱을 지원합니다. np.inner 도 가능합니다.(자동 transpose 지원) 역행렬은...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-aimath/",
        "teaser": null
      },{
        "title": "Python 정리",
        "excerpt":"판다스 실전 데이터는 깨끗한 데이터가 없습니다. 우리는 판다스가 가진 힘을 적극적으로 활용하여 데이터를 가공 해야 합니다. 좋은 데이터는 좋은 학습 결과를 만듭니다. 이것이 우리가 추구하는 바입니다. 판다스는 굉장히 많은 함수를 지원하고 있습니다. 이것을 모두 기억해야 하냐고요? 그렇지는 않습니다. 레퍼런스를 참고하면 되기 때문이죠. 다만 이것을 자유롭게 활용 할 수 있는 능력을...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-python/",
        "teaser": null
      },{
        "title": "Pytorch ",
        "excerpt":"✅ Introduction to PyTorch 파이토치를 공부합시다. 네트워크 구현 및 데이터 로딩, 프로젝트 구조, 로깅, Multi GPU, 이어 학습 을 다룹니다. 밑바닥부터 딥러닝 코드 짜기를 짤 수도 있습니다. 책 읽어보세요. 하지만 저희는 딥러닝 프레임워크를 사용합니다. 예를 들어서 텐서플로와 파이토치가 있습니다. 텐서플로는 구글에서 만들었고, 파이토치는 페이스북에서 만들었습니다. 저희는 파이토치를 사용할 것입니다. 파이토치는...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-pytorch/",
        "teaser": null
      },{
        "title": "a01_study tech -Day03 ",
        "excerpt":"오늘 무엇을 했나? python 복습했다. aimath 1 ~ 5 강을 들었다. pytorch template 분석 했다. 포스팅 정리를 했다. github 블로그를 만들었다. 내일 무엇을 할 것인가? ai math, pytorch 강의 마무리 하면서 포스팅 정리 하기 과제 검토 RNN 의 오차 역전파 연구하기 [오늘의 생각] 오늘 NLP 팀 발표 시간을 가졌다. 논문...","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day03/",
        "teaser": null
      },{
        "title": "a01_study tech - pytorch Template 완전 분석 ",
        "excerpt":"Pytorch 템플릿을 문석해봅시다. 링크 여기 오픈 소스가 하나 있습니다. 이 포스팅을 통해 이 템플릿을 분해, 분석 해보는 시간을 가지려고 합니다. * train.py -&gt; 실행 * test.py -&gt; 실행 * config -&gt; 설정 * parse_config -&gt; 설정 * base -&gt; base 모델 * data_loader ~ -&gt; data * model ~ -&gt;...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-pytorchtemplate/",
        "teaser": null
      },{
        "title": "ai_01_cv",
        "excerpt":"     ai_cv  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-cv/",
        "teaser": null
      },{
        "title": "NLP 개론",
        "excerpt":"     ai_nlp  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-nlp/",
        "teaser": null
      },{
        "title": "선형대수학",
        "excerpt":"선형대수학 선형대수(linear algebra)는 데이터 분석에 필요한 각종 계산을 돕는 학문 [링크] 선형성 선형성이란 입력값에 a 라는 영향을 주면 결과치도 a 라는 결과 값을 받는 것을 말한다. 선형성의 결과에 따라 예측 가능한 시스템을 만들 수 있다. 선형 결합 ax + by = z 를 만족하는 a, b 의 값을 찾는 것이...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99/",
        "teaser": null
      },{
        "title": "a01_study tech -Day04 ",
        "excerpt":"   오늘 무엇을 했나?     과제를 풀면서 한 주간 배운 내용을 정리했다.   파이토치 내용을 보충했다.   딥러닝 기초 다지기 강의를 들었다.   ai math 내용을 보충했다.   내일 무엇을 할 것인가?     RNN 강의 복습   pytorch 강의 복습   딥러닝 기초 다지기 강의 수강  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day04/",
        "teaser": null
      },{
        "title": "Dive into NLP",
        "excerpt":"Dive Into NLP 자연어 처리를 공부합시다. 자연어 처리(自然語處理) 또는 자연 언어 처리(自然言語處理)는 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 모사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나 (출처: 위키피디아) 자연어처리의 주요 분야 자연어처리의 주요 분야를 알아봅시다. 1. NLP (ACL, EMNLP, NAACL) 자연어 처리의 대표적인 학회는 ACL, EMNLP,...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-Dive-Into-NLP/",
        "teaser": null
      },{
        "title": "딥러닝 모니터링(Monintoring) 하기",
        "excerpt":"Monitoring 학습을 하는 데 굉장히 긴 시간이 걸립니다. 학습 과정을 기록하는게 좋겠죠. TensorBoard와 Weight &amp; Bias를 이용해봅시다. Tensorboard scalar : metric 표시 graph : 계산 그래프 histogram : weight 분포 image: 예측 값과 실게 값을 비교 표시 mesh : 3d 형태의 데이터를 표현하는 도구 import os logs_base_dir = 'logs' os.makedirs(logs_base_dir,...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-monitoring/",
        "teaser": null
      },{
        "title": "딥러닝의 모든 것(All about Deep Learning)",
        "excerpt":"누가 좋은 딥러너인가 ? 누가 좋은 딥러너 일까요? 수학적 지식이 뛰어나야 합니다. 논문을 잘 읽어야 하고요. 구현 능력이 뛰어나야 합니다. 여러분들은 그 실력을 키우시기 바랍니다. 논문을 읽거나 모델을 연구할 때 1. 데이터 2. 모델 3. 손실함수 4. 학습 알고리즘 를 고려합시다. 공부합시다. 1. Historical Review 2. Neural Networks &amp; Multi-Layer...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EB%AA%A8%EB%93%A0%EA%B2%83-copy/",
        "teaser": null
      },{
        "title": "선형대수학",
        "excerpt":"   선형대수학     선형 대   ","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99/",
        "teaser": null
      },{
        "title": "딥러닝 바닥부터 만들기 (intro ~ step10)",
        "excerpt":"   바닥부터 딥러닝을 만들어보자.   우리는 바닥부터 딥러닝 모델을 한번 만들어 볼것입니다.  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D(1)/",
        "teaser": null
      },{
        "title": "nlp 면접 준비",
        "excerpt":"nlp 면접 인터뷰 준비  면접 준비를 한번 잘 해봅시다. 답을 나만의 언어로 천천히 기록해보도록 합시다.          참고했던 자료     링크1   ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EC%9D%B8%ED%84%B0%EB%B7%B0/",
        "teaser": null
      },{
        "title": "챗봇 만들기",
        "excerpt":"   챗봇을 만듭시다.  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EC%B1%97%EB%B4%87/",
        "teaser": null
      },{
        "title": "a01_study tech -Day05 ",
        "excerpt":"  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day05/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 1주차를 보내며...",
        "excerpt":"[1주차 계획] python, aimath, pytorch 완강 과제 완수 [1주차 정리] 강의 정리 파이썬 강의록 정리 AIMath 강의록 정리 [1주차를 보내며] 설레는 마음으로 첫 주차 부트캠프에 참여했습니다. 상당히 전문성 있는 교육 프로그램이 인상 깊었습니다. 첫 날에 타운홀 미팅이 있었고 팀원들과 자기소개 하는 시간을 가졌습니다. 하루에 최대 2시간의 시간을 제외하면 모두 제가...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-1%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "a01_study tech - Day06 ",
        "excerpt":"5F 그날의 사실 (Facts) : 파이토치 수업을 시작했습니다. 본격적인 딥러닝 구현을 들어가서 설렜습니다. 월요일 9시가 되고 과제를 열어보니 난이도가 꽤 있어서 걱정이 조금 되었습니다. 수요일 까지 최대한 빨리 끝내놓고 한 주의 마무리를 잘 해야 겠다는 다짐을 했습니다. 팀원들과 코딩테스트 스터디를 시작했습니다. [이것이 취업을 위한 코딩테스트다.] 라는 책으로 시작하게 되었는데요. 그리디...","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day06/",
        "teaser": null
      },{
        "title": "a01_study tech -Day07 ",
        "excerpt":"5F 그날의 사실 (Facts) : 파이토치 autograd, dataset, dataLoader 에 대해 공부했습니다. 구글링을 하지 않고 과제를 풀었습니다. 파이토치 공식 문서를 하루 종일 보면서 몇 문제를 남겨놓고 어찌어찌 풀긴 풀었습니다. 기분이 좋기도 하지만 그 과정이 너무 힘들었습니다. 지문이 상당히 많은데 복습하는데 시간을 써야 겠습니다. DataLoader 부분을 현재 풀고 있는데 좌절감이 듭니다....","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day07/",
        "teaser": null
      },{
        "title": "a01_study tech -Day08 ",
        "excerpt":"   5F  그날의 사실 (Facts) :  과제1, 과제 2을 풀었습니다. 강의와 딥러닝 파이토치 교과서 라는 책을 병행하면서 과제를 풀고 있습니다. 팀원들과 그리디 알고리즘 2 문제를 풀었습니다.   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day08/",
        "teaser": null
      },{
        "title": "[이코테]이코테 4장(구현)",
        "excerpt":"구현 구현이란 머릿속에 있는 알고리즘을 소스코드로 바꾸는 과정을 말합니다. 아이디어를 떠올리는 것은 쉽지만 코드로 바꾸는 것이 쉽지 않은 것이 구현 문제로 나온다. 결국 코드를 잘 만질 수 있는 능력이 있어야 한다는 소리다. 시뮬레이션, 구현, 완전 탐색은 유사한 부분이 많다. 일반적으로 전체 데이터 개수가 100만 개 이하일 때 완전 탐색을 사용하면...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C4%EC%9E%A5-%EA%B5%AC%ED%98%84/",
        "teaser": null
      },{
        "title": "a01_study tech -Day09 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day09/",
        "teaser": null
      },{
        "title": "a01_study tech -Day10 ",
        "excerpt":"  ","categories": ["a02_aitech_daily"],
        "tags": [],
        "url": "/a02_aitech_daily/post-day10/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 2주차를 보내며...",
        "excerpt":"[2주차 계획] 텐서보드 튜토리얼 코드 돌리기 WanB 튜토리얼 코드 돌려보기 하이퍼 파라미터 튜닝 해보기 코테 스터디 잘 참여하기 [2주차를 보내며] 강의 정리 파이토치 강의록 정리 벌써 2주의 시간이 흘렀습니다. 첫 주차에 파이썬, 딥러닝 수학을 배웠고 이번주엔 딥러닝을 실제 구현 할 수 있는 파이토치 를 배웠습니다. 파이토치의 기본적인 사용법, dataset, dataLoader...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[백준][14916] 거스름돈",
        "excerpt":"해결 전략 그리디 알고리즘으로 풉니다. 앞 사람과의 키차이를 gabs 라는 리스트에 저장해줍니다. 문제에서 요구하는 것은 최소 비용으로 M 개의 그룹을 만드는 것을 요구합니다. gab 리스트에서 특정 하나를 제거한다는 것은 그 구간을 통합한다는 개념이고 그룹 수를 하나 줄인다는 것입니다. (N-1 개의 갭이 있는 gabs는 M개의 그룹이 최초로 세팅되어 있다고 이해하면 됩니다.)...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EB%B0%B1%EC%A4%80-14816-%EA%B1%B0%EC%8A%A4%EB%A6%84%EB%8F%88/",
        "teaser": null
      },{
        "title": "전이학습",
        "excerpt":"전이학습 위키백과에 의하면 전이학습은 한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식을 말합니다. 전이 학습은 하나의 작업에 대해 훈련된 모델을 사용하여 다른 관련 작업의 성능을 향상시킬 수 있는 기계 학습 기술입니다. 전이 학습에서는 처음부터 시작하는 대신 사전 훈련된 모델을 새로운 작업의 시작점으로 사용합니다. 사전 훈련된...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/",
        "teaser": null
      },{
        "title": "[논문리뷰] A Survey of the Usages of Deep Learning for Natural Language Processing(2017)",
        "excerpt":"A Survey of the Usages of Deep Learning for Natural Language Processing 💡 2018년 1. Introduction 2. Fundamentals of Deep Learning and NLP 2.1 Deep Learning 2.2 Natural Language Processing 3. Deep Learning Architectures for NLP 3.1 Convolutional Neural Networks 3.2 Recurrent Neural Networks 3.3 Transformers 4. Use Cases of...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-surveyNLP/",
        "teaser": null
      },{
        "title": "[논문리뷰] Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)",
        "excerpt":"Deep Learning’s Most Important Ideas - A Brief Historical Review(2020) 2012 – AlexNet AlexNet은 2012년 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 개발한 심층 컨볼루션 신경망(CNN) 아키텍처다. 오류율은 15.3%로 두 번째로 좋은 모델보다 훨씬 뛰어나다. AlexNet은 8개의 계층으로 구성되어 있다. 5개의 컨볼루션 계층과 3개의 완전 연결 계층이 있습니다. 이 네트워크는...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-A-Brief-Historical-Review/",
        "teaser": null
      },{
        "title": "Segmentation & Detection",
        "excerpt":"Segmentation Segmentation는 미리 정의된 기준이나 특징에 따라 이미지나 비디오를 여러 영역 또는 세그먼트로 나누는 컴퓨터 비전 작업입니다. 분할의 목표는 이미지나 동영상에서 의미 있고 유용한 정보를 추출하여 사물인식, 장면이해, 자율주행 등 다양한 응용에 활용될 수 있도록 하는 것입니다. 세그멘테이션에는 시맨틱 세그먼테이션과 인스턴스 세그먼테이션의 두 가지 주요 유형이 있습니다. 시맨틱 분할에는 이미지...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-Segmentation-&-Detection/",
        "teaser": null
      },{
        "title": "컴퓨터 비전의 중요한 7가지 모델",
        "excerpt":"ai 컴퓨터 비전의 중요한 7가지 모델 컴퓨터 비전 분야에는 몇 가지 영향력 있는 모델과 아키텍처가 있으며, 그 중 다수는 이 분야를 발전시키는 데 중요한 역할을 했습니다. 다음은 7가지 중요한 모델입니다. LeNet-5: 1990년대에 Yann LeCun이 개발한 LeNet-5는 필기 숫자 인식을 위해 설계된 선구적인 컨볼루션 신경망(CNN)입니다. 이는 많은 미래 CNN 아키텍처의 토대를...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/",
        "teaser": null
      },{
        "title": "Pytorch DataLoader DataSet",
        "excerpt":"Pytorch DataLoader DataSet 옵션 데이터 집합: 로드할 데이터 집합 개체를 지정하는 필수 인수입니다. 데이터 집합 개체는 torch.utils.data에서 파생된 클래스의 인스턴스여야 합니다.getitem 및 len 메서드가 구현된 데이터 세트. 배치_크기: 이 옵션 인수는 각 배치에서 로드하고 처리할 샘플 수를 정의합니다. 기본적으로 1(즉, 배치 없음)로 설정됩니다. 배치 크기가 클수록 교육 효율성이 향상될 수...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-Pytorch-DataLoader-DataSet/",
        "teaser": null
      },{
        "title": "RNN, LSTM, GRU",
        "excerpt":"RNN RNN(Recurrent Neural Network)은 시계열, 자연어 및 음성 신호와 같은 순차적 데이터로 작업하도록 설계된 인공 신경망 클래스입니다. 기존의 피드포워드 신경망과 달리 RNN에는 자체 루프백 연결이 있어 일종의 메모리 역할을 할 수 있는 숨겨진 상태를 유지할 수 있습니다. 따라서 RNN은 입력 시퀀스를 처리하고 입력 데이터의 컨텍스트 또는 기록을 기반으로 결과를 예측하는...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-RNN,-LSTM,-GRU/",
        "teaser": null
      },{
        "title": "[논문리뷰] Attention is all you need",
        "excerpt":"Attention is All you need 구글의 Attention is All you 논문을 통해 nlp 의 혁명이 일어났습니다. 기존의 rnn 모델은 attention 모델로 대체되었습니다. 왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠. “Attention is All You Need”는 자연어 처리 및 기계 번역과 같은 sequence-to-sequence 작업을 위한 새로운 딥 러닝 아키텍처인 Transformer...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-attention-is-all-you-need/",
        "teaser": null
      },{
        "title": "[프로그래머스] 기둥과보",
        "excerpt":"해결 전략 is_normal 함수를 이용해서 정상성 여부를 검사한다. 수의 범위가 적으니 완전탐색으로 풀어도 되는 문제였다. 수가 적으면 완전탐색을 의심해봅시다. def solution(n, build_frame): answer = [[]] update_map = set() def is_normal(update_map): for material in update_map: # 보 라면 if material[2] == 1: # 한쪽에라도 기둥이 있으면 된다. if (material[0], material[1]-1, 0)...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4/",
        "teaser": null
      },{
        "title": "[연재][Clear Algo][1편] - 그리디 알고리즘 ",
        "excerpt":"[연재][Clear Algo][1편] - 그리디 알고리즘   ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_-%EC%97%B0%EC%9E%AC-clearAlgo-1%ED%8E%B8/",
        "teaser": null
      },{
        "title": "[백준][18428][감시피하기]",
        "excerpt":"해결 전략 선생님들이 학생을 발견할 수 없는 장애물을 설치할 수 있는지 없는지 여부를 확인하는 문제입니다. 선생님들의 감시 경로를 DFS 로 구현합니다. N 의 주어진 범위가 적으니 조합을 모두 구하고 각각에 대하여 DFS 를 수행하면 됩니다. 생각정리 시간복잡도 -&gt; 완전탐색으로 풀어도 되겠다. 3개의 장애물을 만든다. -&gt; combination 을 쓰자. 36*35*34 /...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EB%B0%B1%EC%A4%80-18428-%EA%B0%90%EC%8B%9C%ED%94%BC%ED%95%98%EA%B8%B0/",
        "teaser": null
      },{
        "title": "[백준][3190][뱀]",
        "excerpt":"해결 전략 전형적인 시뮬레이션 문제입니다. 문제를 잘 읽고 step 을 구현합시다. 동서남북 이동과 방향이동에 주의합시다. 사과조건과 뱀의 trace 를 잘 표시해야 합니다. import sys input = sys.stdin.readline N = int(input()) apple_cnt = int(input()) # 사과 표시하기 apple_map = [[False for i in range(N)] for j in range(N)] for i in...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/",
        "teaser": null
      },{
        "title": "[이코테]이코테 5장(DFS & BFS)",
        "excerpt":"DFS &amp; BFS   ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5-BFS-&-DFS/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 3주차를 보내며...",
        "excerpt":"[3주차를 보내며] 강의 정리 딥러닝 Basic 강의록 정리 5F 사실 (Facts) : 이번주에는 딥러닝 기초 강좌와 data visualization 강의를 들었습니다. CNN, RNN, LSTM, Transfomer, GAN, matplotlib 을 배웠습니다. 이 모델들을 가지고 간단한 모델을 구현해보았습니다. matplotlib을 통해서 데이터를 visualization 을 해봤습니다. 좋습니다. 점점 많은 것을 배우고 있다는 것을 실감하고 있습니다. 양이...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-3%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "추천 시스템이란?",
        "excerpt":"ai_recsys 추천 시스템은 인공지능 기술을 활용하여 사용자에게 맞춤형 추천을 제공하는 시스템입니다. 예를 들어, 온라인 쇼핑몰에서 고객의 이전 구매 이력, 검색어, 클릭 이력 등을 분석하여 해당 고객에게 맞는 상품을 추천하거나, 영화나 음악 스트리밍 서비스에서 사용자의 시청 기록, 검색 기록, 평점 등을 분석하여 해당 사용자에게 맞는 콘텐츠를 추천하는 기술입니다. 추천 시스템은 사용자...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-recsys/",
        "teaser": null
      },{
        "title": "자기만의 역사를 쓴다는 것",
        "excerpt":"현재는 고인이 된 지의 거장, 다치바나 다카시의 책이다. 그는 &lt;나는 이런 책을 읽어왔다&gt;, ` 등으로 한국에도 유명한 작가이다. 다치바나 다카시를 들어본 적있는 독자라면 매일 같이 읽고 쓰는 그의 괴물같은 독서력과 필력에 대해 잘 알것이다. 7만 권이 넘는 장서를 보관하고 있는 고양이 빌딩은 유명하다. &lt;자기 역사를 쓴다는 것&gt;은 2013년 출판된 책으로서...","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-%EC%9E%90%EA%B8%B0%EB%A7%8C%EC%9D%98-%EC%97%AD%EC%82%AC%EB%A5%BC-%EC%93%B4%EB%8B%A4%EB%8A%94-%EA%B2%83/",
        "teaser": null
      },{
        "title": "컴퓨터 비전의 모든 것",
        "excerpt":"컴퓨터 비전의 역사 딥러닝은 빠르게 변하는 분야이기 때문에 손 놓고 남들이 해놓은 자료만 보려고 하다가는 뒤쳐지게 됩니다. 우리는 영어에 익숙해져야 합니다. 거꾸로 돌려져있는 인간의 초상화 를 본 적 있습니까. 우리는 거꾸로 뒤집힌 인간의 얼굴을 올바르게 보는 능력을 가지고 있지 않습니다. 결국 인간도 편향적으로 학습이 된 것이죠. 컴퓨터 비전은 많은 곳에서...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-cv/",
        "teaser": null
      },{
        "title": "KLUE",
        "excerpt":"목차 한국어 언어모델 학습 및 다중 과제 튜닝 과정 인공지능과 자연어 처리 (이론/실습) 자연어의 전처리 (이론/실습) BERT 언어모델(1) (이론/실습) BERT 언어모델(2) (이론/실습) BERT 언어모델 기반의 단일 문장 분류 (이론/실습) BERT 언어모델 기반의 두 문장 관계 분류 (이론/실습) BERT 언어모델 기반의 문장 토큰 분류 (이론/실습) GPT 언어모델 (이론/실습) GPT 언어모델 기반의...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-klue/",
        "teaser": null
      },{
        "title": "MRC(Machine reading comprehension)",
        "excerpt":"MRC(Machine reading comprehension)란? 주어진 지문(context)를 이해하고 주어진 질의(Query/Question)의 답변을 추론하는 문제 Q&amp;A 분야에 응용될 수 있습니다. Extractive Answer Datasets 질의에 대한 답이 항상 주어진 지문의 segment (or span) 으로 존재 Descriptive/Narrative Answer Datasets 지문 내에서 추출한 span이 아닌, 질의를 보고 생성된 sentence (or free-form) 형태의 output을 내야하는 task Multiple-choice Datasets...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-mrc/",
        "teaser": null
      },{
        "title": "자연어 처리의 모든 것",
        "excerpt":"   자연어 처리의 모든 것  시작합니다.  ","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-nlp/",
        "teaser": null
      },{
        "title": "recsys",
        "excerpt":"   ","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-recsys/",
        "teaser": null
      },{
        "title": "[논문리뷰] Word2Vec",
        "excerpt":"   Word2Vec  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-word2vec/",
        "teaser": null
      },{
        "title": "[이코테]이코테 6장(정렬)",
        "excerpt":"정렬  ","categories": ["a01_study"],
        "tags": [],
        "url": "/a01_study/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C6%EC%9E%A5-%EC%A0%95%EB%A0%AC/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 4주차를 보내며...",
        "excerpt":"[3주차를 보내며] 강의 정리 자연어 처리 입문 5F 사실 (Facts) : 이번주에는 주재걸 마스터님의 NLP 도메인 강의를 들었습니다. Bag of Word 부터 Word2vec, Glove, FastText, RNN, LSTM, GRU, Seq2Seq 를 처음부터 다져 나가며 NLP 이론 공부를 했습니다. 팀원들과 코딩테스트 DFS/BFS 파트를 풀었습니다. 느낌 (Feeling) : 이전에 보았던 책들이 다시 느껴지는...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-4%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "git 정리",
        "excerpt":"이고잉님 깃허브 특강 3월 28일, 4월 4일 진행 What is Git? Git is a distributed version control system used for tracking changes in source code during software development. It was created by Linus Torvalds in 2005 for the development of the Linux kernel. Git provides a way to manage changes...","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-git/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 5주차를 보내며...",
        "excerpt":"[5주차를 보내며] 5F 사실 (Facts) : 이번주에는 강의가 그렇게 많지 않았다. Transformer, GPT, BERT 를 일주일 동안 공부하는 시간을 가졌다. 이번 주에는 내가 주간 모더레이터여서 정렬 발표와 Attention Is All You Need 발표를 했다. 느낌 (Feeling) : 주재걸 마스터님의 강의는 정말 명강의인 것 같다. 행렬의 곱이 실제 어떻게 이뤄지는지 예시를...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-5%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 6주차를 보내며...",
        "excerpt":"[6주차를 보내며] 5F 사실 (Facts) : 이번 주 부터 U 스테이지 프로젝트를 진행했다. 주제는 STS 프로젝트. 처음 참여하는 프로젝트여서 그런지 기대가 많이 되었다. 이제까지 5주 정도 이론을 공부하며 BERT, GPT 까지 열심히 공부했다. 이제 열매를 맺을 시간이다. GPT-1 논문을 멘토님과 같이 리딩하는 시간을 가졌다. 피어세션 때는 동료들과 DP 를 공부했다....","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-6%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 7주차를 보내며...",
        "excerpt":"[7주차를 보내며] 5F 사실 (Facts) : STS 프로젝트가 끝이 났다. 화요일엔 동료들과 네이버 역삼 스퀘어에서 오프라인으로 대면했다. public 리더보드는 12등, private 리더보드는 6등을 했다. 앙상블 기법을 이용하였더니 성능이 좋아졌다. 알고리즘 스터디는 이진탐색을 진행했다. 느낌 (Feeling) : 2 주간의 짧으면서도 길게 느껴진 프로젝트가 끝이 났다. 프로젝트를 진행하면서 많은 것을 배웠다. 먼저,...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-7%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "a01_study 서비스 개발 기초",
        "excerpt":"[ai 서비스 개발 기초] 파이썬 버전 관리 파이썬은 2.x 버전과 3.x 버전이 존재한다. 2.x 버전은 2020년 1월 1일부터 지원이 중단되었다. 3.x 버전은 2.x 버전과 호환되지 않는다. 3.x 버전을 사용하자. 버전과 버저닝 CalVer 버전은 소프트웨어의 개발 단계를 나타낸다. 버전은 3자리로 구성된다. 첫 번째 자리는 메이저 버전이다. 두 번째 자리는 마이너 버전이다....","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-ai%EC%84%9C%EB%B9%84%EC%8A%A4%EA%B0%9C%EB%B0%9C%EA%B8%B0%EC%B4%88/",
        "teaser": null
      },{
        "title": "a01_study 서비스 개발 기초",
        "excerpt":"   [현업자 특강]   이활석 CTO  실무에서는 학습 데이터 셋 또한 모아야 한다.  ","categories": ["a04_aitech_knowledge"],
        "tags": [],
        "url": "/a04_aitech_knowledge/post-%ED%98%84%EC%97%85%EC%9E%90-%ED%8A%B9%EA%B0%95/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 8주차를 보내며...",
        "excerpt":"5F 사실 (Facts) : AI 서비스 기초를 배웠다. Docker, Linux, Streamlit 에 대해서 배웠다. RoBERTa 논문 리뷰를 했다. 느낌 (Feeling) : 확실히 프론트, 백, MLOps 까지 배우고 나니 모델링 하는 것보다 재미있는 거 같다. 이런 것을 토데로 무언가를 만드는 작업에서 굉장히 흥미로운 일이 생길거 같다. 역시 이론은 활용되어야 한다는 생각이...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-8%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 9주차를 보내며...",
        "excerpt":"5F 사실 (Facts) : KLUE 강의를 배웠다. 이제 이론적인 것은 거의 다 배웠고 각 task 별로 모델을 적용해보는 수업을 들었다. bert와 gpt 에 대한 추가적인 수업을 수강했다. 두 번째 대회가 시작되었다. 이번에 진행하는 프로젝트는 문장 내 개체간의 관계를 추출하는 작업이다. 느낌 (Feeling) : 이제 내가 해야 할 것은 최신 nlp...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-9%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 10주차를 보내며...",
        "excerpt":"5F 사실 (Facts) : Klue 프로젝트를 계속 진행했다. 나는 Should We Rely on Entity Mentions for Relation Extraction? Debiasing Relation Extraction with Counterfactual Analysis, NAACL2022 이 논문을 전담해서 읽고 구현을 시도하는 방식으로 진행했다. 느낌 (Feeling) : 논문 구현은 처음 시도해보았으나 지금까지 논문은 7 편 정도 읽었고 틈틈히 계속 봐왔어서 읽는...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-10%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "[a01_study tech 5기] [회고] 11주차를 보내며...",
        "excerpt":"5F 사실 (Facts) : KLUE 프로젝트 진행 CoRE 논문 리뷰 Sweep 을 통한 하이퍼 파라미터 튜닝 느낌 (Feeling) : 논문 리뷰를 진행하면서 RE 태스크에 대한 이해도가 높아지는 걸 스스로도 느낄 수 있었다. CoRE 구현 방법을 직접 적용하는 것은 실패했지만 엔티티 편향, 라벨 편향에 대해서 고민해 볼 수 있는 기회였다. 배운점...","categories": ["a03_aitech_weekly"],
        "tags": [],
        "url": "/a03_aitech_weekly/post-11%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      }]
