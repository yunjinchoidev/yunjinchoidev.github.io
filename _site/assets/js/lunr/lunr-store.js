var store = [{
        "title": "ai tech 온보딩",
        "excerpt":"[온보딩기간을 보내며] 3월 1일 부터 3월 5일까지 온보딩 기간을 보내며 설레는 마음으로 공부를 했다. 파이썬, ai math, pytorch 강의를 들었다. 수학과를 다니면서 선형대수학을 과연 사용할 일이 있을까 생각을 했었는데 딥러닝에서 매우 중요하다고 한다. 통계학도 중요하다. 선형대수, 수리통계 책을 구입했고 심기일전해서 다시 공부해보려고 한다. ai tech 5기는 3월 6일 부터 8월...","categories": ["aitech_weekly"],
        "tags": [],
        "url": "/aitech_weekly/post-%EC%98%A8%EB%B3%B4%EB%94%A9/",
        "teaser": null
      },{
        "title": "ai tech - Day01",
        "excerpt":"   오늘 무엇을 했나?     OT 참여   python 강의 수강   파이토치 강의 1~5강 수강  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day01/",
        "teaser": null
      },{
        "title": "ai tech 1주차",
        "excerpt":"[1주차 계획] python, aimath, pytorch 완강 과제 완수 [1주차 정리] 강의 정리 파이썬 강의록 정리 AIMath 강의록 정리 [1주차를 보내며] 설레는 마음으로 첫 주차 부트캠프에 참여했습니다. 상당히 전문성 있는 교육 프로그램이 인상 깊었습니다. 첫 날에 타운홀 미팅이 있었고 팀원들과 자기소개 하는 시간을 가졌습니다. 하루에 최대 2시간의 시간을 제외하면 모두 제가...","categories": ["aitech_weekly"],
        "tags": [],
        "url": "/aitech_weekly/post-1%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "ai tech - Day02 ",
        "excerpt":"   오늘 무엇을 했나?  - numpy, pandas  를 집중 분석했다. - 공부하는 것과 실제 적용하는 것에는 큰 차이가 있는 거 같다. - 경사하강법, 오차 역전파에서 스칼라가 텐서로 바뀔 때의 상황이 직관적으로 와닿지가 않아서 공부했다. - 최대 우도법을 공부.  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day02/",
        "teaser": null
      },{
        "title": "딥러닝에 필요한 수학적 지식",
        "excerpt":"벡터 벡터란 뭡니까? 스칼라 다음의 차원을 표시하기 위한 수학 도구입니다. $ L_1$ 노름은 변화량읠 절대값을, $L_2$ 노름은 유클리드 거리를 말합니다 행렬 행렬에 대해서 알아봅시다. 행렬곱은 행과 열의 조건을 맞춰야 연산가능합니다. 행렬의 곱은 교환법칙이 성립하지 않으니 유의해야 합니다. 파이썬에서는 @ 기호를 통해 행렬의 곱을 지원합니다. np.inner 도 가능합니다.(자동 transpose 지원) 역행렬은...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-aimath/",
        "teaser": null
      },{
        "title": "Python 정리",
        "excerpt":"판다스 실전 데이터는 깨끗한 데이터가 없습니다. 우리는 판다스가 가진 힘을 적극적으로 활용하여 데이터를 가공 해야 합니다. 좋은 데이터는 좋은 학습 결과를 만듭니다. 이것이 우리가 추구하는 바입니다. 판다스는 굉장히 많은 함수를 지원하고 있습니다. 이것을 모두 기억해야 하냐고요? 그렇지는 않습니다. 레퍼런스를 참고하면 되기 때문이죠. 다만 이것을 자유롭게 활용 할 수 있는 능력을...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-python/",
        "teaser": null
      },{
        "title": "Pytorch ",
        "excerpt":"✅ Introduction to PyTorch 파이토치를 공부합시다. 네트워크 구현 및 데이터 로딩, 프로젝트 구조, 로깅, Multi GPU, 이어 학습 을 다룹니다. 밑바닥부터 딥러닝 코드 짜기를 짤 수도 있습니다. 책 읽어보세요. 하지만 저희는 딥러닝 프레임워크를 사용합니다. 예를 들어서 텐서플로와 파이토치가 있습니다. 텐서플로는 구글에서 만들었고, 파이토치는 페이스북에서 만들었습니다. 저희는 파이토치를 사용할 것입니다. 파이토치는...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-pytorch/",
        "teaser": null
      },{
        "title": "컴퓨터 비전의 모든 것",
        "excerpt":"컴퓨터 비전의 역사 딥러닝은 빠르게 변하는 분야이기 때문에 손 놓고 남들이 해놓은 자료만 보려고 하다가는 뒤쳐지게 됩니다. 우리는 영어에 익숙해져야 합니다. 거꾸로 돌려져있는 인간의 초상화 를 본 적 있습니까. 우리는 거꾸로 뒤집힌 인간의 얼굴을 올바르게 보는 능력을 가지고 있지 않습니다. 결국 인간도 편향적으로 학습이 된 것이죠. 컴퓨터 비전은 많은 곳에서...","categories": ["aitech_knowledge_cv"],
        "tags": [],
        "url": "/aitech_knowledge_cv/post-cv/",
        "teaser": null
      },{
        "title": "KLUE",
        "excerpt":"목차 한국어 언어모델 학습 및 다중 과제 튜닝 과정 인공지능과 자연어 처리 (이론/실습) 자연어의 전처리 (이론/실습) BERT 언어모델(1) (이론/실습) BERT 언어모델(2) (이론/실습) BERT 언어모델 기반의 단일 문장 분류 (이론/실습) BERT 언어모델 기반의 두 문장 관계 분류 (이론/실습) BERT 언어모델 기반의 문장 토큰 분류 (이론/실습) GPT 언어모델 (이론/실습) GPT 언어모델 기반의...","categories": ["aitech_knowledge_nlp"],
        "tags": [],
        "url": "/aitech_knowledge_nlp/post-klue/",
        "teaser": null
      },{
        "title": "MRC(Machine reading comprehension)",
        "excerpt":"MRC(Machine reading comprehension)란? 주어진 지문(context)를 이해하고 주어진 질의(Query/Question)의 답변을 추론하는 문제 Q&amp;A 분야에 응용될 수 있습니다. Extractive Answer Datasets 질의에 대한 답이 항상 주어진 지문의 segment (or span) 으로 존재 Descriptive/Narrative Answer Datasets 지문 내에서 추출한 span이 아닌, 질의를 보고 생성된 sentence (or free-form) 형태의 output을 내야하는 task Multiple-choice Datasets...","categories": ["aitech_knowledge_nlp"],
        "tags": [],
        "url": "/aitech_knowledge_nlp/post-mrc/",
        "teaser": null
      },{
        "title": "자연어 처리의 모든 것",
        "excerpt":"   자연어 처리의 모든 것  시작합니다.  ","categories": ["aitech_knowledge_nlp"],
        "tags": [],
        "url": "/aitech_knowledge_nlp/post-nlp/",
        "teaser": null
      },{
        "title": "recsys",
        "excerpt":"   ","categories": ["aitech_knowledge_recsys"],
        "tags": [],
        "url": "/aitech_knowledge_recsys/post-recsys/",
        "teaser": null
      },{
        "title": "[이코테]이코테 4장(구현)",
        "excerpt":"구현 구현이란 머릿속에 있는 알고리즘을 소스코드로 바꾸는 과정을 말합니다. 아이디어를 떠올리는 것은 쉽지만 코드로 바꾸는 것이 쉽지 않은 것이 구현 문제로 나온다. 결국 코드를 잘 만질 수 있는 능력이 있어야 한다는 소리다. 시뮬레이션, 구현, 완전 탐색은 유사한 부분이 많다. 일반적으로 전체 데이터 개수가 100만 개 이하일 때 완전 탐색을 사용하면...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C4%EC%9E%A5-%EA%B5%AC%ED%98%84/",
        "teaser": null
      },{
        "title": "[이코테] 1장, 2장",
        "excerpt":"이코테 1 장 개요 시간 복잡도 알고리즘을 위해 필요한 연산의 횟수 공간 복잡도 알고리즘을 위해 필요한 메모리의 양 빅오 표기법 빅오 표기법 명칭 O(1) 상수 O(logN) 로그 시간 O(N) 선형 시간 O(NlonN) 로그 선형 시간 O(N^2) 이차 시간 O(N^3) 삼차 시간 O(2^3) 지수 시간 수행 시간 체크 import time start_time...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C1,2%EC%9E%A5/",
        "teaser": null
      },{
        "title": "[이코테] 3장(그리디 알고리즘)",
        "excerpt":"그리디 알고리즘 자, 그리디 알고리즘을 공부합시다. 그리디 알고리즘은 지금 당장 최적인 답을 선택하는 과정을 반복하여 결과를 도출하는 알고리즘을 말합니다. 일반적으로 그리디 알고리즘은 최적의 해를 보장할 수 없는 경우가 많다. 역으로, 그리디 알고리즘을 사용해야 해야 하는 경우는 탐욕적으로 찾은 해가 최적의 해라는 뜻이다. 코딩테스트 환경에서 그리디 알고리즘으로 풀 수 있는 경우는...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C3%EC%9E%A5-%EA%B7%B8%EB%A6%AC%EB%94%94%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/",
        "teaser": null
      },{
        "title": "ai tech -Day03 ",
        "excerpt":"오늘 무엇을 했나? python 복습했다. aimath 1 ~ 5 강을 들었다. pytorch template 분석 했다. 포스팅 정리를 했다. github 블로그를 만들었다. 내일 무엇을 할 것인가? ai math, pytorch 강의 마무리 하면서 포스팅 정리 하기 과제 검토 RNN 의 오차 역전파 연구하기 [오늘의 생각] 오늘 NLP 팀 발표 시간을 가졌다. 논문...","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day03/",
        "teaser": null
      },{
        "title": "ai tech - pytorch Template 완전 분석 ",
        "excerpt":"Pytorch 템플릿을 문석해봅시다. 링크 여기 오픈 소스가 하나 있습니다. 이 포스팅을 통해 이 템플릿을 분해, 분석 해보는 시간을 가지려고 합니다. * train.py -&gt; 실행 * test.py -&gt; 실행 * config -&gt; 설정 * parse_config -&gt; 설정 * base -&gt; base 모델 * data_loader ~ -&gt; data * model ~ -&gt;...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-pytorchtemplate/",
        "teaser": null
      },{
        "title": "ai_cv",
        "excerpt":"ai_cv  ","categories": ["ai_cv"],
        "tags": [],
        "url": "/ai_cv/post-cv/",
        "teaser": null
      },{
        "title": "선형대수학",
        "excerpt":"선형대수학 선형대수(linear algebra)는 데이터 분석에 필요한 각종 계산을 돕는 학문 [링크] 선형성 선형성이란 입력값에 a 라는 영향을 주면 결과치도 a 라는 결과 값을 받는 것을 말한다. 선형성의 결과에 따라 예측 가능한 시스템을 만들 수 있다. 선형 결합 ax + by = z 를 만족하는 a, b 의 값을 찾는 것이...","categories": ["ai_linearalgebra"],
        "tags": [],
        "url": "/ai_linearalgebra/post-%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99/",
        "teaser": null
      },{
        "title": "NLP 개론",
        "excerpt":"ai_nlp  ","categories": ["ai_nlp"],
        "tags": [],
        "url": "/ai_nlp/post-nlp/",
        "teaser": null
      },{
        "title": "ai_recsys",
        "excerpt":"ai_recsys  ","categories": ["ai_recsys"],
        "tags": [],
        "url": "/ai_recsys/post-recsys/",
        "teaser": null
      },{
        "title": "ai tech -Day04 ",
        "excerpt":"   오늘 무엇을 했나?     과제를 풀면서 한 주간 배운 내용을 정리했다.   파이토치 내용을 보충했다.   딥러닝 기초 다지기 강의를 들었다.   ai math 내용을 보충했다.   내일 무엇을 할 것인가?     RNN 강의 복습   pytorch 강의 복습   딥러닝 기초 다지기 강의 수강  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day04/",
        "teaser": null
      },{
        "title": "Dive into NLP",
        "excerpt":"Dive Into NLP 자연어 처리를 공부합시다. 자연어 처리(自然語處理) 또는 자연 언어 처리(自然言語處理)는 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 모사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나 (출처: 위키피디아) 자연어처리의 주요 분야 자연어처리의 주요 분야를 알아봅시다. 1. NLP (ACL, EMNLP, NAACL) 자연어 처리의 대표적인 학회는 ACL, EMNLP,...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-Dive-Into-NLP/",
        "teaser": null
      },{
        "title": "딥러닝 모니터링(Monintoring) 하기",
        "excerpt":"Monitoring 학습을 하는 데 굉장히 긴 시간이 걸립니다. 학습 과정을 기록하는게 좋겠죠. TensorBoard와 Weight &amp; Bias를 이용해봅시다. Tensorboard scalar : metric 표시 graph : 계산 그래프 histogram : weight 분포 image: 예측 값과 실게 값을 비교 표시 mesh : 3d 형태의 데이터를 표현하는 도구 import os logs_base_dir = 'logs' os.makedirs(logs_base_dir,...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-monitoring/",
        "teaser": null
      },{
        "title": "딥러닝의 모든 것(All about Deep Learning)",
        "excerpt":"누가 좋은 딥러너인가 ? 누가 좋은 딥러너 일까요? 수학적 지식이 뛰어나야 합니다. 논문을 잘 읽어야 하고요. 구현 능력이 뛰어나야 합니다. 여러분들은 그 실력을 키우시기 바랍니다. 논문을 읽거나 모델을 연구할 때 1. 데이터 2. 모델 3. 손실함수 4. 학습 알고리즘 를 고려합시다. 공부합시다. 1. Historical Review 2. Neural Networks &amp; Multi-Layer...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EB%AA%A8%EB%93%A0%EA%B2%83-copy/",
        "teaser": null
      },{
        "title": "선형대수학",
        "excerpt":"   선형대수학     선형 대   ","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99/",
        "teaser": null
      },{
        "title": "ai tech -Day05 ",
        "excerpt":"  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day05/",
        "teaser": null
      },{
        "title": "딥러닝 바닥부터 만들기 (intro ~ step10)",
        "excerpt":"   바닥부터 딥러닝을 만들어보자.   우리는 바닥부터 딥러닝 모델을 한번 만들어 볼것입니다.  ","categories": ["book"],
        "tags": [],
        "url": "/book/post-%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D(1)/",
        "teaser": null
      },{
        "title": "챗봇 만들기",
        "excerpt":"   챗봇을 만듭시다.  ","categories": ["chatbot"],
        "tags": [],
        "url": "/chatbot/post-%EC%B1%97%EB%B4%87/",
        "teaser": null
      },{
        "title": "nlp 면접 준비",
        "excerpt":"nlp 면접 인터뷰 준비 면접 준비를 한번 잘 해봅시다. 답을 나만의 언어로 천천히 기록해보도록 합시다. 참고했던 자료 링크1 전이학습 - 전이학습이란? 한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식입니다. 전이학습을 위해서는 ImageNet과 같은 대량의 데이터셋으로 이미 학습이 되어있는 모델을 사용합니다. 이를 '사전에 학습된 모델' 혹은...","categories": ["interview"],
        "tags": [],
        "url": "/interview/post-%EC%9D%B8%ED%84%B0%EB%B7%B0/",
        "teaser": null
      },{
        "title": "ai tech 2주차",
        "excerpt":"[2주차 계획] 텐서보드 튜토리얼 코드 돌리기 WanB 튜토리얼 코드 돌려보기 하이퍼 파라미터 튜닝 해보기 코테 스터디 잘 참여하기 [2주차를 보내며] 강의 정리 파이토치 강의록 정리 벌써 2주의 시간이 흘렀습니다. 첫 주차에 파이썬, 딥러닝 수학을 배웠고 이번주엔 딥러닝을 실제 구현 할 수 있는 파이토치 를 배웠습니다. 파이토치의 기본적인 사용법, dataset, dataLoader...","categories": ["aitech_weekly"],
        "tags": [],
        "url": "/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/",
        "teaser": null
      },{
        "title": "ai tech - Day06 ",
        "excerpt":"5F 그날의 사실 (Facts) : 파이토치 수업을 시작했습니다. 본격적인 딥러닝 구현을 들어가서 설렜습니다. 월요일 9시가 되고 과제를 열어보니 난이도가 꽤 있어서 걱정이 조금 되었습니다. 수요일 까지 최대한 빨리 끝내놓고 한 주의 마무리를 잘 해야 겠다는 다짐을 했습니다. 팀원들과 코딩테스트 스터디를 시작했습니다. [이것이 취업을 위한 코딩테스트다.] 라는 책으로 시작하게 되었는데요. 그리디...","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day06/",
        "teaser": null
      },{
        "title": "ai tech -Day07 ",
        "excerpt":"5F 그날의 사실 (Facts) : 파이토치 autograd, dataset, dataLoader 에 대해 공부했습니다. 구글링을 하지 않고 과제를 풀었습니다. 파이토치 공식 문서를 하루 종일 보면서 몇 문제를 남겨놓고 어찌어찌 풀긴 풀었습니다. 기분이 좋기도 하지만 그 과정이 너무 힘들었습니다. 지문이 상당히 많은데 복습하는데 시간을 써야 겠습니다. DataLoader 부분을 현재 풀고 있는데 좌절감이 듭니다....","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day07/",
        "teaser": null
      },{
        "title": "ai tech -Day08 ",
        "excerpt":"   5F  그날의 사실 (Facts) :  과제1, 과제 2을 풀었습니다. 강의와 딥러닝 파이토치 교과서 라는 책을 병행하면서 과제를 풀고 있습니다. 팀원들과 그리디 알고리즘 2 문제를 풀었습니다.   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day08/",
        "teaser": null
      },{
        "title": "ai tech -Day09 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day09/",
        "teaser": null
      },{
        "title": "ai tech -Day10 ",
        "excerpt":"  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day10/",
        "teaser": null
      },{
        "title": "전이학습",
        "excerpt":"전이학습 위키백과에 의하면 전이학습은 한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식을 말합니다. 전이 학습은 하나의 작업에 대해 훈련된 모델을 사용하여 다른 관련 작업의 성능을 향상시킬 수 있는 기계 학습 기술입니다. 전이 학습에서는 처음부터 시작하는 대신 사전 훈련된 모델을 새로운 작업의 시작점으로 사용합니다. 사전 훈련된...","categories": ["aitech_knowledge"],
        "tags": [],
        "url": "/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/",
        "teaser": null
      },{
        "title": "[백준][14916] 거스름돈",
        "excerpt":"해결 전략 그리디 알고리즘으로 풉니다. 앞 사람과의 키차이를 gabs 라는 리스트에 저장해줍니다. 문제에서 요구하는 것은 최소 비용으로 M 개의 그룹을 만드는 것을 요구합니다. gab 리스트에서 특정 하나를 제거한다는 것은 그 구간을 통합한다는 개념이고 그룹 수를 하나 줄인다는 것입니다. (N-1 개의 갭이 있는 gabs는 M개의 그룹이 최초로 세팅되어 있다고 이해하면 됩니다.)...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-%EB%B0%B1%EC%A4%80-14816-%EA%B1%B0%EC%8A%A4%EB%A6%84%EB%8F%88/",
        "teaser": null
      },{
        "title": "[논문리뷰] A Survey of the Usages of Deep Learning for Natural Language Processing(2017)",
        "excerpt":"A Survey of the Usages of Deep Learning for Natural Language Processing 💡 2018년 1. Introduction 2. Fundamentals of Deep Learning and NLP 2.1 Deep Learning 2.2 Natural Language Processing 3. Deep Learning Architectures for NLP 3.1 Convolutional Neural Networks 3.2 Recurrent Neural Networks 3.3 Transformers 4. Use Cases of...","categories": ["paper"],
        "tags": [],
        "url": "/paper/post-surveyNLP/",
        "teaser": null
      },{
        "title": "Segmentation & Detection",
        "excerpt":"Segmentation Segmentation는 미리 정의된 기준이나 특징에 따라 이미지나 비디오를 여러 영역 또는 세그먼트로 나누는 컴퓨터 비전 작업입니다. 분할의 목표는 이미지나 동영상에서 의미 있고 유용한 정보를 추출하여 사물인식, 장면이해, 자율주행 등 다양한 응용에 활용될 수 있도록 하는 것입니다. 세그멘테이션에는 시맨틱 세그먼테이션과 인스턴스 세그먼테이션의 두 가지 주요 유형이 있습니다. 시맨틱 분할에는 이미지...","categories": ["ai"],
        "tags": [],
        "url": "/ai/post-Segmentation-&-Detection/",
        "teaser": null
      },{
        "title": "컴퓨터 비전의 중요한 7가지 모델",
        "excerpt":"ai 컴퓨터 비전의 중요한 7가지 모델 컴퓨터 비전 분야에는 몇 가지 영향력 있는 모델과 아키텍처가 있으며, 그 중 다수는 이 분야를 발전시키는 데 중요한 역할을 했습니다. 다음은 7가지 중요한 모델입니다. LeNet-5: 1990년대에 Yann LeCun이 개발한 LeNet-5는 필기 숫자 인식을 위해 설계된 선구적인 컨볼루션 신경망(CNN)입니다. 이는 많은 미래 CNN 아키텍처의 토대를...","categories": ["ai"],
        "tags": [],
        "url": "/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/",
        "teaser": null
      },{
        "title": "ai tech - Day11 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day11/",
        "teaser": null
      },{
        "title": "[논문리뷰] Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)",
        "excerpt":"Deep Learning’s Most Important Ideas - A Brief Historical Review(2020) 2012 – AlexNet AlexNet은 2012년 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 개발한 심층 컨볼루션 신경망(CNN) 아키텍처다. 오류율은 15.3%로 두 번째로 좋은 모델보다 훨씬 뛰어나다. AlexNet은 8개의 계층으로 구성되어 있다. 5개의 컨볼루션 계층과 3개의 완전 연결 계층이 있습니다. 이 네트워크는...","categories": ["paper"],
        "tags": [],
        "url": "/paper/post-A-Brief-Historical-Review/",
        "teaser": null
      },{
        "title": "Pytorch DataLoader DataSet",
        "excerpt":"Pytorch DataLoader DataSet 옵션 데이터 집합: 로드할 데이터 집합 개체를 지정하는 필수 인수입니다. 데이터 집합 개체는 torch.utils.data에서 파생된 클래스의 인스턴스여야 합니다.getitem 및 len 메서드가 구현된 데이터 세트. 배치_크기: 이 옵션 인수는 각 배치에서 로드하고 처리할 샘플 수를 정의합니다. 기본적으로 1(즉, 배치 없음)로 설정됩니다. 배치 크기가 클수록 교육 효율성이 향상될 수...","categories": ["ai"],
        "tags": [],
        "url": "/ai/post-Pytorch-DataLoader-DataSet/",
        "teaser": null
      },{
        "title": "RNN, LSTM, GRU",
        "excerpt":"RNN RNN(Recurrent Neural Network)은 시계열, 자연어 및 음성 신호와 같은 순차적 데이터로 작업하도록 설계된 인공 신경망 클래스입니다. 기존의 피드포워드 신경망과 달리 RNN에는 자체 루프백 연결이 있어 일종의 메모리 역할을 할 수 있는 숨겨진 상태를 유지할 수 있습니다. 따라서 RNN은 입력 시퀀스를 처리하고 입력 데이터의 컨텍스트 또는 기록을 기반으로 결과를 예측하는...","categories": ["ai"],
        "tags": [],
        "url": "/ai/post-RNN,-LSTM,-GRU/",
        "teaser": null
      },{
        "title": "ai tech - Day12 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day12/",
        "teaser": null
      },{
        "title": "[논문리뷰] Attention is all you need",
        "excerpt":"Attention is All you need 구글의 Attention is All you 논문을 통해 nlp 의 혁명이 일어났습니다. 기존의 rnn 모델은 attention 모델로 대체되었습니다. 왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠. “Attention is All You Need”는 자연어 처리 및 기계 번역과 같은 sequence-to-sequence 작업을 위한 새로운 딥 러닝 아키텍처인 Transformer...","categories": ["paper"],
        "tags": [],
        "url": "/paper/post-attention-is-all-you-need/",
        "teaser": null
      },{
        "title": "ai tech - Day13 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day13/",
        "teaser": null
      },{
        "title": "ai tech - Day14 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day14/",
        "teaser": null
      },{
        "title": "[프로그래머스] 기둥과보",
        "excerpt":"해결 전략 is_normal 함수를 이용해서 정상성 여부를 검사한다. 수의 범위가 적으니 완전탐색으로 풀어도 되는 문제였다. 수가 적으면 완전탐색을 의심해봅시다. def solution(n, build_frame): answer = [[]] update_map = set() def is_normal(update_map): for material in update_map: # 보 라면 if material[2] == 1: # 한쪽에라도 기둥이 있으면 된다. if (material[0], material[1]-1, 0)...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4/",
        "teaser": null
      },{
        "title": "[연재][Clear Algo][1편] - 그리디 알고리즘 ",
        "excerpt":"[연재][Clear Algo][1편] - 그리디 알고리즘   ","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-ps_study_-%EC%97%B0%EC%9E%AC-clearAlgo-1%ED%8E%B8/",
        "teaser": null
      },{
        "title": "ai tech - Day15 ",
        "excerpt":"   5F  그날의 사실 (Facts) :   느낌 (Feeling) :   배운점 (Findings) :   미래의 행동계획 (Future) :   피드백 (Feedback) :  ","categories": ["aitech_daily"],
        "tags": [],
        "url": "/aitech_daily/post-day15/",
        "teaser": null
      },{
        "title": "[프로그래머스] 기둥과보",
        "excerpt":"해결 전략 전형적인 시뮬레이션 문제입니다. 문제를 잘 읽고 step 을 구현합시다. 동서남북 이동과 방향이동에 주의합시다. 사과조건과 뱀의 trace 를 잘 표시해야 합니다. import sys input = sys.stdin.readline N = int(input()) apple_cnt = int(input()) # 사과 표시하기 apple_map = [[False for i in range(N)] for j in range(N)] for i in...","categories": ["ps"],
        "tags": [],
        "url": "/ps/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/",
        "teaser": null
      }]
