<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-12T18:16:48+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><entry><title type="html">Post: ai tech 2주차</title><link href="http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/" rel="alternate" type="text/html" title="Post: ai tech 2주차" /><published>2023-03-12T00:00:00+09:00</published><updated>2023-03-13T06:20:02+09:00</updated><id>http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8</id><content type="html" xml:base="http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="2주차-계획">2주차 계획</h1>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />텐서보드 튜토리얼 코드 돌리기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />WanB 튜토리얼 코드 돌려보기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />하이퍼 파라미터 튜닝 해보기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />코테 스터디 잘 참여하기</li>
</ul>

<h1 id="2주차">2주차</h1>

<h1 id="2주차를-보내며">[2주차를 보내며]</h1>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_weekly" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: ai tech -Day05</title><link href="http://localhost:4000/aitech_daily/post-day05/" rel="alternate" type="text/html" title="Post: ai tech -Day05" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day05</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day05/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: 딥러닝 바닥부터 만들기 (intro ~ step10)</title><link href="http://localhost:4000/book/post-%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D(1)/" rel="alternate" type="text/html" title="Post: 딥러닝 바닥부터 만들기 (intro ~ step10)" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/book/post-%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0%20%EB%A7%8C%EB%93%9C%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D(1)</id><content type="html" xml:base="http://localhost:4000/book/post-%EB%B0%94%EB%8B%A5%EB%B6%80%ED%84%B0-%EB%A7%8C%EB%93%9C%EB%8A%94-%EB%94%A5%EB%9F%AC%EB%8B%9D(1)/"><![CDATA[<p><img src="../../../image/바닥부터.png" alt="image" /></p>

<h1 id="바닥부터-딥러닝을-만들어보자">바닥부터 딥러닝을 만들어보자.</h1>

<p>우리는 바닥부터 딥러닝 모델을 한번 만들어 볼것입니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="book" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: 챗봇 만들기</title><link href="http://localhost:4000/chatbot/post-%EC%B1%97%EB%B4%87/" rel="alternate" type="text/html" title="Post: 챗봇 만들기" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/chatbot/post-%EC%B1%97%EB%B4%87</id><content type="html" xml:base="http://localhost:4000/chatbot/post-%EC%B1%97%EB%B4%87/"><![CDATA[<p><img src="../../../image/chatbot/chatbot_lachesis.png" width="200" height="400" /></p>

<h1 id="챗봇을-만듭시다">챗봇을 만듭시다.</h1>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="chatbot" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: Attention is all you need</title><link href="http://localhost:4000/paper/post-attention-is-all-you-need/" rel="alternate" type="text/html" title="Post: Attention is all you need" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-attention%20is%20all%20you%20need</id><content type="html" xml:base="http://localhost:4000/paper/post-attention-is-all-you-need/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<h1 id="attention-is-all-you-need"><code class="language-plaintext highlighter-rouge">Attention is All you need</code></h1>

<h2 id="이-논문의-함의">이 논문의 함의!</h2>
<p>구글의 <code class="language-plaintext highlighter-rouge">Attention is All you</code> 논문을 통해 nlp 의 혁명이 일어났습니다. 
기존의 rnn 모델은 attention 모델로 대체되었습니다.
왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: 논문리뷰</title><link href="http://localhost:4000/paper/post-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/" rel="alternate" type="text/html" title="Post: 논문리뷰" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0</id><content type="html" xml:base="http://localhost:4000/paper/post-%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<h1 id="논문리뷰">논문리뷰</h1>
<ul>
  <li>논문 리뷰를 합시다.</li>
</ul>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: nlp 면접 준비</title><link href="http://localhost:4000/interview/post-%EC%9D%B8%ED%84%B0%EB%B7%B0/" rel="alternate" type="text/html" title="Post: nlp 면접 준비" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-13T10:20:02+09:00</updated><id>http://localhost:4000/interview/post-%EC%9D%B8%ED%84%B0%EB%B7%B0</id><content type="html" xml:base="http://localhost:4000/interview/post-%EC%9D%B8%ED%84%B0%EB%B7%B0/"><![CDATA[<h1 id="nlp-면접-인터뷰-준비">nlp 면접 인터뷰 준비</h1>
<p>면접 준비를 한번 잘 해봅시다. 답을 나만의 언어로 천천히 기록해보도록 합시다.</p>

<p><br /><br /><br /><br /></p>

<h1 id="참고했던-자료">참고했던 자료</h1>
<ul>
  <li><a href="https://github.com/boostcamp-ai-tech-4/ai-tech-interview">링크1</a></li>
</ul>

<h2 id="interview-questions">Interview Questions</h2>

<h2 id="통계수학">통계/수학</h2>
<ul>
  <li>고유값(eigen value)와 고유벡터(eigen vector)이 무엇이고 왜 중요한지 설명해주세요.</li>
</ul>

<p>선형대수학에서 중요한 개념입니다. 선형대수학은 선형성을 가지는 대수를 연구하는 학문입니다.</p>

<ul>
  <li>샘플링(Sampling)과 리샘플링(Resampling)이 무엇이고 리샘플링의 장점을 말씀해주세요.</li>
  <li>확률 모형과 확률 변수는 무엇인가요?</li>
  <li>누적 분포 함수와 확률 밀도 함수는 무엇인가요? 수식과 함께 표현해주세요.</li>
  <li>조건부 확률은 무엇인가요?</li>
  <li>공분산과 상관계수는 무엇일까요? 수식과 함께 표현해주세요.</li>
  <li>신뢰 구간의 정의는 무엇인가요?</li>
  <li>p-value를 모르는 사람에게 설명한다면 어떻게 설명하실 건가요?</li>
  <li>R square의 의미는 무엇인가요?</li>
  <li>평균(mean)과 중앙값(median)중에 어떤 케이스에서 뭐를 써야할까요?</li>
  <li>중심극한정리는 왜 유용한걸까요?</li>
  <li>엔트로피(entropy)에 대해 설명해주세요. 가능하면 Information Gain도요.</li>
  <li>어떨 때 모수적 방법론을 쓸 수 있고, 어떨 때 비모수적 방법론을 쓸 수 있나요?</li>
  <li>“likelihood”와 “probability”의 차이는 무엇일까요?</li>
  <li>통계에서 사용되는 bootstrap의 의미는 무엇인가요.</li>
  <li>모수가 매우 적은 (수십개 이하) 케이스의 경우 어떤 방식으로 예측 모델을 수립할 수 있을까요?</li>
  <li>베이지안과 프리퀀티스트 간의 입장차이를 설명해주실 수 있나요?</li>
  <li>검정력(statistical power)은 무엇일까요?</li>
  <li>missing value가 있을 경우 채워야 할까요? 그 이유는 무엇인가요?</li>
  <li>아웃라이어의 판단하는 기준은 무엇인가요?</li>
  <li>필요한 표본의 크기를 어떻게 계산합니까?</li>
  <li>Bias를 통제하는 방법은 무엇입니까?</li>
  <li>로그 함수는 어떤 경우 유용합니까? 사례를 들어 설명해주세요.</li>
  <li>베르누이 분포 / 이항 분포 / 카테고리 분포 / 다항 분포 / 가우시안 정규 분포 / t 분포 / 카이제곱 분포 / F 분포 / 베타 분포 / 감마 분포에 대해 설명해주세요. 그리고 분포 간의 연관성도 설명해주세요.</li>
  <li>출장을 위해 비행기를 타려고 합니다. 당신은 우산을 가져가야 하는지 알고 싶어 출장지에 사는 친구 3명에게 무작위로 전화를 하고 비가 오는 경우를 독립적으로 질문해주세요. 각 친구는 2/3로 진실을 말하고 1/3으로 거짓을 말합니다. 3명의 친구가 모두 “그렇습니다. 비가 내리고 있습니다”라고 말했습니다. 실제로 비가 내릴 확률은 얼마입니까?</li>
</ul>

<p>머신러닝</p>

<ul>
  <li>알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision …)</li>
  <li>정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?</li>
  <li>Local Minima와 Global Minimum에 대해 설명해주세요.</li>
  <li>차원의 저주에 대해 설명해주세요.</li>
  <li>dimension reduction기법으로 보통 어떤 것들이 있나요?</li>
  <li>PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?</li>
  <li>LSA, LDA, SVD 등의 약자들이 어떤 뜻이고 서로 어떤 관계를 가지는지 설명할 수 있나요?</li>
  <li>Markov Chain을 고등학생에게 설명하려면 어떤 방식이 제일 좋을까요?</li>
  <li>텍스트 더미에서 주제를 추출해야 합니다. 어떤 방식으로 접근해 나가시겠나요?</li>
  <li>SVM은 왜 반대로 차원을 확장시키는 방식으로 동작할까요? SVM은 왜 좋을까요?</li>
  <li>다른 좋은 머신 러닝 대비, 오래된 기법인 나이브 베이즈(naive bayes)의 장점을 옹호해보세요.</li>
  <li>회귀 / 분류시 알맞은 metric은 무엇일까?</li>
  <li>Association Rule의 Support, Confidence, Lift에 대해 설명해주세요.</li>
  <li>최적화 기법중 Newton’s Method와 Gradient Descent 방법에 대해 알고 있나요?</li>
  <li>머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?</li>
  <li>인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?</li>
  <li>지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?</li>
  <li>ROC 커브에 대해 설명해주실 수 있으신가요?</li>
  <li>여러분이 서버를 100대 가지고 있습니다. 이때 인공신경망보다 Random Forest를 써야하는 이유는 뭘까요?</li>
  <li>K-means의 대표적 의미론적 단점은 무엇인가요? (계산량 많다는것 말고)</li>
  <li>L1, L2 정규화에 대해 설명해주세요.</li>
  <li>Cross Validation은 무엇이고 어떻게 해야하나요?</li>
  <li>XGBoost을 아시나요? 왜 이 모델이 캐글에서 유명할까요?</li>
  <li>앙상블 방법엔 어떤 것들이 있나요?</li>
  <li>feature vector란 무엇일까요?</li>
  <li>좋은 모델의 정의는 무엇일까요?</li>
  <li>50개의 작은 의사결정 나무는 큰 의사결정 나무보다 괜찮을까요? 왜 그렇게 생각하나요?</li>
  <li>스팸 필터에 로지스틱 리그레션을 많이 사용하는 이유는 무엇일까요?</li>
  <li>OLS(ordinary least squre) regression의 공식은 무엇인가요?</li>
</ul>

<details>
<summary><a href="./answers/3-deep-learning.md"><strong>🧠 딥러닝</strong></a></summary>

- 딥러닝은 무엇인가요? 딥러닝과 머신러닝의 차이는?
- Cost Function과 Activation Function은 무엇인가요?
- Tensorflow, PyTorch 특징과 차이가 뭘까요?
- Data Normalization은 무엇이고 왜 필요한가요?
- 알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)
- 오버피팅일 경우 어떻게 대처해야 할까요?
- 하이퍼 파라미터는 무엇인가요?
- Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?
- 볼츠만 머신은 무엇인가요?
- TF, PyTorch 등을 사용할 때 디버깅 노하우는?
- 뉴럴넷의 가장 큰 단점은 무엇인가? 이를 위해 나온 One-Shot Learning은 무엇인가?
- 요즘 Sigmoid 보다 ReLU를 많이 쓰는데 그 이유는?
  - Non-Linearity라는 말의 의미와 그 필요성은?
  - ReLU로 어떻게 곡선 함수를 근사하나?
  - ReLU의 문제점은?
  - Bias는 왜 있는걸까?
- Gradient Descent에 대해서 쉽게 설명한다면?
  - 왜 꼭 Gradient를 써야 할까? 그 그래프에서 가로축과 세로축 각각은 무엇인가? 실제 상황에서는 그 그래프가 어떻게 그려질까?
  - GD 중에 때때로 Loss가 증가하는 이유는?
  - Back Propagation에 대해서 쉽게 설명 한다면?
- Local Minima 문제에도 불구하고 딥러닝이 잘 되는 이유는?
  - GD가 Local Minima 문제를 피하는 방법은?
  - 찾은 해가 Global Minimum인지 아닌지 알 수 있는 방법은?
- Training 세트와 Test 세트를 분리하는 이유는?
  - Validation 세트가 따로 있는 이유는?
  - Test 세트가 오염되었다는 말의 뜻은?
  - Regularization이란 무엇인가?
- Batch Normalization의 효과는?
  - Dropout의 효과는?
  - BN 적용해서 학습 이후 실제 사용시에 주의할 점은? 코드로는?
  - GAN에서 Generator 쪽에도 BN을 적용해도 될까?
- SGD, RMSprop, Adam에 대해서 아는대로 설명한다면?
  - SGD에서 Stochastic의 의미는?
  - 미니배치를 작게 할때의 장단점은?
  - 모멘텀의 수식을 적어 본다면?
- 간단한 MNIST 분류기를 MLP+CPU 버전으로 numpy로 만든다면 몇줄일까?
  - 어느 정도 돌아가는 녀석을 작성하기까지 몇시간 정도 걸릴까?
  - Back Propagation은 몇줄인가?
  - CNN으로 바꾼다면 얼마나 추가될까?
- 간단한 MNIST 분류기를 TF, PyTorch 등으로 작성하는데 몇시간이 필요한가?
  - CNN이 아닌 MLP로 해도 잘 될까?
  - 마지막 레이어 부분에 대해서 설명 한다면?
  - 학습은 BCE loss로 하되 상황을 MSE loss로 보고 싶다면?
- 딥러닝할 때 GPU를 쓰면 좋은 이유는?
  - GPU를 두개 다 쓰고 싶다. 방법은?
  - 학습시 필요한 GPU 메모리는 어떻게 계산하는가?

</details>

<details>
<summary><a href="./answers/4-python.md"><strong>🐍 파이썬</strong></a></summary>

- What is the difference between list and tuples in Python?
- What are the key features of Python?
- What type of language is python? Programming or scripting?
- Python an interpreted language. Explain.
- What is pep 8?
- How is memory managed in Python?
- What is namespace in Python?
- What is PYTHONPATH?
- What are python modules? Name some commonly used built-in modules in Python?
- What are local variables and global variables in Python?
- Is python case sensitive?
- What is type conversion in Python?
- How to install Python on Windows and set path variable?
- Is indentation required in python?
- What is the difference between Python Arrays and lists?
- What are functions in Python?
- What is `__init__`?
- What is a lambda function?
- What is self in Python?
- How does break, continue and pass work?
- What does `[::-1]` do?
- How can you randomize the items of a list in place in Python?
- What’s the difference between iterator and iterable?
- How can you generate random numbers in Python?
- What is the difference between range &amp; xrange?
- How do you write comments in python?
- What is pickling and unpickling?
- What are the generators in python?
- How will you capitalize the first letter of string?
- How will you convert a string to all lowercase?
- How to comment multiple lines in python?
- What are docstrings in Python?
- What is the purpose of is, not and in operators?
- What is the usage of help() and dir() function in Python?
- Whenever Python exits, why isn’t all the memory de-allocated?
- What is a dictionary in Python?
- How can the ternary operators be used in python?
- What does this mean: `*args`, `**kwargs`? And why would we use it?
- What does len() do?
- Explain split(), sub(), subn() methods of “re” module in Python.
- What are negative indexes and why are they used?
- What are Python packages?
- How can files be deleted in Python?
- What are the built-in types of python?
- What advantages do NumPy arrays offer over (nested) Python lists?
- How to add values to a python array?
- How to remove values to a python array?
- Does Python have OOps concepts?
- What is the difference between deep and shallow copy?
- How is Multithreading achieved in Python?
- What is the process of compilation and linking in python?
- What are Python libraries? Name a few of them.
- What is split used for?
- How to import modules in python?
- Explain Inheritance in Python with an example.
- How are classes created in Python?
- What is monkey patching in Python?
- Does python support multiple inheritance?
- What is Polymorphism in Python?
- Define encapsulation in Python?
- How do you do data abstraction in Python?
- Does python make use of access specifiers?
- How to create an empty class in Python?
- What does an object() do?
- What is map function in Python?
- Is python numpy better than lists?
- What is GIL in Python language?
- What makes the CPython different from Python?
- What are Decorators in Python?
- What is object interning?
- What is @classmethod, @staticmethod, @property?

</details>

<details>
<summary><a href="./answers/5-network.md"><strong>🌐 네트워크</strong></a></summary>

- TCP/IP의 각 계층을 설명해주세요.
- OSI 7계층와 TCP/IP 계층의 차이를 설명해주세요.
- Frame, Packet, Segment, Datagram을 비교해주세요.
- TCP와 UDP의 차이를 설명해주세요.
- TCP와 UDP의 헤더를 비교해주세요.
- TCP의 3-way-handshake와 4-way-handshake를 비교 설명해주세요.
- TCP의 연결 설정 과정(3단계)과 연결 종료 과정(4단계)이 단계가 차이나는 이유가 무엇인가요?
- 만약 Server에서 FIN 플래그를 전송하기 전에 전송한 패킷이 Routing 지연이나 패킷 유실로 인한 재전송 등으로 인해 FIN 패킷보다 늦게 도착하는 상황이 발생하면 어떻게 될까요?
- 초기 Sequence Number인 ISN을 0부터 시작하지 않고 난수를 생성해서 설정하는 이유가 무엇인가요?
- HTTP와 HTTPS에 대해서 설명하고 차이점에 대해 설명해주세요.
- HTTP 요청/응답 헤더의 구조를 설명해주세요.
- HTTP와 HTTPS 동작 과정을 비교해주세요.
- CORS가 무엇인가요?
- HTTP GET과 POST 메서드를 비교/설명해주세요.
- 쿠키(Cookie)와 세션(Session)을 설명해주세요.
- DNS가 무엇인가요?
- REST와 RESTful의 개념을 설명하고 차이를 말해주세요.
- 소켓(Socket)이 무엇인가요? 자신 있는 언어로 간단히 소켓 생성 예시를 보여주세요.
- Socket.io와 WebSocket의 차이를 설명해주세요.
- IPv4와 IPv6 차이를 설명해주세요.
- MAC Address가 무엇인가요?
- 라우터와 스위치, 허브의 차이를 설명해주세요.
- SMTP가 무엇인가요?
- 노트북으로 `www.google.com`에 접속을 했습니다. 요청을 보내고 받기까지의 과정을 자세히 설명해주세요.
- 여러 네트워크 topology에 대해 간단히 소개해주세요.
- subnet mask에 대해서 설명해주세요.
- data encapsulation이 무엇인가요?
- DHCP를 설명해주세요.
- routing protocol을 몇 가지 설명해주세요. (ex. link state, distance vector)
- 이더넷(ethernet)이 무엇인가요?
- client와 server의 차이점을 설명해주세요.
- delay, timing(jitter), throughput 차이를 설명해주세요.

</details>

<details>
<summary><a href="./answers/6-operating-system.md"><strong>🖥️ 운영체제</strong></a></summary>

- 프로세스와 스레드의 차이(Process vs Thread)를 알려주세요.
- 멀티 프로세스 대신 멀티 스레드를 사용하는 이유를 설명해주세요.
- 캐시의 지역성에 대해 설명해주세요.
- Thread-safe에 대해 설명해주세요. (hint: critical section)
- 뮤텍스와 세마포어의 차이를 설명해주세요.
- 스케줄러가 무엇이고, 단기/중기/장기로 나누는 기준에 대해 설명해주세요.
- CPU 스케줄러인 FCFS, SJF, SRTF, Priority Scheduling, RR에 대해 간략히 설명해주세요.
- 동기와 비동기의 차이를 설명해주세요.
- 메모리 관리 전략에는 무엇이 있는지 간략히 설명해주세요.
- 가상 메모리에 대해 설명해주세요.
- 교착상태(데드락, Deadlock)의 개념과 조건을 설명해주세요.
- 사용자 수준 스레드와 커널 수준 스레드의 차이를 설명해주세요.
- 외부 단편화와 내부 단편화에 대해 설명해주세요.
- Context Switching이 무엇인지 설명하고 과정을 나열해주세요.
- Swapping에 대해 설명해주세요.

</details>

<details>
<summary><a href="./answers/7-data-structure.md"><strong>🗂 자료구조</strong></a></summary>

- linked list
  - single linked list
  - double linked list
  - circular linked list
- hash table
- stack
- queue
  - circular queue
- graph
- tree
  - binary tree
  - full binary tree
  - complete binary tree
  - bst(binary search tree)
- heap(binary heap)
  - min heap
  - max heap
- red-black tree
- b+ tree

</details>

<details>
<summary><a href="./answers/8-algorithm.md"><strong>🔻 알고리즘</strong></a></summary>

- 시간, 공간 복잡도
- Sort Algorithm
  - Bubble Sort
  - Selection Sort
  - Insertion Sort
  - Merge Sort
  - Heap Sort
  - Quick Sort
  - Counting Sort
  - Radix Sort
- Divide and Conquer
- Dynamic Programming
- Greedy Algorithm
- Graph
  - Graph Traversal: BFS, DFS
  - Shortest Path
    - Dijkstra
    - Floyd-Warshall
    - Bellman-Ford
  - Minimum Spanning Tree
    - Prim
    - Kruskal
  - Union-find
  - Topological sort

</details>

<hr />]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="interview" /><summary type="html"><![CDATA[nlp 면접 인터뷰 준비 면접 준비를 한번 잘 해봅시다. 답을 나만의 언어로 천천히 기록해보도록 합시다.]]></summary></entry><entry><title type="html">Post: ai tech -Day04</title><link href="http://localhost:4000/aitech_daily/post-day04/" rel="alternate" type="text/html" title="Post: ai tech -Day04" /><published>2023-03-09T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day04</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day04/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="오늘-무엇을-했나">오늘 무엇을 했나?</h1>
<ul>
  <li>과제를 풀면서 한 주간 배운 내용을 정리했다.</li>
  <li>파이토치 내용을 보충했다.</li>
  <li>딥러닝 기초 다지기 강의를 들었다.</li>
  <li>ai math 내용을 보충했다.</li>
</ul>

<h1 id="내일-무엇을-할-것인가">내일 무엇을 할 것인가?</h1>
<ul>
  <li>RNN 강의 복습</li>
  <li>pytorch 강의 복습</li>
  <li>딥러닝 기초 다지기 강의 수강</li>
</ul>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: Dive into NLP</title><link href="http://localhost:4000/aitech_knowledge/post-Dive-Into-NLP/" rel="alternate" type="text/html" title="Post: Dive into NLP" /><published>2023-03-09T00:00:00+09:00</published><updated>2023-03-09T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-Dive%20Into%20NLP</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-Dive-Into-NLP/"><![CDATA[<p><img src="../../../image/nlp.png" alt="image" /></p>

<h1 id="dive-into-nlp">Dive Into NLP</h1>
<p>자연어 처리를 공부합시다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>자연어 처리(自然語處理) 또는 자연 언어 처리(自然言語處理)는 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 모사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나 (출처: 위키피디아)
</code></pre></div></div>

<p><br /><br /><br /><br /></p>

<h1 id="자연어처리의-주요-분야">자연어처리의 주요 분야</h1>
<p>자연어처리의 주요 분야를 알아봅시다.</p>

<h2 id="1-nlp-acl-emnlp-naacl">1. NLP (ACL, EMNLP, NAACL)</h2>
<p>자연어 처리의 대표적인 학회는 ACL, EMNLP, NAACL 이 있습니다.</p>

<p>주요 분야는 아래를 참고하세요.</p>

<ul>
  <li>machine translation -&gt; 기계 번역</li>
  <li>Sentiment analysis</li>
  <li>dialog systems -&gt; 챗봇 🔥</li>
  <li>summarization</li>
  <li>Named entity recognition (NER) -&gt; 객체에 이름 부여하기 (인식의 문제)</li>
  <li>텍스트 생성</li>
  <li>Spam Detection : 스팸 디텍션</li>
</ul>

<p><br /><br /><br /><br /></p>

<h2 id="2-text-mining-kdd-www-wsdm-cikm-icwsm">2. Text mining (KDD, WWW, WSDM, CIKM, ICWSM)</h2>
<ul>
  <li>비정형 데이터로부터 유용한 정보를 찾기</li>
  <li>추천 시스템</li>
  <li>MRC -&gt; 기계 독해</li>
  <li>MRC란 인공지능이 사람처럼 문서를 읽고 이해한 후 질문에 정확히 답하는 기술</li>
</ul>

<p><br /><br /><br /><br /></p>

<h2 id="3-information-retieval-sigir-wsdm-cikm-recsys">3. Information retieval (SIGIR, WSDM, CIKM, RecSys)</h2>
<ul>
  <li>추천 시스템</li>
  <li>Keyword Search</li>
</ul>

<h1 id="nlp-의-역사">NLP 의 역사</h1>
<p>NLP 는 최근 들어서 급속도로 연구되고 발전하고 있는 분야입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- RNN
- LSTRM
- GRU
- Transformer `Àttention all you need`
 - NLP의 혁명, AI 의 혁명
- BERT, GPT
  - self-supervised learning
</code></pre></div></div>

<p>요즘엔 NLP 의 혁명을 주도하는 곳은 거대 기업이라고 할수 있다. 왜냐하면 거대 모델은 거대한 학습이 필요하기 때문이다.
개인 개발자가 할 수 있는 것은 무엇인가?  AI 는 플랫폼 독점으로 나갈 것인가? 생각이 필요합니다.</p>

<p><br /><br /><br /><br /></p>

<h1 id="문장-분해하기">문장 분해하기</h1>

<h2 id="tokenization">Tokenization</h2>
<h2 id="stemming">stemming</h2>

<h2 id="한국어-자연어-처리-모델">한국어 자연어 처리 모델</h2>
<ul>
  <li>KoNLPy</li>
  <li>카카오</li>
  <li>은전한닢</li>
  <li>KT~</li>
</ul>

<h1 id="고전---bowbag-of-words">[고전] - BOW(Bag of Words)</h1>
<p>단어들의 순서를 고려하지 않습니다. 출현 빈도만 고려해서 텍스트를 분석하는 기법을 말합니다. 
즉, 가방에다가 단어들을 넣어 놓고 ‘뭐’ 가 ‘몇개’ 있는 지를 보는 아주 직관적인 방법으로 볼 수 있는 것이죠.</p>

<h2 id="나이브-베이즈-분류기">나이브 베이즈 분류기</h2>
<p>우리 나이브 베이스 분류기를 공부해봅시다.</p>

<h1 id="고전---tf-idfterm-frequency---inverse-document-frequency">[고전] - TF-IDF(Term Frequency - Inverse Document Frequency)</h1>

<p>특정 문서에 특정 단어가 얼만큼 있는지 값을 표현하는 것.
TF(단어 빈도, term frequency)
특정 단어가 문서 내에 얼마나 자주 등장하는 지 ? 
DF(문서 빈도, document frequency)
단어 자체가 전체 문서에서 사용되는 지
One hot encoding 으로 표현합니다. -&gt; 단어 간의 유사성을 파악하지 못하는 문제가 있습니다.</p>

<h1 id="word-embedding">Word Embedding</h1>
<p>현대 nlp의 근간이 되는 기술입니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>연관성 있는 단어들을 군집화하여 multi-dimension 공간에 vector 로 표시
단어나 문장을 vector space 로 끼워 넣음 (embedding)
</code></pre></div></div>

<p>k 번째 단어인 one hot encoding 와 word embedding matrix 를 곱하면 k 번째 로우가 k 번째 단어를 설명하는 weigts 가 된다.</p>

<h1 id="word2vec">Word2Vec</h1>
<p>구글이 2013년 개발했습니다. -&gt; by 비지도학습
중심단어로부터 주변단어를, 주변단어로부터 중심 단어를 임베딩 시키는 방식으로 학습합니다. 그 코사인 유사도가 유사하도록 한다.</p>

<h1 id="gloveglobal-vectors-for-word-representation">Glove(Global Vectors for Word Representation)</h1>
<p>2014, Stanford
말뭉치 전체를 고려한 word embeding</p>

<h1 id="fasttext">FastText</h1>
<p>2016, Facebook
희소한 단어가 학습되지 않는 문제점을 해겼다. 다양한 용언을 가진 한국어의 특성에 잘 맞습니다.</p>

<h1 id="rnn">RNN</h1>
<p>시퀀스데이터 
history 전달</p>

<ul>
  <li>one to one -&gt; 이미지 분류</li>
  <li>one to many -&gt; 이미지로부터 문장 생성, 작곡</li>
  <li>many to one -&gt; 감성 분석, 생성 모델</li>
  <li>many to many -&gt; 기계 번역, 챗봇, Q&amp;A</li>
</ul>

<h1 id="lstm">LSTM</h1>
<p>새로운 입력을 어떻게 받을 것인지 forget gate, update gate, output gate 가 있수다.</p>

<h1 id="gru">GRU</h1>
<p>lstm의 gate 를 하나로 줄인것.</p>

<h1 id="sentiment-analysis">Sentiment Analysis</h1>

<h1 id="ner-개체-인식">NER (개체 인식)</h1>

<h1 id="language-model">Language Model</h1>
<ul>
  <li>이전으로부터 다음을 예측하기</li>
  <li>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  기계 번역
  Qna
  chatbot
  speech recognition
  text summarization
  text to speech(tts)
  image caption
</code></pre></div>    </div>
  </li>
</ul>

<h1 id="seq2seqencoder-decoder">Seq2Seq(Encoder-decoder)</h1>
<p>Machine Translate 분야에 사용된다.</p>

<h2 id="챗봇을-만들어보자">챗봇을 만들어보자.</h2>

<h2 id="기계-번역-평가-알고리즘">기계 번역 평가 알고리즘</h2>
<ul>
  <li>BLUE</li>
  <li></li>
</ul>

<h1 id="transformers">Transformers</h1>
<p>2017 - Transformer
현재 딥러닝은 트랜스포머 이전과 이후라 나뉩니다.</p>
<h1 id="transfer-learning-전이학습">Transfer Learning (전이학습)</h1>

<h1 id="elmo">ELMO</h1>
<ul>
  <li>마지막 RNN 모델ㅇ</li>
</ul>

<h1 id="bert">BERT</h1>
<p>2018 - Bert</p>

<h1 id="gpt">GPT</h1>
<p>2020 - GPT 3</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: 딥러닝 모니터링(Monintoring) 하기</title><link href="http://localhost:4000/aitech_knowledge/post-monitoring/" rel="alternate" type="text/html" title="Post: 딥러닝 모니터링(Monintoring) 하기" /><published>2023-03-09T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-monitoring</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-monitoring/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="monitoring">Monitoring</h1>
<p>학습을 하는 데 굉장히 긴 시간이 걸립니다. 학습 과정을 기록하는게 좋겠죠. <code class="language-plaintext highlighter-rouge">TensorBoard</code>와 <code class="language-plaintext highlighter-rouge">Weight &amp; Bias</code>를 이용해봅시다.</p>

<h1 id="tensorboard">Tensorboard</h1>
<ul>
  <li>scalar : metric 표시</li>
  <li>graph : 계산 그래프</li>
  <li>histogram : weight 분포</li>
  <li>image: 예측 값과 실게 값을 비교 표시</li>
  <li>mesh : 3d 형태의 데이터를 표현하는 도구</li>
</ul>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
import os
logs_base_dir = 'logs'
os.makedirs(logs_base_dir, exist_ok=True)

from torch.utils.tensorboard import SummaryWriter
import numpy as np

exp = f"{logs_base_dir}/ex3"
writer = SummaryWriter(exp)
for n_iter in range(100):
  writer.add_scalar('Loss/train', np.random.random(), n_iter)
  writer.add_scalar('Loss/test', np.random.random(), n_iter)
  writer.add_scalar('Accuracy/train', np.random.random(), n_iter)  
  writer.add_scalar('Accuracy/test', np.random.random(), n_iter)
writer.flush()

%load_ext tensorboard
%tensorboard --logdir {"logs"}

</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># 분포를 본다.

from torch.utils.tensorboard import SummaryWriter
import numpy as np
writer = SummaryWriter(logs_base_dir)
for i in range(10):
  x = np.random.random(1000)
  writer.add_histogram('distribution centers', x+i, i)
writer.close()

</code></pre></div></div>

<h1 id="weight--bias">Weight &amp; Bias</h1>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry></feed>