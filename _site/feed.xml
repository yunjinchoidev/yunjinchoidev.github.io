<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-21T11:50:05+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><entry><title type="html">ai tech - Day14</title><link href="http://localhost:4000/aitech_daily/post-day14/" rel="alternate" type="text/html" title="ai tech - Day14" /><published>2023-03-21T00:00:00+09:00</published><updated>2023-03-12T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day14</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day14/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[논문리뷰] Attention is all you need</title><link href="http://localhost:4000/paper/post-attention-is-all-you-need/" rel="alternate" type="text/html" title="[논문리뷰] Attention is all you need" /><published>2023-03-21T00:00:00+09:00</published><updated>0219-04-01T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-attention%20is%20all%20you%20need</id><content type="html" xml:base="http://localhost:4000/paper/post-attention-is-all-you-need/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<h1 id="attention-is-all-you-need"><code class="language-plaintext highlighter-rouge">Attention is All you need</code></h1>

<p>구글의 <code class="language-plaintext highlighter-rouge">Attention is All you</code> 논문을 통해 nlp 의 혁명이 일어났습니다.  기존의 rnn 모델은 attention 모델로 대체되었습니다.  왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠.</p>

<p>“Attention is All You Need”는 자연어 처리 및 기계 번역과 같은 sequence-to-sequence 작업을 위한 새로운 딥 러닝 아키텍처인 Transformer 모델을 소개한 획기적인 논문입니다. Transformer 모델의 주요 혁신은 self-attention 메커니즘으로 입력 시퀀스를 순차적이 아닌 병렬로 처리하여 더 빠른 훈련과 더 나은 성능을 제공합니다.</p>

<p>이 논문의 결과는 Transformer 모델이 WMT 2014 영어-독일어 및 영어-프랑스어 번역 작업을 포함한 여러 벤치마크 작업에서 기존의 최첨단 기술을 능가한다는 것을 보여주었습니다. 트랜스포머는 병렬화 가능한 아키텍처로 인해 기존의 순환 신경망(RNN) 및 컨볼루션 신경망(CNN)보다 훨씬 적은 계산 시간으로 이러한 결과를 달성했습니다. Transformer 모델의 성공은 NLP 연구의 패러다임 전환과 그 아키텍처를 기반으로 한 수많은 후속 모델 개발로 이어졌습니다.</p>

<h2 id="attention의-원리">Attention의 원리</h2>

<p>Transformer는 자연어 처리 및 기계 번역과 같은 시퀀스 간 작업을 위해 설계된 딥 러닝 아키텍처입니다. 핵심 원리는 입력 시퀀스의 효율적인 병렬 처리를 가능하게 하는 self-attention 메커니즘입니다. 다음은 Transformer 모델에 대한 자세한 설명입니다.</p>

<p>아키텍처: Transformer는 인코더와 디코더로 구성되며 둘 다 동일한 구조의 여러 레이어로 구성됩니다. 인코더는 입력 시퀀스를 처리하고 디코더는 출력 시퀀스를 생성합니다.</p>

<p>Self-Attention: Self-Attention 메커니즘을 사용하면 모델이 시퀀스의 각 요소의 중요성을 다른 요소와 비교하여 평가할 수 있으므로 거리에 관계없이 종속성을 캡처할 수 있습니다. 이 메커니즘은 확장된 내적 어텐션을 사용하여 구현됩니다. 이 어텐션은 쿼리, 키 및 값 벡터의 내적을 취하여 시퀀스의 각 단어에 대한 어텐션 점수를 계산한 다음 소프트맥스 함수를 사용하여 확률을 생성합니다.</p>

<p>Multi-Head Attention: 모델이 단어 사이의 여러 관계를 캡처할 수 있도록 self-attention 메커니즘이 병렬로 여러 번 적용되어 여러 개의 어텐션 헤드가 생성됩니다. 이러한 어텐션 헤드의 출력은 연결되어 선형 레이어를 통과하여 최종 다중 헤드 어텐션 출력을 생성합니다.</p>

<p>위치별 피드포워드 네트워크: 다중 헤드 어텐션 레이어 이후 입력 시퀀스의 각 위치는 위치별 피드포워드 네트워크(FFN)에 의해 독립적으로 처리됩니다. FFN은 사이에 ReLU 활성화 기능이 있는 두 개의 선형 계층으로 구성됩니다.</p>

<p>위치 인코딩: Transformer 모델에는 시퀀스에서 단어의 위치에 대한 고유한 지식이 없기 때문에 위치 인코딩이 입력 임베딩에 추가됩니다. 이러한 인코딩은 빈도가 다른 정현파 함수이므로 모델이 단어의 상대적 위치에 대한 정보를 캡처할 수 있습니다.</p>

<p>계층 정규화 및 잔여 연결: 다중 헤드 어텐션 및 FFN을 포함하여 Transformer의 각 하위 계층 다음에는 계층 정규화 및 잔여 연결이 있습니다. 이러한 기술은 훈련을 안정화하고 복잡한 패턴을 학습하는 모델의 능력을 향상시키는 데 도움이 됩니다.</p>

<p>인코더-디코더 주의: 디코더에는 인코더-디코더 주의라는 추가 주의 메커니즘이 있어 디코더가 출력 시퀀스를 생성하는 동안 입력 시퀀스의 관련 부분에 집중할 수 있습니다. 이 어텐션 레이어는 셀프 어텐션 메커니즘과 유사하게 작동하지만 인코더의 출력을 키 및 값 벡터로 사용합니다.</p>

<p>선형 레이어와 소프트맥스: 마지막 디코더 레이어의 출력을 선형 레이어와 소프트맥스 함수에 통과시켜 디코더의 최종 출력을 얻는다. softmax 함수는 출력을 대상 어휘에 대한 확률 분포로 변환합니다.</p>

<p>입력 시퀀스를 병렬로 처리하는 트랜스포머의 능력은 셀프 어텐션 메커니즘과 결합되어 기존의 RNN 및 CNN보다 더 효율적으로 장거리 종속성을 처리할 수 있습니다. 이로 인해 다양한 NLP 작업에 널리 채택되고 아키텍처를 기반으로 한 후속 모델이 개발되었습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Pytorch DataLoader DataSet</title><link href="http://localhost:4000/ai/post-Pytorch-DataLoader-DataSet/" rel="alternate" type="text/html" title="Pytorch DataLoader DataSet" /><published>2023-03-21T00:00:00+09:00</published><updated>2023-03-22T10:20:02+09:00</updated><id>http://localhost:4000/ai/post-Pytorch%20DataLoader%20DataSet</id><content type="html" xml:base="http://localhost:4000/ai/post-Pytorch-DataLoader-DataSet/"><![CDATA[<p align="center">
<img src="../../../image/ai.png" width="400" height="400" />
</p>

<h1 id="pytorch-dataloader-dataset">Pytorch DataLoader DataSet</h1>

<h2 id="옵션">옵션</h2>
<p>데이터 집합: 로드할 데이터 집합 개체를 지정하는 필수 인수입니다. 데이터 집합 개체는 torch.utils.data에서 파생된 클래스의 인스턴스여야 합니다.<strong>getitem</strong> 및 <strong>len</strong> 메서드가 구현된 데이터 세트.</p>

<p>배치_크기: 이 옵션 인수는 각 배치에서 로드하고 처리할 샘플 수를 정의합니다. 기본적으로 1(즉, 배치 없음)로 설정됩니다. 배치 크기가 클수록 교육 효율성이 향상될 수 있지만 메모리도 더 많이 필요합니다.</p>

<p>셔플: 이 선택적 부울 인수는 배치를 만들기 전에 데이터 집합을 섞을지 여부를 나타냅니다. 셔플링은 연속된 표본 간의 상관 관계를 줄임으로써 과적합을 방지하는 데 도움이 됩니다. 기본적으로 False로 설정됩니다.</p>

<p>샘플러: 이 옵션 인수를 사용하면 샘플러 개체를 사용하여 사용자 지정 샘플링 전략을 지정할 수 있습니다. torch.utils.data에서 파생된 클래스의 인스턴스여야 합니다.샘플러. 제공된 경우 샘플러가 샘플 순서를 정의하므로 shuffle 인수를 False로 설정해야 합니다.</p>

<p>num_workers: 이 옵션 인수는 데이터 로드에 사용할 하위 프로세스의 수를 지정합니다. 기본적으로 이 값은 0으로 설정되며, 이는 주 프로세스가 데이터를 로드함을 의미합니다. 작업자 수를 늘리면 데이터 로드 속도를 향상시킬 수 있지만 메모리 사용량도 증가할 수 있습니다.</p>

<p>collate_fn: 이 옵션 인수를 사용하면 개별 표본을 배치로 병합하는 사용자 정의 함수를 지정할 수 있습니다. 함수는 샘플 목록을 입력으로 가져가서 배치를 반환해야 합니다. 기본적으로 DataLoader는 torch.utils.data를 사용합니다.0번째 차원을 따라 텐서를 연결하는 _delocs.collate.default_collate.</p>

<p>핀_메모리: 이 선택적 부울 인수를 True로 설정하면 DataLoader가 고정 메모리(페이지 잠금 메모리)의 텐서를 할당하여 GPU를 사용할 때 전송 속도를 향상시킬 수 있습니다. 기본적으로 False로 설정됩니다.</p>

<p>drop_last: 이 선택적 부울 인수는 데이터 집합 크기를 배치 크기로 구분할 수 없는 경우 마지막 불완전한 배치를 삭제할지 여부를 나타냅니다. 기본적으로 False로 설정됩니다.</p>

<p>시간 초과: 이 선택적 인수는 작업자로부터 배치를 수집하기 위한 시간 초과 값(초)을 지정합니다. 기본적으로 0으로 설정되어 시간 초과가 없음을 의미합니다.</p>

<p>worker_init_fn: 이 옵션 인수를 사용하면 초기화 시 각 작업자 하위 프로세스에서 호출할 함수를 지정할 수 있습니다. 함수는 작업자 ID를 나타내는 단일 정수 인수를 사용해야 합니다.</p>

<h2 id="예시">예시</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from torch.utils.data import DataLoader

data_loader = DataLoader(
    dataset=my_dataset,
    batch_size=64,
    shuffle=True,
    num_workers=4,
    pin_memory=True,
    drop_last=True
)
</code></pre></div></div>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ai" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day13</title><link href="http://localhost:4000/aitech_daily/post-day13/" rel="alternate" type="text/html" title="ai tech - Day13" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-14T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day13</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day13/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Segmentation &amp;amp; Detection</title><link href="http://localhost:4000/ai/post-Segmentation-&-Detection/" rel="alternate" type="text/html" title="Segmentation &amp;amp; Detection" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-21T10:20:02+09:00</updated><id>http://localhost:4000/ai/post-Segmentation%20&amp;%20Detection</id><content type="html" xml:base="http://localhost:4000/ai/post-Segmentation-&amp;-Detection/"><![CDATA[<p align="center">
<img src="../../../image/ai.png" width="400" height="400" />
</p>

<h1 id="segmentation">Segmentation</h1>

<p>Segmentation는 미리 정의된 기준이나 특징에 따라 이미지나 비디오를 여러 영역 또는 세그먼트로 나누는 컴퓨터 비전 작업입니다. 분할의 목표는 이미지나 동영상에서 의미 있고 유용한 정보를 추출하여 사물인식, 장면이해, 자율주행 등 다양한 응용에 활용될 수 있도록 하는 것입니다.</p>

<p>세그멘테이션에는 시맨틱 세그먼테이션과 인스턴스 세그먼테이션의 두 가지 주요 유형이 있습니다. <code class="language-plaintext highlighter-rouge">시맨틱 분할에는 이미지 또는 비디오의 각 픽셀이 속한 개체 또는 영역을 기반으로 클래스 레이블을 할당하는 작업이 포함</code>됩니다. 예를 들어 거리 장면의 이미지에서 시맨틱 분할을 사용하여 각 픽셀에 “도로”, “하늘”, “자동차”, “나무” 등의 레이블을 지정할 수 있습니다. 각 픽셀에 대한 클래스 레이블뿐 아니라 동일한 클래스의 각 인스턴스를 서로 다른 세그먼트로 분리합니다. 예를 들어 군중 이미지에서 인스턴스 분할을 사용하여 각 사람을 별도의 세그먼트로 식별하고 레이블을 지정할 수 있습니다.</p>

<p>분할은 영역 기반 방법, 에지 기반 방법, 딥 러닝 기반 방법 등 다양한 기법을 사용하여 수행할 수 있습니다. 특히 딥 러닝 기반 방법은 많은 양의 데이터에서 복잡한 특징과 패턴을 학습할 수 있기 때문에 세분화 정확도와 효율성이 크게 향상되었습니다. 일부 인기 있는 딥 러닝 기반 분할 모델에는 U-Net, Mask R-CNN 및 FCN(Fully Convolutional Network)이 포함됩니다.</p>

<p>전반적으로 분할은 컴퓨터 비전에서 중요한 작업이며 의료 영상, 자율 주행 및 로봇 공학과 같은 분야에서 많은 실용적인 응용 프로그램이 있습니다.</p>

<ol>
  <li>OpenCV, scikit-image 및 MATLAB과 같은 이미지 처리 라이브러리 및 도구. 이러한 라이브러리는 임계값, 가장자리 감지 및 영역 성장과 같은 이미지 분할을 위한 다양한 기능과 알고리즘을 제공합니다.</li>
  <li>k-평균 클러스터링, 지원 벡터 머신(SVM), 랜덤 포레스트와 같은 기계 학습 알고리즘. 이러한 알고리즘은 특정 기능이나 특성을 기반으로 이미지의 픽셀을 클러스터링하거나 분류하는 데 사용할 수 있습니다.</li>
  <li>TensorFlow, PyTorch 및 Keras와 같은 딥 러닝 프레임워크. 이러한 프레임워크를 사용하면 U-Net, Mask R-CNN 및 FCN과 같은 분할 작업을 위한 심층 신경망의 교육 및 배포가 가능합니다.</li>
  <li>AWS, Google Cloud 및 Microsoft Azure와 같은 클라우드 컴퓨팅 플랫폼. 이러한 플랫폼은 대규모 데이터 세트를 처리하고 복잡한 세분화 모델을 실행하기 위한 확장 가능하고 비용 효율적인 컴퓨팅 리소스를 제공합니다.</li>
  <li>GPU 및 TPU와 같은 하드웨어 가속기. 이러한 액셀러레이터는 분할 모델의 계산 및 교육 속도를 크게 높여 보다 효율적이고 효과적으로 만듭니다.</li>
</ol>

<h1 id="detection">Detection</h1>

<p>RCNN, SPPNet, Fast R-CNN 및 YOLO는 모두 컴퓨터 비전에 사용되는 객체 감지 모델입니다. 각각에 대한 간략한 개요는 다음과 같습니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">RCNN(CNN 기능이 있는 지역):</code> RCNN은 물체 감지에 CNN(컨볼루션 신경망)을 사용한 최초의 모델 중 하나입니다. 먼저 선택적 검색 알고리즘을 사용하여 일련의 지역 제안을 생성한 다음 CNN을 사용하여 각 지역 제안에서 기능을 추출하는 방식으로 작동합니다. 마지막으로 <code class="language-plaintext highlighter-rouge">SVM</code>(Support Vector Machine)을 사용하여 각 제안을 개체 또는 배경으로 분류하고 경계 상자 회귀 모델을 사용하여 제안 위치를 세분화합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">SPPNet</code>(Spatial Pyramid Pooling Net): SPPNet은 가변 크기 입력 이미지를 활성화하기 위해 공간 피라미드 풀링을 사용하는 RCNN의 변형입니다. 즉, 크기를 조정하거나 자를 필요 없이 다양한 크기의 이미지에 대해 모델을 학습할 수 있습니다. SPPNet은 기능 맵을 크기가 다른 영역으로 나누고 각 영역 내에서 기능을 풀링하여 이를 달성합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">Fast R-CNN:</code> 빠른 R-CNN은 영역 제안 및 기능 추출 단계를 단일 네트워크로 결합하는 RCNN 및 SPPNet보다 개선된 것입니다. 이것은 모델을 이전 모델보다 더 빠르고 정확하게 만듭니다. Fast R-CNN은 또한 제안을 분류하기 위해 SVM 대신 소프트맥스 레이어를 사용하고 제안의 위치를 구체화하기 위해 바운딩 박스 회귀 레이어를 사용합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">YOLO(You Only Look Once): YOLO는 단일 신경망을 사용하여 이미지에 있는 객체의 클래스 확률과 경계 상자를 예측하는 실시간 객체 감지 모델입니다</code>. RCNN, SPPNet 및 Fast R-CNN과 달리 YOLO는 지역 제안을 사용하지 않습니다. 대신 <code class="language-plaintext highlighter-rouge">이미지를 그리드로 나누고 각 그리드 셀에 대한 클래스 확률과 경계 상자를 예측</code>합니다. 이로 인해 YOLO는 다른 모델보다 훨씬 빠르지만 작은 물체나 복잡한 모양의 물체를 감지하는 데는 정확하지 않을 수 있습니다.</li>
</ol>

<p>전반적으로 RCNN, SPPNet, Fast R-CNN 및 YOLO는 모두 컴퓨터 비전의 상당한 발전에 기여한 효과적인 객체 감지 모델입니다. 각 모델에는 고유한 강점과 약점이 있으며 모델 선택은 특정 애플리케이션 및 요구 사항에 따라 다릅니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ai" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[논문리뷰] Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)</title><link href="http://localhost:4000/paper/post-A-Brief-Historical-Review/" rel="alternate" type="text/html" title="[논문리뷰] Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-21T02:20:02+09:00</updated><id>http://localhost:4000/paper/post-A%20Brief%20Historical%20Review</id><content type="html" xml:base="http://localhost:4000/paper/post-A-Brief-Historical-Review/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<p><br /><br /><br /><br /></p>

<h1 id="deep-learnings-most-important-ideas---a-brief-historical-review2020">Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)</h1>
<p><br /><br /><br /><br /></p>

<h2 id="2012--alexnet">2012 – AlexNet</h2>

<p>AlexNet은 2012년 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 개발한 심층 컨볼루션 신경망(CNN<code class="language-plaintext highlighter-rouge">) 아키텍처다. 오류율은 15.3%로 두 번째로 좋은 모델보다 훨씬 뛰어나다.</code></p>

<p><code class="language-plaintext highlighter-rouge">AlexNet은 8개의 계층으로 구성되어 있다. 5개의 컨볼루션 계층과 3개의 완전 연결 계층이 있습니다. 이 네트워크는 ReLU(Rectified Linear Unit) 활성화 함수를 사용하여 시그모이드 또는 tanh와 같은 기존 활성화 함수에 비해 더 빠르게 훈련할 수 있습니다. 또한 AlexNet은 최대 풀링 계층, 로컬 응답 정규화(LRN) 및 드롭아웃 정규화를 사용하여 과적합을 방지합니다.</code></p>

<p><code class="language-plaintext highlighter-rouge">AlexNet의 성공은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 광범위한 컴퓨터 비전 작업을 위한 딥 러닝, 특히 CNN에 대한 관심의 물결을 촉발시켰습니다. 오늘날 AlexNet은 VGG, ResNet 및 Inception과 같은 고급 아키텍처를 위한 길을 닦은 기본 모델로 간주됩니다.</code></p>

<h2 id="2013--dqn">2013 – DQN</h2>

<p>DQN(Deep Q-Network)은 2013년 <code class="language-plaintext highlighter-rouge">DeepMind</code> 연구원들이 개발한 강화 학습 알고리즘입니다. 인기 있는 무모델 강화 학습 방법인 Q-러닝과 심층 신경망을 결합하여 원시에서 직접 학습할 수 있는 강력한 알고리즘을 만듭니다. 복잡한 환경의 픽셀 데이터. DQN은 여러 게임에서 인간 수준의 성능을 달성한 Atari 2600 게임에서 처음 시연되었습니다.</p>

<p><code class="language-plaintext highlighter-rouge">DQN의 주요 혁신은 주어진 상태에서 행동을 취하는 데 대한 예상되는 미래 보상을 예측하는 행동-가치 함수 또는 Q-함수를 추정하기 위한 함수 근사값으로 심층 신경망을 사용하는 것</code>입니다. DQN은 두 가지 주요 기술을 도입하여 강화 학습을 위한 심층 신경망 훈련에서 종종 발생하는 불안정성과 발산 문제를 해결합니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">경험 재생:</code> 순차적 경험에서 학습하는 대신 DQN은 경험(상태, 작업, 보상 및 다음 상태)을 재생 버퍼에 저장하고 훈련 중에 이 버퍼에서 임의의 미니 배치를 샘플링합니다. 이것은 연속 경험 간의 상관 관계를 깨고 보다 안정적인 학습으로 이어집니다.</li>
  <li><code class="language-plaintext highlighter-rouge">대상 네트워크:</code> DQN은 메인 네트워크의 가중치로 주기적으로 업데이트되는 별도의 대상 네트워크를 사용합니다. 이렇게 하면 지속적으로 변화하는 목표 값으로 인해 발생하는 진동 및 발산 가능성을 줄여 학습 프로세스를 안정화하는 데 도움이 됩니다.</li>
</ol>

<p>DQN은 Double DQN, Dueling DQN 및 Prioritized Experience Replay와 같은 많은 확장 및 개선 사항에 영감을 주어 심층 강화 학습 분야에서 영향력 있는 알고리즘이었습니다.</p>

<p>알파고를 만든 알고리즘 입니다.</p>

<h2 id="2014--encoderdecoder-adam">2014 – Encoder/Decoder, Adam</h2>

<p>인코더/디코더:</p>

<p><code class="language-plaintext highlighter-rouge">인코더-디코더 아키텍처는 특히 기계 번역, 텍스트 요약 및 이미지 캡션과 같은 시퀀스 간(seq2seq) 작업을 위한 딥 러닝에서 널리 사용되는 프레임워크</code>입니다. 아키텍처는 두 가지 주요 구성 요소로 구성됩니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">인코더</code>: <code class="language-plaintext highlighter-rouge">인코더는 입력 시퀀스를 처리하고 이를 고정 크기 컨텍스트 벡터 또는 잠재 표현으로 압축하는 신경망(일반적으로 RNN 또는 LSTM)입니다.</code> <code class="language-plaintext highlighter-rouge">이 벡터는 디코딩 프로세스에 필요한 입력 시퀀스에서 필수 정보를 캡처</code>합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">디코더</code>: 디코더는 인코더에서 <code class="language-plaintext highlighter-rouge">생성된 컨텍스트 벡터를 가져와 단계적으로 출력 시퀀스를 생성하는 또 다른 신경망(일반적으로 RNN 또는 LSTM)입니다.</code> 컨텍스트 벡터와 이전 예측을 기반으로 출력 시퀀스의 <code class="language-plaintext highlighter-rouge">다음 요소를 예측합니다.</code></li>
</ol>

<p>인코더-디코더 아키텍처는 디코더가 디코딩 프로세스 중에 입력 시퀀스의 특정 부분에 집중할 수 있게 하여 긴 시퀀스에서 성능을 향상시키는 어텐션 메커니즘과 결합되는 경우가 많습니다.</p>

<p>Adam(적응 모멘트 추정):</p>

<p>Adam은 2014년에 Diederik Kingma와 Jimmy Ba가 소개한 신경망의 기울기 기반 최적화를 위한 최적화 알고리즘입니다. 이것은 확률적 기울기 하강(SGD) 방법의 확장이며 각 매개변수에 대한 학습 속도를 개별적으로 조정하도록 설계되었습니다. <code class="language-plaintext highlighter-rouge">Adam은 그래디언트의 1차 모멘트(평균)와 2차 모멘트(비중심 분산)를 모두 계산하여 두 가지 인기 있는 적응형 학습 속도 기술인 AdaGrad 및 RMSProp의 이점을 결합</code>합니다.</p>

<p>Adam의 주요 기능은 다음과 같습니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">적응형 학습 속도</code>: Adam은 기울기의 첫 번째 및 두 번째 모멘트를 기반으로 각 매개변수에 대한 학습 속도를 조정하여 표준 SGD에 비해 더 빠른 수렴 및 개선된 일반화로 이어질 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">모멘텀</code>: Adam은 기울기의 지수 이동 평균을 사용하여 모멘텀을 통합하여 수렴을 가속화하고 최적화 환경에서 로컬 최소값 또는 안장 지점을 극복하는 데 도움이 될 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">편향 보정</code>: Adam은 모멘트가 0으로 편향될 수 있는 훈련 시작 시 첫 번째 및 두 번째 모멘트의 정확한 추정을 보장하기 위해 편향 수정 항을 포함합니다.</li>
</ol>

<p>Adam은 구현 용이성, 빠른 수렴, 다양한 신경망 아키텍처 및 문제에 대한 견고성으로 인해 딥 러닝에서 널리 사용되는 최적화 알고리즘이 되었습니다.</p>

<p>Adam 이 그냥 잘 나온다. (경험적)</p>

<h2 id="2015--gan-resnet">2015 – GAN, ResNet</h2>

<p>GAN(생성적 적대 신경망):</p>

<p>GAN은 2014년 <code class="language-plaintext highlighter-rouge">이안 굿펠로우(Ian Goodfellow)</code>와 그의 동료들이 소개한 생성 모델입니다. 두 개의 신경망인 생성기와 판별기로 구성되며 경쟁 환경에서 동시에 훈련됩니다. Generator는 합성 데이터 샘플을 생성하고 Discriminator는 실제 샘플과 생성된 샘플을 구별하는 방법을 학습합니다. 교육 과정은 현실적인 샘플을 생성하는 생성기의 능력과 <code class="language-plaintext highlighter-rouge">진짜와 가짜 샘플을 정확하게 식별하는 판별기의 능력을 향상시키는 것을 목표로</code> 합니다. <code class="language-plaintext highlighter-rouge">훈련이 진행됨에 따라 생성기는 점점 더 사실적인 샘플을 생성하는 능력이 향상되어 판별자가 실제 데이터와 가짜 데이터를 구별하기가 더 어려워집니다. GAN은 이미지 합성, 스타일 전송, 데이터 확장 및 도메인 적응을 포함한 다양한 응용 분야에서 널리 사용</code>되었습니다.</p>

<p>ResNet(잔차 네트워크):</p>

<p>ResNet은 2015년 Kaiming He와 그의 동료들이 소개한 심층 합성곱 신경망(CNN) 아키텍처입니다. 심층 신경망의 훈련을 방해하는 <code class="language-plaintext highlighter-rouge">기울기 소멸 문제를 해결하도록 설계</code>되었습니다. ResNet은 그라디언트가 네트워크를 통해 보다 효과적으로 흐를 수 있도록 <code class="language-plaintext highlighter-rouge">건너뛰기 연결 또는 바로가기 연결을 도입</code>했습니다. <code class="language-plaintext highlighter-rouge">이러한 연결은 블록의 입력과 출력 사이의 잔차 함수를 학습하는 잔차 블록을 생성합니다</code>. 이 아키텍처는 정확도를 유지하고 기울기 소실 문제를 완화하면서 <code class="language-plaintext highlighter-rouge">훨씬 더 깊은 네트워크(원본 논문에서 최대 152개 계층)의 교육을 가능하게 합니다</code>. <code class="language-plaintext highlighter-rouge">ResNet은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 다양한 컴퓨터 비전 작업에서 최첨단 결과를 달성했으며 딥 러닝 아키텍처의 수많은 변형 및 개선에 영감을 주었습니다.</code></p>

<h2 id="2016-">2016 –</h2>

<h2 id="2017--transformer">2017 – Transformer</h2>

<p><code class="language-plaintext highlighter-rouge">Attention is All you need</code></p>

<p>Transformer는 Vaswani 등이 도입한 신경망 아키텍처입니다. 2017년에 기계 번역과 같은 시퀀스 간 작업을 위해 설계되었습니다. 자가 주의 메커니즘을 사용하여 순환 신경망(RNN)의 한계를 극복하여 더 효율적인 병렬화와 장거리 종속성을 더 잘 처리할 수 있습니다. <code class="language-plaintext highlighter-rouge">트랜스포머는 인코더와 디코더로 구성되어 있으며 각각 여러 레이어의 자체 주의 및 피드포워드 하위 레이어가 있어 모델이 입력 및 출력 시퀀스의 요소 간의 복잡한 관계를 학습</code>할 수 있습니다.</p>

<blockquote>
  <p>Attention 구조를 이해하는 게 정말 중요하다.</p>

</blockquote>

<h2 id="2018--bert">2018 – Bert</h2>

<p>BERT (Bidirectional Encoder Representations from Transformers):</p>

<p>BERT는 2018년 Google에서 도입한 사전 학습된 Transformer 기반 언어 모델입니다. <code class="language-plaintext highlighter-rouge">양방향 컨텍스트를 사용</code>하여 레이블이 지정되지 않은 텍스트 데이터에서 풍부한 언어 표현을 학습함으로써 자연어 처리(NLP)에 혁명을 일으켰습니다. <code class="language-plaintext highlighter-rouge">BERT는 마스킹된 언어 모델링 및 다음 문장 예측 작업을 사용하여 대규모 비지도 데이터에 대해 사전 훈련</code>됩니다. 감정 분석 또는 명명된 엔터티 인식과 같은 특정 다운스트림 작업에서 <code class="language-plaintext highlighter-rouge">BERT를 미세 조정하면 상대적으로 최소한의 추가 교육으로 최첨단 성능</code>을 얻을 수 있습니다.</p>

<blockquote>
  <p>Find Tuning 의 시초</p>

</blockquote>

<h2 id="2019--big-language-modelsgpt-x">2019 – Big Language Models(GPT-X)</h2>

<p>GPT(Generative Pre-trained Transformer):
GPT는 OpenAI에서 개발한 일련의 Transformer 기반 언어 모델이며, GPT-3는 2021년 9월 제 지식 컷오프 당시 가장 강력한 최신 버전입니다. <code class="language-plaintext highlighter-rouge">GPT는 다음 단어를 예측하는 단방향 자동 회귀 접근 방식을 사용하여 훈련</code>됩니다. <code class="language-plaintext highlighter-rouge">이전 단어를 기반으로 순서대로. 방대한 양의 텍스트 데이터에 대해 사전 훈련된 GPT</code>는 <code class="language-plaintext highlighter-rouge">강력한 일반화 기능</code>을 나타내<code class="language-plaintext highlighter-rouge">며 텍스트 생성, 요약, 번역 및 질문 답변과 같은 다양한 NLP 작업에 대해 미세 조정할 수 있</code>습니다.</p>

<h2 id="2020--self-supervised-learning">2020 – Self-Supervised Learning</h2>

<p>Self-Supervised Learning 자기 지도 학습:
<code class="language-plaintext highlighter-rouge">자기 지도 학습은 모델이 명시적으로 레이블이 지정된 데이터를 사용하지 않고 데이터 자체에서 유용한 표현이나 기능을 학습하는 일종의 비지도 학습</code>입니다. 대신 문장에서 누락된 단어를 예측(마스킹된 언어 모델링)하거나 두 문장의 상대적 위치를 예측(다음 문장 예측)하는 등 데이터에서 감독 신호를 생성하도록 설계된 작업인 <code class="language-plaintext highlighter-rouge">프리텍스트 작업을 사용</code>합니다. 자기 지도 학습은 BERT 및 GPT와 같은 모델이 레이블이 지정되지 않은 방대한 양의 데이터에서 풍부하고 전송 가능한 표현을 학습할 수 있도록 하므로 딥 러닝, 특히 NLP에서 점점 인기를 얻고 있습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">컴퓨터 비전의 중요한 7가지 모델</title><link href="http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/" rel="alternate" type="text/html" title="컴퓨터 비전의 중요한 7가지 모델" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-21T10:20:02+09:00</updated><id>http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0%20%EB%B9%84%EC%A0%84%EC%9D%98%20%EC%A4%91%EC%9A%94%ED%95%9C%207%EA%B0%80%EC%A7%80%20%EB%AA%A8%EB%8D%B8</id><content type="html" xml:base="http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/"><![CDATA[<p align="center">
<img src="../../../image/ai.png" width="400" height="400" />
</p>

<h1 id="ai">ai</h1>
<h1 id="컴퓨터-비전의-중요한-7가지-모델">컴퓨터 비전의 중요한 7가지 모델</h1>

<p>컴퓨터 비전 분야에는 몇 가지 영향력 있는 모델과 아키텍처가 있으며, 그 중 다수는 이 분야를 발전시키는 데 중요한 역할을 했습니다. 다음은 7가지 중요한 모델입니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">LeNet-5:</code> 1990년대에 Yann LeCun이 개발한 LeNet-5는 필기 숫자 인식을 위해 설계된 선구적인 컨볼루션 신경망(CNN)입니다. 이는 많은 미래 CNN 아키텍처의 토대를 마련했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">AlexNet</code>: Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 만든 AlexNet은 2012 ImageNet Large Scale Visual Recognition Challenge(ILSVRC)에서 우승했습니다. 심층 CNN 아키텍처는 다른 모델을 훨씬 능가하여 컴퓨터 비전에서 딥 러닝의 전환점이 되었습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">VGGNet</code>: 옥스포드 대학의 Visual Geometry Group에서 개발한 VGGNet은 다중 컨벌루션 레이어가 있는 심층 아키텍처로 유명합니다. VGGNet은 2014 ILSVRC에서 2위를 차지했으며 여전히 다양한 컴퓨터 비전 작업의 벤치마크로 사용되고 있습니다.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">인셉션(GoogLeNet):</code> GoogLeNet으로도 알려진 인셉션은 2014년 Google의 연구원들이 소개했습니다. 매우 깊은 네트워크를 효율적으로 훈련할 수 있는 혁신적인 인셉션 모듈로 2014 ILSVRC에서 우승했습니다.</p>

    <p>Inception 블록은 이미지 인식 작업을 위해 컨벌루션 신경망에 사용되는 빌딩 블록입니다. Inception 블록의 주요 이점은 동일한 레이어 내에서 다양한 규모와 복잡성의 기능을 추출하고 결합하는 기능입니다.</p>

    <p>전통적으로 컨볼루션 신경망은 서로 다른 규모의 특징을 추출하기 위해 별도의 계층을 가지고 있어 더 많은 계산 리소스와 훈련 시간이 필요합니다. 인셉션 블록은 크기가 다른 여러 필터(1x1, 3x3, 5x5)를 사용하고 동일한 레이어 내에서 작업을 풀링하여 이를 보다 효율적으로 달성할 수 있습니다. 이를 통해 네트워크는 다양한 수준의 추상화에서 기능을 학습하고 추출할 수 있으며 동시에 모델을 교육하는 데 필요한 매개변수의 수를 줄일 수 있습니다.</p>

    <p>또한 Inception 블록 내에서 1x1 컨볼루션 필터를 사용하면 3x3 및 5x5 컨볼루션과 같이 계산 비용이 더 많이 드는 작업을 적용하기 전에 기능 맵의 채널 수를 줄임으로써 네트워크의 계산 비용을 줄이는 데 도움이 될 수 있습니다. 이 기술을 차원 축소라고 합니다.</p>

    <p>전반적으로 Inception 블록은 이미지 인식 작업에서 컨볼루션 신경망의 성능을 개선하는 동시에 훈련에 필요한 계산 비용과 매개변수 수를 줄이는 것으로 나타났습니다.</p>

    <p>인셉션 블록의 맥락에서 “인셉션”이라는 용어는 새로운 것을 시작하거나 처음부터 무언가를 만드는 아이디어를 의미합니다. Inception 블록은 신경망이 미리 정의된 필터나 손으로 만든 기능에 의존하지 않고 처음부터 다양한 규모와 복잡성의 기능을 학습하고 추출할 수 있도록 설계되었기 때문에 이 이름이 붙여졌습니다.</p>

    <p>인셉션 블록은 각 인형 안에 작은 인형이 들어 있는 러시아 인형의 아이디어에서 영감을 받았습니다. 마찬가지로 Inception 블록에는 필터 크기가 다른 더 작은 레이어와 더 큰 레이어 내부의 풀링 작업이 포함되어 있습니다.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ResNet</code>: Microsoft Research에서 개발한 ResNet(Residual Network)이 2015 ILSVRC에서 우승했습니다. 기울기 소실 문제를 겪지 않고 훨씬 더 깊은 네트워크(최대 152개 계층)를 훈련할 수 있는 잔류 연결(연결 건너뛰기)을 도입했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">YOLO</code>(You Only Look Once): YOLO는 Joseph Redmon, Santosh Divvala, Ross Girshick 및 Ali Farhadi가 만든 실시간 객체 감지 시스템입니다. 속도와 정확성으로 유명하여 실시간 응용 프로그램에 적합합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">Mask R-CNN</code>: Kaiming He, Georgia Gkioxari, Piotr Dollár 및 Ross Girshick이 소개한 Mask R-CNN은 Faster R-CNN 객체 감지 모델의 확장입니다. 분할 마스크를 예측하기 위한 분기를 추가하여 이미지 내에서 개체를 동시에 감지하고 분할하는 작업인 인스턴스 분할을 활성화합니다.</li>
</ol>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ai" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day12</title><link href="http://localhost:4000/aitech_daily/post-day12/" rel="alternate" type="text/html" title="ai tech - Day12" /><published>2023-03-19T00:00:00+09:00</published><updated>2023-03-13T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day12</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day12/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[논문리뷰] A Survey of the Usages of Deep Learning for Natural Language Processing(2017)</title><link href="http://localhost:4000/paper/post-surveyNLP/" rel="alternate" type="text/html" title="[논문리뷰] A Survey of the Usages of Deep Learning for Natural Language Processing(2017)" /><published>2023-03-19T00:00:00+09:00</published><updated>2023-03-20T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-surveyNLP</id><content type="html" xml:base="http://localhost:4000/paper/post-surveyNLP/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<p><br /><br /><br /><br /></p>

<h1 id="a-survey-of-the-usages-of-deep-learning-for-natural-language-processing">A Survey of the Usages of Deep Learning for Natural Language Processing</h1>

<p><br /><br /><br /><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>💡 2018년

1. Introduction
2. Fundamentals of Deep Learning and NLP
2.1 Deep Learning
2.2 Natural Language Processing
3. Deep Learning Architectures for NLP
3.1 Convolutional Neural Networks
3.2 Recurrent Neural Networks
3.3 Transformers
4. Use Cases of Deep Learning for NLP
4.1 Language Modeling
4.2 Sentiment Analysis
4.3 Text Classification
4.4 Machine Translation
4.5 Question Answering
5. Challenges and Future Directions
5.1 Challenges
5.2 Future Directions
6. Conclusion
7. References

</code></pre></div></div>

<ul>
  <li>1장
    <ul>
      <li>딥러닝에 대한 간략한 소개와 딥 러닝 아키텍처 및 방법에 대한 간략한 개요를 제공 (딥 러닝, 신경망, 자연어 처리, 컴퓨터 언어학, 기계 학습)</li>
      <li></li>
    </ul>
  </li>
  <li>
    <p>2장</p>

    <p># 2장</p>

    <ul>
      <li>딥 러닝 및 자연어 처리(NLP)의 기본 개념을 소개합니다. 이 장은 인공 신경망, 역전파 및 활성화 기능과 같은 딥 러닝 개념에 대한 개요로 시작</li>
      <li>이러한 개념을 텍스트 분류 및 감정 분석과 같은 NLP 작업에 어떻게 적용할 수 있는지 설명</li>
      <li>토큰화, 형태소 분석 및 불용어 제거와 같은 데이터 전처리 기술을 포함하여 NLP의 기본 사항을 다룹니다. 저자는 이러한 기술을 사용하여 텍스트 데이터를 딥 러닝 모델에 공급하기 전에 정리하고 사전 처리하는 방법을 설명</li>
      <li>데이터 전처리, 기능 추출 및 모델 훈련과 같은 NLP를 위한 일반적인 딥 러닝 파이프라인의 다양한 구성 요소를 설명</li>
      <li>저자는 컨볼루션 신경망(CNN) 및 순환 신경망(RNN)과 같은 NLP에 사용되는 일반적인 딥 러닝 아키텍처의 예를 제공</li>
      <li>
        <p>이 장에서는 주석이 달린 대량의 데이터가 필요하고 결과 모델을 해석하는 어려움과 같이 NLP에 딥러닝을 사용하는 것과 관련된 문제에 대해 논의하면서 결론을 내립</p>
      </li>
      <li>자연어 처리 분야는 컴퓨터 언어학이라고도 하며, 인간 언어를 이해하는 데 있어 실질적인 문제를 해결하기 위한 계산 모델과 프로세스의 엔지니어링을 포함한다</li>
      <li>핵심 영역은 자연적으로 발생하는 단어 간의 정량화 연관성을 강조하는 언어 모델링, 단어의 의미 있는 구성 요소의 분할 및 사용된 단어의 실제 발화 부분을 식별하는 형태학적 처리와 같은 근본적인 문제를 다룬다</li>
      <li>Currently, NLP is primarily a data-driven field using sta- tistical and probabilistic computations along with machine learning.</li>
      <li></li>
    </ul>
  </li>
  <li>3장</li>
  <li>4장</li>
  <li>5장 V. APPLICATIONS OF NATURAL LANGUAGE PROCESSING USING DEEP LEARNING
    <ul>
      <li><em>Information Retrieval</em>
        <ul>
          <li>기존 정보 검색 시스템을 ..</li>
          <li>맥아베니 외. [171] 사전 훈련된 두 가지 상황별 언어 모델인 ELMo [70]와 BERT [71]에서 쿼리 용어 표현을 추출하고, 표현을 사용하여 애드혹 문서 순위를 위해 기존의 3개의 경쟁 신경 순위 아키텍처를 보강했다. 그 중 하나는 DRMM [169]이다. 그들은 또한 BERT의 분류 벡터를 이러한 아키텍처와 결합하여 두 가지 접근법의 이점을 얻는 공동 모델을 제시했다. MacAveney의 CEDR(문서 랭킹을 위한 컨텍스트 임베딩)이라는 시스템은 이전 모델 세 가지 모두의 성능을 향상시켰고, BERT의 토큰 표현을 사용하여 최첨단 결과를 생성했습니다</li>
        </ul>
      </li>
      <li>Sentiment analysis
        <ul>
          <li></li>
        </ul>
      </li>
      <li>Machine translation</li>
      <li>Text classification</li>
      <li>Question answering</li>
      <li>Named entity recognition</li>
      <li>Summarization</li>
      <li>Conversational agents</li>
      <li>Text generation</li>
    </ul>
  </li>
  <li>V. CONCLUSIONS
    <ul>
      <li>자연어 처리(NLP)를 위한 딥 러닝 사용에 대한 개요를 제공하고 이 분야의 최근 진행 상황을 강조합니다. 딥 러닝 기술은 감정 분석, 기계 번역, 텍스트 분류 및 질문 답변과 같은 NLP 작업에서 큰 성공을 거두었습니다. 그러나 딥 러닝 모델의 해석 가능성 부족과 많은 양의 데이터 및 계산 리소스가 필요하다는 문제가 남아 있습니다. 이 논문은 복잡한 모델을 위한 고도로 전문화된 구성 요소를 개발하는 것보다 사전 교육 방법론에 더 많은 연구 노력을 기울여야 한다고 제안합니다. 또한 이 백서는 향후 작업이 보다 다양한 언어와 분석되지 않은 언어를 사용하는 NLP 모델의 유효성 검사로 향할 것을 권장합니다. 딥 러닝 모델은 데이터가 매우 부족하지만 사전 훈련 및 전이 학습이 매우 영향력 있는 역할을 수행하면서 컴퓨터 언어학의 표준이 될 것으로 예상됩니다. 마지막으로, 이 논문은 뉴로모픽 칩과 같은 계산 장비의 발전이 NLP의 지속적인 발전에 도움이 될 것이라고 제안합니다.</li>
      <li>매우 최근에는 인코더 및 종종 디코더로서 주의력을 동력으로 하는 <code class="language-plaintext highlighter-rouge">트랜스포머</code> 유닛의 스택이 NLP 필드의 풍부하고 다양한 지형에서 일관되게 우수한 결과를 생성했다.</li>
      <li>이 최종 관찰 이후, 복잡한 모델에서 마지막 성능 드롭을 짜내기 위해 고도로 전문화된 구성 요소를 개발하는 것보다 <code class="language-plaintext highlighter-rouge">사전 훈련 방법론에 더 많은 연구 노력을 기울이는 것이 유용</code>할 수 있다.</li>
      <li><strong><em>인간의 언어 능력이 우리의 감성의 한 부분에 불과하듯이, 언어 처리도 인공지능의 작은 한 부분에 불과하다.</em></strong> 이러한 구성 요소가 어떻게 상호 연관되어 있는지 이해하는 것은 보다 완벽한 AI 시스템을 구성하는 데 중요하며, 통합된 NLP 아키텍처를 만드는 것은 이러한 시스템을 현실화하기 위한 또 다른 단계이다.</li>
      <li>그러나 딥 러닝 모델의 해석 가능성 부족과 많은 양의 데이터 및 계산 리소스가 필요하다는 문제가 남아 있습니다.</li>
      <li>GPU 의 발전</li>
    </ul>
  </li>
</ul>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">전이학습</title><link href="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/" rel="alternate" type="text/html" title="전이학습" /><published>2023-03-18T00:00:00+09:00</published><updated>2023-03-18T23:09:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="전이학습">전이학습</h1>

<p>위키백과에 의하면 전이학습은 <code class="language-plaintext highlighter-rouge">한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식</code>을 말합니다.</p>

<p>전이 학습은 하나의 작업에 대해 훈련된 모델을 사용하여 다른 관련 작업의 성능을 향상시킬 수 있는 기계 학습 기술입니다. 전이 학습에서는 처음부터 시작하는 대신 사전 훈련된 모델을 새로운 작업의 시작점으로 사용합니다. 사전 훈련된 모델은 이미 대규모 데이터 세트에서 일반적인 기능을 학습했으며 이 지식을 새로운 작업으로 이전하여 정확도를 높이고 훈련에 필요한 데이터 양을 줄일 수 있습니다. 전이 학습은 모델이 사전 훈련 단계에서 더 큰 데이터 세트에서 얻은 지식을 활용할 수 있도록 하므로 새 작업에 사용 가능한 데이터가 제한적일 때 특히 유용합니다. 전이 학습은 자연어 처리, 컴퓨터 비전 및 기타 기계 학습 영역에서 널리 사용됩니다.</p>

<blockquote>
  <p>앤드류 응 曰 “지도학습 이후로 전이학습이 머신러닝에서 대세가 될 것이다.”</p>
</blockquote>

<p>전이학습은 사실 우리 인간들이 사용하는 학습법 중 하나입니다. 우리는 과거에 이런저런 문제들을 해결하면서 축적된 경험을 토대로 그것과 유사한 문제를 해결하지 않나요? 이것이 바로 전이학습의 본질입니다. <a href="https://bskyvision.com/entry/%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5transfer-learning-%EC%9E%AC%EB%B0%8C%EA%B3%A0-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0">[출처]</a></p>

<p>특히나 기계의 시각적 이해를 목표로 하는 컴퓨터 비전의 영역에서 전이 학습으로 수행된 모델들이 높은 성능을 보이고 있어 가장 많이 사용되는 방법 중에 하나입니다.</p>

<p>아래 캐글 노트북을 추천합니다. <code class="language-plaintext highlighter-rouge">Advanced Transfer Learning Starter Notebook</code> <a href="https://www.kaggle.com/code/aakashns/advanced-transfer-learning-starter-notebook/notebook">[링크]</a></p>

<h2 id="source-tasks에서-학습된-지식을-target-task-을-로-이전">“Source Tasks”에서 학습된 지식을 “Target Task” 을 로 이전</h2>

<h2 id="fine-tuning">“Fine-Tuning”</h2>

<h2 id="가중치-초기화-weight-initialization">가중치 초기화 (Weight Initialization)</h2>
<p><a href="https://reniew.github.io/13/">[출처]</a></p>

<p>가중치를 잘못 설정할 경우 기울기 소실 문제나 표현력의 한계를 갖는 등 여러 문제를 야기하게 된다. 또한 딥러닝의 학습의 문제가 non-convex 이기 때문에 초기값을 잘못 설정할 경우 local minimum에 수렴할 가능성이 커지게 됨.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) 초기값을 모두 0으로 설정
-&gt; 문제 가 있음
2) LeCun Initialization
3) Xavier Initialization
4) He Initialization
</code></pre></div></div>

<h1 id="ray">Ray</h1>
<p>Ray는 Distributed application을 만들기 위한 프레임워크로, 분산 컴퓨팅 환경에서 많이 사용합니다.</p>

<p>Ray를 사용한 전이 학습은 Ray 분산 컴퓨팅 프레임워크를 사용하여 전이 학습을 대규모 데이터 세트로 확장하는 기계 학습 기술입니다. Ray는 분산 애플리케이션 구축을 위한 인기 있는 오픈 소스 프레임워크이며 확장 가능한 기계 학습 파이프라인 구축을 위한 라이브러리 및 도구 세트를 제공합니다.</p>

<p>Ray를 사용한 전이 학습을 사용하면 사전 훈련된 모델이 클러스터의 여러 노드에 분산되고 분산 방식으로 새 데이터에 대해 모델을 미세 조정할 수 있습니다. 이를 통해 대규모 데이터 세트로 작업할 때 학습 시간이 단축되고 확장성이 향상됩니다.</p>

<p>Ray는 또한 하이퍼파라미터 튜닝을 위한 Ray Tune 및 분산 확률적 경사 하강을 위한 Ray SGD와 같은 전이 학습 작업을 위한 라이브러리 및 도구 세트를 제공합니다. 이러한 도구는 전이 학습 프로세스를 간소화하고 확장 가능한 고성능 기계 학습 모델을 보다 쉽게 ​​구축할 수 있도록 도와줍니다.</p>

<p>전반적으로 Ray를 사용한 전이 학습은 전이 학습을 대규모 데이터 세트로 확장하고 확장 가능한 기계 학습 파이프라인을 구축하기 위한 강력한 기술입니다. Ray는 분산 컴퓨팅의 성능을 활용하여 전이 학습 모델의 속도, 효율성 및 정확도를 개선하는 데 도움을 줄 수 있습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry></feed>