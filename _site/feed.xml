<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-24T23:06:22+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name></author><entry><title type="html">[ai tech 5기] [회고] 3주차를 보내며…</title><link href="http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8/" rel="alternate" type="text/html" title="[ai tech 5기] [회고] 3주차를 보내며…" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-13T06:20:02+09:00</updated><id>http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8</id><content type="html" xml:base="http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="3주차를-보내며">[3주차를 보내며]</h1>

<blockquote>
  <ul>
    <li>강의 정리
      <blockquote>

      </blockquote>
    </li>
    <li><a href="https://yunjinchoidev.github.io/aitech_knowledge/post-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EB%AA%A8%EB%93%A0%EA%B2%83-copy/">딥러닝 Basic 강의록 정리</a></li>
  </ul>
</blockquote>

<h1 id="5f">5F</h1>

<h2 id="사실-facts-">사실 (Facts) :</h2>

<p>이번주에는 딥러닝 기초 강좌와 data visualization 강의를 들었습니다. CNN, RNN, LSTM, Transfomer, GAN, matplotlib 을 배웠습니다. 이 모델들을 가지고 간단한 모델을
구현해보았습니다. matplotlib을 통해서 데이터를 visualization 을 해봤습니다. 좋습니다. 점점 많은 것을 배우고 있다는 것을 실감하고 있습니다. 양이 쌓이고 정리해야 할 내용은 산떠미 같이 늘어나고
있습니다.</p>

<p>팀원들과 코딩테스트 문제를 2문제씩 풀어가고 있습니다. 잘 진행되고 있어서 기분이 좋습니다. 이대로 8월 초까지 쭉 한다면 분명 좋은 결과가 있을거라고 믿습니다. 골드 1 까지 풀 수 있는 실력을 갖추게 된다면
어떨까요. 꽤 신날겁니다.</p>

<p>월요일에는 팀원들과 논문 리뷰를 진행했습니다. <code class="language-plaintext highlighter-rouge">A Survey of the Usages of Deep Learning for Natural Language Processing(2017)</code> 논문이었은데 NLP 역사의
개괄적인 내용과 NLP 의 활용 분야에 대한 survey 논문이었습니다. 저자는 최근에는 전이학습, Transfomer 가 대세이니 이것을 강조하고 있었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<p>최신 NLP 모델들에서 사용되고 있는 Transfomer 모델은 구조 자체가 꽤 이해하기 어려웠습니다. Self-Attention 과 Mulit-head Attention 개념, Encoder-Decoder,
Positional Encoding 쪽도 난해했습니다. 확률분포를 근사하는 모델을 만드는 GAN 도 수식적인 내용이 많았습니다.</p>

<p>이번주 마스터 클래스는 최성준 마스터님의 <code class="language-plaintext highlighter-rouge">가르치며 성장하기 (Teaching By Learning)</code>이라는 주제였습니다. 사실 누군가를 가르치며 배운다는 것은 되게 유명한 말입니다. 하지만 열린 마음으로 강연을
듣다 보니 다시 듣게 되더군요. 좋습니다. 그래서 저는 유튜브 채널을 개설했고 벌써 영상을 두 개 !
올렸씁니다. <a href="https://www.youtube.com/channel/UC7B4c49J4XFzoety13KYuDg">링크</a>. 두 개를 올렸는데 뭔가 남는 기분이 남아서 좋더군요. 구독자가 1명만 생겨도 재미있는
감정일 거 같습니다.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<p>하지만 이런 모형들이 내는 결과는 놀랍기만 합니다. 점점 인간의 인지 능력을 뛰어넘는 AI 는 이 모델로부터 나오기 때문이죠.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<p>코테 문제는 꾸준히 풀 문제입니다. 주말동안 다시 알고리즘 공부를 할 생각이고 다음 주에는 동료들에게 좋은 모습을 보여주고 싶습니다. 동시에 Transfomer, Word2Vec, GAN 에 대해서 공부를
해야겠네요. 논문을 좀 읽어야 겠습니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>잘 쉬어야 겠습니다.</p>]]></content><author><name>최윤진</name></author><category term="aitech_weekly" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[이코테]이코테 4장(구현)</title><link href="http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5-BFS-&-DFS/" rel="alternate" type="text/html" title="[이코테]이코테 4장(구현)" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-19T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5%20BFS%20&amp;%20DFS</id><content type="html" xml:base="http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5-BFS-&amp;-DFS/"><![CDATA[<h1 id="구현">구현</h1>

<p>구현이란 머릿속에 있는 알고리즘을 소스코드로 바꾸는 과정을 말합니다.
아이디어를 떠올리는 것은 쉽지만 코드로 바꾸는 것이 쉽지 않은 것이 구현 문제로 나온다. 결국 코드를 잘 만질 수 있는 능력이 있어야 한다는 소리다.</p>

<p>시뮬레이션, 구현, 완전 탐색은 유사한 부분이 많다.</p>

<p>일반적으로 전체 데이터 개수가 100만 개 이하일 때 완전 탐색을 사용하면 적절하다.</p>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[구현]]></summary></entry><entry><title type="html">[백준][3190][뱀]</title><link href="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/" rel="alternate" type="text/html" title="[백준][3190][뱀]" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-25T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-%5B%EB%B0%B1%EC%A4%80%5D%5B3190%5D%5B%EB%B1%80%5D</id><content type="html" xml:base="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/"><![CDATA[<p><img src="../../../image/ps.png" alt="paper.png" /></p>

<h1 id="해결-전략">해결 전략</h1>

<p>전형적인 시뮬레이션 문제입니다. 문제를 잘 읽고 step 을 구현합시다. 동서남북 이동과 방향이동에 주의합시다. 사과조건과 뱀의 trace 를 잘 표시해야 합니다.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/afC0h53Ib1o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br />
<br />
<br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import sys
input = sys.stdin.readline

N = int(input())
apple_cnt = int(input())

# 사과 표시하기
apple_map = [[False for i in range(N)] for j in range(N)]
for i in range(apple_cnt):
    r, c = list(map(int, input().split()))
    apple_map[r-1][c-1] = True

# 회전하기
turn_cnt = int(input())
turns = []
for i in range(turn_cnt):
    turns.append(list(map(str, input().split())))

# 뱀이 갈 수 있는 맵 선언
snake_able_map = [[True for i in range(N)] for j in range(N)]


turn_idx = 0
time = 0
row, col = 0, 0

# 동, 남, 서, 북
direction = [(0, 1), (1, 0), (0, -1), (-1, 0)]

direction_idx = 0

tail_row, tail_col = 0, 0

# 뱀이 현재 위치하고 있는 영역을 보관한 리스트
trace = []
turn_time = int(turns[turn_idx][0])
trace.append([0, 0])

while True:

    # 주어진 방향대로 일단 이동한다.
    nrow = row + direction[direction_idx][0]
    ncol = col + direction[direction_idx][1]

    # 유효성 검사 1) 이동할려는 칸이 밖이라면 break
    if nrow &lt; 0 or nrow &gt;= N or ncol &lt; 0 or ncol &gt;= N:
        time += 1
        break

    # 유효성 검사 2) 자기 몸을 밟는 지 확인한다.
    if not snake_able_map[nrow][ncol]:
        # print("G")
        time += 1
        break

    # 이제 이동해도 된다.


    # 새로운 머리 위치 snake_able_map 에 표시하고 이동할 위치를 trace 에 기록
    snake_able_map[nrow][ncol] = False
    trace.append([nrow, ncol])


    # 사과 먹었는지 확인한다.
    if apple_map[nrow][ncol] == True:
        # 사과 먹음 처리
        apple_map[nrow][ncol] = False
    else:

        # 사과를 안먹었다면 trace 에서 먼저 들어온것을 제거하고, 이제 갈 수 있는 영역이다.
        tail_row, tail_col = trace.pop(0)
        snake_able_map[tail_row][tail_col] = True


    # 실제 이동 처리
    row = nrow
    col = ncol
    time += 1

    # 이동까지 마치고 난 후 회전을 해야 한다면 회전한다.
    if time &lt;= int(turns[-1][0]):

        # 움직이는 지 확인 검사.
        if time == turn_time:
            # 시계방향
            if turns[turn_idx][1] == 'D':
                direction_idx = (direction_idx + 1) % 4

            # 반시계 방향
            if turns[turn_idx][1] == 'L':
                direction_idx = (direction_idx - 1) % 4

            if turn_idx &lt; len(turns)-1:
                turn_idx += 1
                turn_time = int(turns[turn_idx][0])

print(time)
</code></pre></div></div>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day15</title><link href="http://localhost:4000/aitech_daily/post-day15/" rel="alternate" type="text/html" title="ai tech - Day15" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-25T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day15</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day15/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[프로그래머스] 기둥과보</title><link href="http://localhost:4000/ps/post-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4/" rel="alternate" type="text/html" title="[프로그래머스] 기둥과보" /><published>2023-03-23T00:00:00+09:00</published><updated>2023-03-24T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-%5B%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4%5D%5B%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4%5D</id><content type="html" xml:base="http://localhost:4000/ps/post-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EA%B8%B0%EB%91%A5%EA%B3%BC%EB%B3%B4/"><![CDATA[<p><img src="../../../image/ps.png" alt="paper.png" /></p>

<h1 id="해결-전략">해결 전략</h1>

<p>is_normal 함수를 이용해서 정상성 여부를 검사한다. 수의 범위가 적으니 완전탐색으로 풀어도 되는 문제였다. 수가 적으면 완전탐색을 의심해봅시다.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/yEslpDMIoS0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br />
<br />
<br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def solution(n, build_frame):
    answer = [[]]
    
    
    update_map = set()
    
    def is_normal(update_map):
        
        for material in update_map:
            # 보 라면
            if material[2] == 1:                
                # 한쪽에라도 기둥이 있으면 된다.
                if (material[0], material[1]-1, 0) in update_map or\
                   (material[0]+1, material[1]-1, 0) in update_map :
                    continue
                # 양쪽에 보가 있으면 된다.
                if (material[0]-1, material[1], 1) in update_map and\
                    (material[0]+1, material[1], 1) in update_map:
                    continue

            
                return False
                
            # 기둥 이라면
            elif material[2] == 0:
                
                # 바닥이라면
                if material[1] == 0:
                    continue
                    
                # 아래에 기둥이 있다면
                if (material[0], material[1]-1, 0) in update_map:  
                    continue
                    
                # 양쪽에 보가 하나라도 있으면 된다.
                if (material[0]-1, material[1], 1) in update_map or\
                    (material[0], material[1], 1) in update_map:              
                    continue
                
                return False
                
            

        return True
                
    for frame in build_frame:

        if frame[3] == 1:
            update_map.add((frame[0], frame[1], frame[2]))

            if not is_normal(update_map):
                update_map.remove((frame[0], frame[1], frame[2]))

        # 삭제한다면
        if frame[3] == 0:

            update_map.remove((frame[0], frame[1], frame[2]))

            if not is_normal(update_map):
                update_map.add((frame[0], frame[1], frame[2]))              

                    
    r = []
    for f in update_map:
        r.append(list(f))
    r.sort(key=lambda x: (x[0], x[1], x[2]))
        
    answer = r
    return answer

</code></pre></div></div>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[연재][Clear Algo][1편] - 그리디 알고리즘</title><link href="http://localhost:4000/ps/post-ps_study_-%EC%97%B0%EC%9E%AC-clearAlgo-1%ED%8E%B8/" rel="alternate" type="text/html" title="[연재][Clear Algo][1편] - 그리디 알고리즘" /><published>2023-03-23T00:00:00+09:00</published><updated>2023-03-24T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-ps_study_%5B%EC%97%B0%EC%9E%AC%5D%20clearAlgo%20%5B1%ED%8E%B8%5D</id><content type="html" xml:base="http://localhost:4000/ps/post-ps_study_-%EC%97%B0%EC%9E%AC-clearAlgo-1%ED%8E%B8/"><![CDATA[<h1 id="연재clear-algo1편---그리디-알고리즘">[연재][Clear Algo][1편] - 그리디 알고리즘</h1>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[[연재][Clear Algo][1편] - 그리디 알고리즘]]></summary></entry><entry><title type="html">ai tech - Day14</title><link href="http://localhost:4000/aitech_daily/post-day14/" rel="alternate" type="text/html" title="ai tech - Day14" /><published>2023-03-23T00:00:00+09:00</published><updated>2023-03-24T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day14</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day14/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day13</title><link href="http://localhost:4000/aitech_daily/post-day13/" rel="alternate" type="text/html" title="ai tech - Day13" /><published>2023-03-22T00:00:00+09:00</published><updated>2023-03-23T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day13</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day13/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[논문리뷰] Attention is all you need</title><link href="http://localhost:4000/paper/post-attention-is-all-you-need/" rel="alternate" type="text/html" title="[논문리뷰] Attention is all you need" /><published>2023-03-21T00:00:00+09:00</published><updated>0219-04-01T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-attention%20is%20all%20you%20need</id><content type="html" xml:base="http://localhost:4000/paper/post-attention-is-all-you-need/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<h1 id="attention-is-all-you-need"><code class="language-plaintext highlighter-rouge">Attention is All you need</code></h1>

<p>구글의 <code class="language-plaintext highlighter-rouge">Attention is All you</code> 논문을 통해 nlp 의 혁명이 일어났습니다.  기존의 rnn 모델은 attention 모델로 대체되었습니다.  왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠.</p>

<p>“Attention is All You Need”는 자연어 처리 및 기계 번역과 같은 sequence-to-sequence 작업을 위한 새로운 딥 러닝 아키텍처인 Transformer 모델을 소개한 획기적인 논문입니다. Transformer 모델의 주요 혁신은 self-attention 메커니즘으로 입력 시퀀스를 순차적이 아닌 병렬로 처리하여 더 빠른 훈련과 더 나은 성능을 제공합니다.</p>

<p>이 논문의 결과는 Transformer 모델이 WMT 2014 영어-독일어 및 영어-프랑스어 번역 작업을 포함한 여러 벤치마크 작업에서 기존의 최첨단 기술을 능가한다는 것을 보여주었습니다. 트랜스포머는 병렬화 가능한 아키텍처로 인해 기존의 순환 신경망(RNN) 및 컨볼루션 신경망(CNN)보다 훨씬 적은 계산 시간으로 이러한 결과를 달성했습니다. Transformer 모델의 성공은 NLP 연구의 패러다임 전환과 그 아키텍처를 기반으로 한 수많은 후속 모델 개발로 이어졌습니다.</p>

<h2 id="attention의-원리">Attention의 원리</h2>

<p>Transformer는 자연어 처리 및 기계 번역과 같은 시퀀스 간 작업을 위해 설계된 딥 러닝 아키텍처입니다. 핵심 원리는 입력 시퀀스의 효율적인 병렬 처리를 가능하게 하는 self-attention 메커니즘입니다. 다음은 Transformer 모델에 대한 자세한 설명입니다.</p>

<p>아키텍처: Transformer는 인코더와 디코더로 구성되며 둘 다 동일한 구조의 여러 레이어로 구성됩니다. 인코더는 입력 시퀀스를 처리하고 디코더는 출력 시퀀스를 생성합니다.</p>

<p>Self-Attention: Self-Attention 메커니즘을 사용하면 모델이 시퀀스의 각 요소의 중요성을 다른 요소와 비교하여 평가할 수 있으므로 거리에 관계없이 종속성을 캡처할 수 있습니다. 이 메커니즘은 확장된 내적 어텐션을 사용하여 구현됩니다. 이 어텐션은 쿼리, 키 및 값 벡터의 내적을 취하여 시퀀스의 각 단어에 대한 어텐션 점수를 계산한 다음 소프트맥스 함수를 사용하여 확률을 생성합니다.</p>

<p>Multi-Head Attention: 모델이 단어 사이의 여러 관계를 캡처할 수 있도록 self-attention 메커니즘이 병렬로 여러 번 적용되어 여러 개의 어텐션 헤드가 생성됩니다. 이러한 어텐션 헤드의 출력은 연결되어 선형 레이어를 통과하여 최종 다중 헤드 어텐션 출력을 생성합니다.</p>

<p>위치별 피드포워드 네트워크: 다중 헤드 어텐션 레이어 이후 입력 시퀀스의 각 위치는 위치별 피드포워드 네트워크(FFN)에 의해 독립적으로 처리됩니다. FFN은 사이에 ReLU 활성화 기능이 있는 두 개의 선형 계층으로 구성됩니다.</p>

<p>위치 인코딩: Transformer 모델에는 시퀀스에서 단어의 위치에 대한 고유한 지식이 없기 때문에 위치 인코딩이 입력 임베딩에 추가됩니다. 이러한 인코딩은 빈도가 다른 정현파 함수이므로 모델이 단어의 상대적 위치에 대한 정보를 캡처할 수 있습니다.</p>

<p>계층 정규화 및 잔여 연결: 다중 헤드 어텐션 및 FFN을 포함하여 Transformer의 각 하위 계층 다음에는 계층 정규화 및 잔여 연결이 있습니다. 이러한 기술은 훈련을 안정화하고 복잡한 패턴을 학습하는 모델의 능력을 향상시키는 데 도움이 됩니다.</p>

<p>인코더-디코더 주의: 디코더에는 인코더-디코더 주의라는 추가 주의 메커니즘이 있어 디코더가 출력 시퀀스를 생성하는 동안 입력 시퀀스의 관련 부분에 집중할 수 있습니다. 이 어텐션 레이어는 셀프 어텐션 메커니즘과 유사하게 작동하지만 인코더의 출력을 키 및 값 벡터로 사용합니다.</p>

<p>선형 레이어와 소프트맥스: 마지막 디코더 레이어의 출력을 선형 레이어와 소프트맥스 함수에 통과시켜 디코더의 최종 출력을 얻는다. softmax 함수는 출력을 대상 어휘에 대한 확률 분포로 변환합니다.</p>

<p>입력 시퀀스를 병렬로 처리하는 트랜스포머의 능력은 셀프 어텐션 메커니즘과 결합되어 기존의 RNN 및 CNN보다 더 효율적으로 장거리 종속성을 처리할 수 있습니다. 이로 인해 다양한 NLP 작업에 널리 채택되고 아키텍처를 기반으로 한 후속 모델이 개발되었습니다.</p>

<h1 id="transformer">Transformer</h1>

<blockquote>
  <p>attention 은 입력 시퀀스의 일부에 선택적으로 집중하는 일반적인 메커니즘인 반면 transfomer는 입력 시퀀스를 보다 효율적이고 효과적으로 처리하기 위해 셀프 어텐션 메커니즘을 사용하는 특정 신경망 아키텍처입니다.</p>

</blockquote>

<blockquote>
  <p>Seq2seq는 기계 번역, 텍스트 요약 및 질문 응답과 같은 자연어 처리에서 시퀀스 간 작업에 사용되는 일종의 신경망 아키텍처입니다. seq2seq 아키텍처는 입력 시퀀스를 고정 길이 벡터로 인코딩하는 인코더와 인코딩된 벡터를 기반으로 출력 시퀀스를 생성하는 디코더의 두 가지 주요 부분으로 구성됩니다. seq2seq 아키텍처는 순환 신경망(RNN)을 사용하여 가변 길이 입력 및 출력 시퀀스를 처리</p>
</blockquote>]]></content><author><name>최윤진</name></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day12</title><link href="http://localhost:4000/aitech_daily/post-day12/" rel="alternate" type="text/html" title="ai tech - Day12" /><published>2023-03-21T00:00:00+09:00</published><updated>2023-03-22T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day12</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day12/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry></feed>