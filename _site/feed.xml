<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-19T22:43:57+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><entry><title type="html">[백준][14916] 거스름돈</title><link href="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90/" rel="alternate" type="text/html" title="[백준][14916] 거스름돈" /><published>2023-03-18T00:00:00+09:00</published><updated>2023-03-19T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90</id><content type="html" xml:base="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90/"><![CDATA[<p><img src="../../../image/ps.png" alt="paper.png" /></p>

<h1 id="해결-전략">해결 전략</h1>

<p>그리디 알고리즘으로 풉니다. 앞 사람과의 키차이를 <code class="language-plaintext highlighter-rouge">gabs</code>
라는 리스트에 저장해줍니다. 문제에서 요구하는 것은 최소 비용으로 M 개의 그룹을 만드는 것을 요구합니다. gab 리스트에서 특정 하나를 제거한다는 것은 그 구간을 통합한다는 개념이고 그룹 수를 하나 줄인다는 것입니다. (N-1 개의 갭이 있는 <code class="language-plaintext highlighter-rouge">gabs</code>는 M개의 그룹이 최초로 세팅되어 있다고 이해하면 됩니다.)</p>

<p>이런 아이디어로부터 <code class="language-plaintext highlighter-rouge">gabs</code> 리스트를 내림차순으로 정렬하고  M-1 부터 저장해주게 되면 최솟 값을 구할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import sys

input = sys.stdin.readline

N, M = map(int, input().split())
numbers = list(map(int, input().split()))

gabs = []

for i in range(1, len(numbers)):
    gabs.append(numbers[i]-numbers[i-1])

gabs.sort(reverse=True)

print(sum(gabs[M-1:]))
</code></pre></div></div>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ps" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">전이학습</title><link href="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/" rel="alternate" type="text/html" title="전이학습" /><published>2023-03-18T00:00:00+09:00</published><updated>2023-03-18T23:09:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="전이학습">전이학습</h1>

<p>위키백과에 의하면 전이학습은 <code class="language-plaintext highlighter-rouge">한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식</code>을 말합니다.</p>

<p>전이 학습은 하나의 작업에 대해 훈련된 모델을 사용하여 다른 관련 작업의 성능을 향상시킬 수 있는 기계 학습 기술입니다. 전이 학습에서는 처음부터 시작하는 대신 사전 훈련된 모델을 새로운 작업의 시작점으로 사용합니다. 사전 훈련된 모델은 이미 대규모 데이터 세트에서 일반적인 기능을 학습했으며 이 지식을 새로운 작업으로 이전하여 정확도를 높이고 훈련에 필요한 데이터 양을 줄일 수 있습니다. 전이 학습은 모델이 사전 훈련 단계에서 더 큰 데이터 세트에서 얻은 지식을 활용할 수 있도록 하므로 새 작업에 사용 가능한 데이터가 제한적일 때 특히 유용합니다. 전이 학습은 자연어 처리, 컴퓨터 비전 및 기타 기계 학습 영역에서 널리 사용됩니다.</p>

<blockquote>
  <p>앤드류 응 曰 “지도학습 이후로 전이학습이 머신러닝에서 대세가 될 것이다.”</p>
</blockquote>

<p>전이학습은 사실 우리 인간들이 사용하는 학습법 중 하나입니다. 우리는 과거에 이런저런 문제들을 해결하면서 축적된 경험을 토대로 그것과 유사한 문제를 해결하지 않나요? 이것이 바로 전이학습의 본질입니다. <a href="https://bskyvision.com/entry/%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5transfer-learning-%EC%9E%AC%EB%B0%8C%EA%B3%A0-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0">[출처]</a></p>

<p>특히나 기계의 시각적 이해를 목표로 하는 컴퓨터 비전의 영역에서 전이 학습으로 수행된 모델들이 높은 성능을 보이고 있어 가장 많이 사용되는 방법 중에 하나입니다.</p>

<p>아래 캐글 노트북을 추천합니다. <code class="language-plaintext highlighter-rouge">Advanced Transfer Learning Starter Notebook</code> <a href="https://www.kaggle.com/code/aakashns/advanced-transfer-learning-starter-notebook/notebook">[링크]</a></p>

<h2 id="source-tasks에서-학습된-지식을-target-task-을-로-이전">“Source Tasks”에서 학습된 지식을 “Target Task” 을 로 이전</h2>

<h2 id="fine-tuning">“Fine-Tuning”</h2>

<h2 id="가중치-초기화-weight-initialization">가중치 초기화 (Weight Initialization)</h2>
<p><a href="https://reniew.github.io/13/">[출처]</a></p>

<p>가중치를 잘못 설정할 경우 기울기 소실 문제나 표현력의 한계를 갖는 등 여러 문제를 야기하게 된다. 또한 딥러닝의 학습의 문제가 non-convex 이기 때문에 초기값을 잘못 설정할 경우 local minimum에 수렴할 가능성이 커지게 됨.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) 초기값을 모두 0으로 설정
-&gt; 문제 가 있음
2) LeCun Initialization
3) Xavier Initialization
4) He Initialization
</code></pre></div></div>

<h1 id="ray">Ray</h1>
<p>Ray는 Distributed application을 만들기 위한 프레임워크로, 분산 컴퓨팅 환경에서 많이 사용합니다.</p>

<p>Ray를 사용한 전이 학습은 Ray 분산 컴퓨팅 프레임워크를 사용하여 전이 학습을 대규모 데이터 세트로 확장하는 기계 학습 기술입니다. Ray는 분산 애플리케이션 구축을 위한 인기 있는 오픈 소스 프레임워크이며 확장 가능한 기계 학습 파이프라인 구축을 위한 라이브러리 및 도구 세트를 제공합니다.</p>

<p>Ray를 사용한 전이 학습을 사용하면 사전 훈련된 모델이 클러스터의 여러 노드에 분산되고 분산 방식으로 새 데이터에 대해 모델을 미세 조정할 수 있습니다. 이를 통해 대규모 데이터 세트로 작업할 때 학습 시간이 단축되고 확장성이 향상됩니다.</p>

<p>Ray는 또한 하이퍼파라미터 튜닝을 위한 Ray Tune 및 분산 확률적 경사 하강을 위한 Ray SGD와 같은 전이 학습 작업을 위한 라이브러리 및 도구 세트를 제공합니다. 이러한 도구는 전이 학습 프로세스를 간소화하고 확장 가능한 고성능 기계 학습 모델을 보다 쉽게 ​​구축할 수 있도록 도와줍니다.</p>

<p>전반적으로 Ray를 사용한 전이 학습은 전이 학습을 대규모 데이터 세트로 확장하고 확장 가능한 기계 학습 파이프라인을 구축하기 위한 강력한 기술입니다. Ray는 분산 컴퓨팅의 성능을 활용하여 전이 학습 모델의 속도, 효율성 및 정확도를 개선하는 데 도움을 줄 수 있습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day10</title><link href="http://localhost:4000/aitech_daily/post-day10/" rel="alternate" type="text/html" title="ai tech -Day10" /><published>2023-03-17T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day10</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day10/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day09</title><link href="http://localhost:4000/aitech_daily/post-day09/" rel="alternate" type="text/html" title="ai tech -Day09" /><published>2023-03-16T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day09</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day09/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day08</title><link href="http://localhost:4000/aitech_daily/post-day08/" rel="alternate" type="text/html" title="ai tech -Day08" /><published>2023-03-15T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day08</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day08/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>과제1, 과제 2을 풀었습니다. 강의와 <code class="language-plaintext highlighter-rouge">딥러닝 파이토치 교과서</code> 라는 책을 병행하면서 과제를 풀고 있습니다. 팀원들과 그리디 알고리즘 2 문제를 풀었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day07</title><link href="http://localhost:4000/aitech_daily/post-day07/" rel="alternate" type="text/html" title="ai tech -Day07" /><published>2023-03-14T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day07</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day07/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>파이토치 autograd, dataset, dataLoader 에 대해 공부했습니다. 구글링을 하지 않고 과제를 풀었습니다. 파이토치 공식 문서를 하루 종일 보면서 몇 문제를 남겨놓고 어찌어찌 풀긴 풀었습니다. 기분이 좋기도 하지만 그 과정이 너무 힘들었습니다. 지문이 상당히 많은데 복습하는데 시간을 써야 겠습니다. DataLoader 부분을 현재 풀고 있는데 좌절감이 듭니다. 하나부터 열까지 머리를 지끈지끈하게 합니다. 이런 노력의 결과가 피와 살이 될꺼라는 것을 알고 있지만 고통스럽네요.</p>

<p>오후 피어세션 동안은 팀원들과 [이것이 코딩 테스트다] 책의 <code class="language-plaintext highlighter-rouge">그리디 알고리즘</code> 을 풀었습니다. PR 방식으로 서로 코멘트를 남겨주는 방식으로 진행했는데요. 상당히 깔끔했습니다. 다들 열심히 풀었고 리뷰도 잘 해줘서 이대로 쭉 진행하면 큰 성장이 있을 것 같습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>
<p>결국 기본이 탄탄해야 합니다. 파이토치를 잘 할 수 있다는 것은 파이썬을 잘 다룬다는 것이고 수학적 지식이 탄단하다는 것입니다. 다음 딥러닝 구현 공부에 들어갈 때는 단단한 파이토치 실력이 있어야 겠지요. 실력은 하루 아침에 생기는 것이 아닙니다. 바닥 부터 천천히 쌓아나갈 때 <code class="language-plaintext highlighter-rouge">비로소 내가 해냈구나</code> 라는 감정이 들겠지요.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>
<p>꾸준함입니다. 결국 지금의 어려운 과제들도 시간을 들이면 풀 수 있다고 생각합니다. 활용 하기 위해선, 딥러닝을 내가 구축하기 위해선 이런 classic 한 것들을 잘 다룰 수 있어야 합니다.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>
<p>파이토치 강좌에 너무 연연하지 말고 순수 공부 시간을 늘려야 겠습니다. 좋은 강의 이지만 강의에 집중하다가는 지식을 제대로 못 쌓을 확률이 높습니다. 펜을 들고 공부해야 겠습니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>다시 드는 생각입니다. 체력 관리가 중요합니다. 오늘 따라 굉장히 피곤했습니다. 잘 쉬고 잘 공부해야 겠습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day06</title><link href="http://localhost:4000/aitech_daily/post-day06/" rel="alternate" type="text/html" title="ai tech - Day06" /><published>2023-03-13T00:00:00+09:00</published><updated>2023-03-14T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day06</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day06/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>파이토치 수업을 시작했습니다. 본격적인 딥러닝 구현을 들어가서 설렜습니다. 월요일 9시가 되고 과제를 열어보니 난이도가 꽤 있어서 걱정이 조금 되었습니다. 수요일 까지 최대한 빨리 끝내놓고 한 주의 마무리를 잘 해야 겠다는 다짐을 했습니다.</p>

<p>팀원들과 코딩테스트 스터디를 시작했습니다. [이것이 취업을 위한 코딩테스트다.] 라는 책으로 시작하게 되었는데요. 그리디 알고리즘 개념 공부와 함께 있는 3 문제를 같이 풀었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>
<p>강제로 코드를 치다 보니 손에 익는 것은 분명 있습니다. 파이토치 공부를 하면서 매번 눈으로만 배우는 습관을 가지고 있었는데 이번에는 마음을 다잡고 하나 하나 쳐가면서 공부를 하고 있습니다. 코드는 역시 쳐서 돌려봐야 내것이 되나 봅니다.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>
<p>pytoch를 사용하는 이유, 기초 사용법, Documentation 읽는 법 등을 배웠습니다.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>
<p>코딩테스트 문제는 하루에 2 문제 씩 계속 풀려고 합니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>휴식 시간을 잘 가져야겠습니다. 그리고 식사는 저녁까지 계속 굶다가 저녁에 한 끼만 먹는 것이 좋겠습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech 2주차</title><link href="http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/" rel="alternate" type="text/html" title="ai tech 2주차" /><published>2023-03-12T00:00:00+09:00</published><updated>2023-03-13T06:20:02+09:00</updated><id>http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8</id><content type="html" xml:base="http://localhost:4000/aitech_weekly/post-2%EC%A3%BC%EC%B0%A8/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="2주차-계획">[2주차 계획]</h1>
<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />텐서보드 튜토리얼 코드 돌리기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />WanB 튜토리얼 코드 돌려보기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />하이퍼 파라미터 튜닝 해보기</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />코테 스터디 잘 참여하기</li>
</ul>

<h1 id="2주차를-보내며">[2주차를 보내며]</h1>

<blockquote>
  <ul>
    <li>강의 정리
      <ul>
        <li><a href="https://yunjinchoidev.github.io/aitech_knowledge/post-pytorch/">파이토치 강의록 정리</a></li>
      </ul>
    </li>
  </ul>
</blockquote>

<p>벌써 2주의 시간이 흘렀습니다. 첫 주차에 파이썬, 딥러닝 수학을 배웠고 이번주엔 딥러닝을 실제 구현 할 수 있는 <code class="language-plaintext highlighter-rouge">파이토치</code> 를 배웠습니다. 파이토치의 기본적인 사용법, dataset, dataLoader 를 이용한 데이터 피딩 방법, <code class="language-plaintext highlighter-rouge">torch.module</code>, <code class="language-plaintext highlighter-rouge">torch.Parameter</code> 를 배웠고 <code class="language-plaintext highlighter-rouge">Tensorboard</code>, <code class="language-plaintext highlighter-rouge">Wandb</code> 등을 배습니다.</p>

<p>개념 자체는 그렇게 어렵지 않았습니다. 다만 문제는 그것을 응용하는 능력이었습니다. 이번 주 해결 해야 하는 과제는 pytorch 를 통해 모델을 구축할 수 있는 지, 데이터를 주입할 수 있는지, 전이 학습을 완성된 코드로 돌릴 수 있는지 여부였습니다.</p>

<p>쉽지 않았습니다. 구글링을 하지 않고 공식문서만 이용해서 풀어야 했기 때문에 깊은 인내가 필요했습니다. 하지만 5일의 시간을 투자해 pytorch 공식문서를 읽은 만큼 이해도 깊어졌다고 생각합니다.</p>

<p>팀원들과 코딩테스트 스터디를 시작했습니다. 하루에 두 문제를 풀고 PR을 올리면 동료들이 리뷰를 달아주고 피어세션 때 이야기를 나누는 방식으로 진행했습니다. 잘 진행이 되어서 이 방식을 5개월 동안 유지한다면 좋은 성과가 있을 거라고 생각합니다.</p>

<p>파이토치는 딥러닝 구현에 계속 사용되는 만큼 자유롭게 활용 할 수 있도록 손에 익혀야겠습니다. 일급 함수, OOP 등 파이썬에 대한 깊은 이해도 꼭 필요할 거 같습니다. 익숙하지 않으니 코드 짜는데 많은 시간이 소요되더군요.</p>

<p>이렇게 2주차가 지나갔습니다. 다음주에는 딥러닝 Basic 강의가 시작되는데요. 모델 구현을 직접 코드로 짜보고 데이터를 주입해 학습시켜봐야겠습니다. 4월에 시작되는 프로젝트가 굉장히 기대가 됩니다.</p>

<p>ps. AI 엔지니어와 AI 리서처 중 어떤 것을 하고 싶은지 선택하는 게 중요할 것 같습니다. 
저는 db, infra, workflow, mlOps 등을 다루고 싶은게 많아 AI 엔지니어가 끌리더군요.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_weekly" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day05</title><link href="http://localhost:4000/aitech_daily/post-day05/" rel="alternate" type="text/html" title="ai tech -Day05" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day05</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day05/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Attention is all you need</title><link href="http://localhost:4000/paper/post-attention-is-all-you-need/" rel="alternate" type="text/html" title="Attention is all you need" /><published>2023-03-10T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-attention%20is%20all%20you%20need</id><content type="html" xml:base="http://localhost:4000/paper/post-attention-is-all-you-need/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<h1 id="attention-is-all-you-need"><code class="language-plaintext highlighter-rouge">Attention is All you need</code></h1>

<h2 id="이-논문의-함의">이 논문의 함의!</h2>
<p>구글의 <code class="language-plaintext highlighter-rouge">Attention is All you</code> 논문을 통해 nlp 의 혁명이 일어났습니다. 
기존의 rnn 모델은 attention 모델로 대체되었습니다.
왜 이런 혁명이 일어났을 까요? 간단합니다. 뛰어난 성능 때문이죠.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry></feed>