<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-26T18:10:30+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name></author><entry><title type="html">자기만의 역사를 쓴다는 것</title><link href="http://localhost:4000/book/post-%EC%9E%90%EA%B8%B0%EB%A7%8C%EC%9D%98-%EC%97%AD%EC%82%AC%EB%A5%BC-%EC%93%B4%EB%8B%A4%EB%8A%94-%EA%B2%83/" rel="alternate" type="text/html" title="자기만의 역사를 쓴다는 것" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T10:20:02+09:00</updated><id>http://localhost:4000/book/post-%EC%9E%90%EA%B8%B0%EB%A7%8C%EC%9D%98%20%EC%97%AD%EC%82%AC%EB%A5%BC%20%EC%93%B4%EB%8B%A4%EB%8A%94%20%EA%B2%83</id><content type="html" xml:base="http://localhost:4000/book/post-%EC%9E%90%EA%B8%B0%EB%A7%8C%EC%9D%98-%EC%97%AD%EC%82%AC%EB%A5%BC-%EC%93%B4%EB%8B%A4%EB%8A%94-%EA%B2%83/"><![CDATA[<p>현재는 고인이 된 지의 거장, 다치바나 다카시의 책이다. 그는<code class="language-plaintext highlighter-rouge"> &lt;나는 이런 책을 읽어왔다&gt;, </code><도쿄대생은 바보가="" 되었는가="">` 등으로 한국에도 유명한 작가이다. 다치바나 다카시를 들어본 적있는 독자라면 매일 같이 읽고 쓰는 그의 괴물같은 독서력과 필력에 대해 잘 알것이다. 7만 권이 넘는 장서를 보관하고 있는 고양이 빌딩은 유명하다.</도쿄대생은></p>

<p><code class="language-plaintext highlighter-rouge">&lt;자기 역사를 쓴다는 것&gt;</code>은 2013년 출판된 책으로서 다치바나 다카시가 인생을 마무리하는 시점에서 쓴 책이다. 흔히 역사라고 하면 세계의 역사, 동아시아의 역사, 한 국가의 역사에 대해 생각하기 마련이다. 개인의 역사? 그것은 한 개인의 고유한 영역이 아니던가. 자서전을 쓰는 방법에 관한 것인가? 어찌보면 그렇게 볼 수 도 있겠다.</p>

<blockquote>
  <p>“나는 누구나 시니어 세대가 되면 한 번은 한 번은 자기 역사를 쓰는 일에 도전해 보아야 한다고 생각한다. 자기 역사를 쓰지 않으면 자기라는 인간에 대해서 제대로 이해하지 못하기 때문이다.(p.15)”</p>
</blockquote>

<p>다치바나 다카시는 자기 역사를 쓰는 작업은 환갑 정도의 나이가 적절하다고 말한다. 젊어서는 인생에 대해서 전체적인 조망을 할 수 없다. 하지만 나이가 60정도가 되면 자신이 어떤 선택을 하며 살아왔고 어떤 인생을 살아왔는지 얼핏 스스로 느끼게 된다. 이 때, 남은 인생을 새로운 인생을 살아가기 위해선 총체적 점검을 위한 작업으로서 ‘자기 역사를 쓰기’를 권하는 것이다.</p>

<p>젊은 나이의 독자에겐 이 책이 적절하지 않을 수 있다. 하지만 언젠가 나도 나만의 역사를 쓰는 날이 오겠구나라는 마음가짐을 얻는다는 생각으로 이 책을 읽는다면 소기의 성과를 얻을 수 있지 않을까. 나이가 있는 독자라면 책을 읽으며 자기의 역사를 직접 적는 기회가 되길 바란다.</p>

<p>책은 다치바나 다카시가 직접 자기 역사 쓰기 수업에 참여한 사람들의 수기를 살펴보며 자기 역사를 적어가는 과정에서 겪는 문제점들과 주의할 점, 유용한 팁에 대해 적고 있다. 트라우마에 대해선 조심스럽지만 자신의 인생을 재해석하는 과정에서 겪어야 할 하나의 아픔이며, 역사를 기술하는 과정에서 자신의 무의식의 아픔을 치유할 수 있을 거라고 말한다. 자기 역사 연표, 인간관계 클러스터 맵, 에피소드 수첩과 같은 실전팁도 보여주면서 어떻게 수강생들이 자기 역사를 기록하는 데 도움을 얻었는지에 대해서도 말하고 있다.</p>

<blockquote>
  <p>“자기자신이 자기 자신을 위해서 쓰는 것이 ‘자기 역사’이다(p.281)” 그 누구를 위해서 이 작업을 하는 게 아니다. 자신의 인생을 스스로 마무리하고 자신이 누구였고, 어떤 존재였는지, 어떤 인생을 살아왔는지에 대해 스스로 선명하게 파악하기 위해서이다. 실제 자기 역사를 적은 수 많은 사람들이 역사를 쓰고 있을 때 엄청난 몰입을 경험했다고 한다. 마성을 가진 작업이다. 자신의 기억에 완전히 빠져들어 오직 자신만이 아는 기억들을 적어내는 것. 그것이 바로 자기의 역사를 적는다는 것이다.</p>
</blockquote>

<p>다치바나 다카시는 개인의 역사에 더해 세계의 역사를 같이 기술해 나갈 것을 주문한다. 개인의 역사는 우주의 역사이다! 한 인간은 의식을 가지고 우주를 살아가는 고귀한 지적 유기체이다.</p>

<blockquote>
  <p>“세계는 만물의 집합체로서 존재하며, 동시에 동시대를 구성하는 많은 인간들이 공유하는 장대한 기억의 네트워크로서 존재하고 있다. 이 세계의 주요한 구성 요소를 장대한 전 인류적 기억의 네트워크가 존재한다. 한 인간이 죽으면 그 사람의 뇌가 담당하고 있던 장대한 세계 기억 네트워크의 해당 부분이 소멸하고 만다.(p.28)”</p>
</blockquote>

<p>반면 인간은 지구라는 행성에 갇혀 존재할 수 밖에 없다. 아무리 과학기술이 진보하더라도 1광년 이상을 이동할 수는 없을 것이다. 4차원의 관점에서 보았을 때 한 인간은 태양계 내부에서 기껏해봐야 130년을 살다가 죽을 것이 분명하다. 인간은 그렇게 하찮은 존재이다.</p>

<p>책의 마지막에선 인생의 스승으로서 내공있는 조언을 해주는 것으로 마무리한다.  인생이라는 싸움은 결코 단 한가지 길로만 정할 수 있는 것이 아니다. 자신은 성공한 수 많은 인생을 만나봤지만 그들이 행복하다고 보기에는 힘들었다. 오히려 포기할 것은 포기하고 자신이 원하는 것을 선택하고 그에 시간과 노력을 투자하면서 사는 인생이 오히려 행복한 인생이라고 생각한다. 그러니 경쟁에서 패배했다고 낙심하지 말고 새로운 게임을 계속해서 찾아 나가길 바란다.</p>

<blockquote>
  <p>“인생에서 진행되는 게임은 동시에 병행되기 때문에 하나의 게임에서 지더라도 다른 게임에서 이길 수 있는 기회가 항상 있다. 사실 대부분의 사람들이 그렇게 살고 있다는 것을 인식해야 한다. 뻔한 규칙에 질 것이 뻔해 보이는 게임은 서둘러 던져 버리고, 이길 수 있을 것 같은 다른 게임으로 이행하는 것이 인생에서 올바른 전략이라고 할 수 있다. 또 하나 올바른 전략은 이기고 지는 것으로 모든 일이 결정된다고 믿는 사람들의 인생 게임에서 하루 빨리 벗어나는 일이다. 이기고 지는 것에 그리 상관하지 않는다고 생각하는 사람들 쪽으로 이동하는 것이다(p.306)”</p>
</blockquote>]]></content><author><name>최윤진</name></author><category term="book" /><summary type="html"><![CDATA[현재는 고인이 된 지의 거장, 다치바나 다카시의 책이다. 그는 &lt;나는 이런 책을 읽어왔다&gt;, ` 등으로 한국에도 유명한 작가이다. 다치바나 다카시를 들어본 적있는 독자라면 매일 같이 읽고 쓰는 그의 괴물같은 독서력과 필력에 대해 잘 알것이다. 7만 권이 넘는 장서를 보관하고 있는 고양이 빌딩은 유명하다.]]></summary></entry><entry><title type="html">자연어 처리의 모든 것</title><link href="http://localhost:4000/aitech_knowledge/post-nlp/" rel="alternate" type="text/html" title="자연어 처리의 모든 것" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-nlp</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-nlp/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="자연어-처리의-모든-것">자연어 처리의 모든 것</h1>
<p>시작합니다.</p>]]></content><author><name>최윤진</name></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">MRC(Machine reading comprehension)</title><link href="http://localhost:4000/aitech_knowledge/post-mrc/" rel="alternate" type="text/html" title="MRC(Machine reading comprehension)" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-mrc</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-mrc/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="mrcmachine-reading-comprehension란">MRC(Machine reading comprehension)란?</h1>
<p>주어진 지문(context)를 이해하고 주어진 질의(Query/Question)의 답변을 추론하는 문제</p>

<p>Q&amp;A 분야에 응용될 수 있습니다.</p>

<h2 id="extractive-answer-datasets">Extractive Answer Datasets</h2>
<p>질의에 대한 답이 항상 주어진 지문의 segment (or span) 으로 존재</p>

<h2 id="descriptivenarrative-answer-datasets">Descriptive/Narrative Answer Datasets</h2>
<p>지문 내에서 추출한 span이 아닌, 질의를 보고 생성된 sentence (or free-form) 형태의 output을 내야하는 task</p>

<h2 id="multiple-choice-datasets">Multiple-choice Datasets</h2>
<p>질의에 대한 답을 여러 개의 answer candidates 중 하나로 고르는 형태의 task</p>

<p><br /><br /><br /><br /></p>

<h1 id="mrc-의-도전적-과제들">MRC 의 도전적 과제들</h1>
<h2 id="paraphrasing">Paraphrasing</h2>

<h2 id="coreference-resolution">Coreference Resolution</h2>

<h2 id="unanswerable-questions">Unanswerable questions</h2>
<h2 id="multi-hop-reasoning">Multi-hop reasoning</h2>
<ul>
  <li>여러 개의 document에서 질의에 대한 supporting fact를 찾아야지만 답을 찾을 수 있는 task</li>
</ul>]]></content><author><name>최윤진</name></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">KLUE</title><link href="http://localhost:4000/aitech_knowledge/post-klue/" rel="alternate" type="text/html" title="KLUE" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-klue</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-klue/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="목차">목차</h1>

<p>한국어 언어모델 학습 및 다중 과제 튜닝 과정
인공지능과 자연어 처리 (이론/실습)
자연어의 전처리 (이론/실습)
BERT 언어모델(1) (이론/실습)
BERT 언어모델(2) (이론/실습)
BERT 언어모델 기반의 단일 문장 분류 (이론/실습)
BERT 언어모델 기반의 두 문장 관계 분류 (이론/실습)
BERT 언어모델 기반의 문장 토큰 분류 (이론/실습)
GPT 언어모델 (이론/실습)
GPT 언어모델 기반의 자연어 생성 (이론/실습)
최신 자연어 처리 연구 (이론/실습)</p>

<p><br /><br /><br /><br /></p>

<h1 id="언어모델language-model">언어모델(Language Model)</h1>
<p>모델이란 무엇입니까?  현재로부터 미래를 예측하는 겁니다.  자연 법칙을 컴퓨터로 모사함으로써 시물레이션 가능하겠죠.  같은방식으로 이전 상태를 기반으로 미래의 상태 예측 가능합니다. 검색어 자동 추천
최초의 언어모델 -&gt; 마르코프 -&gt; RNN -&gt; Seq2Seq -&gt; Attention -&gt; self Attention</p>

<p><br /><br /><br /><br /></p>

<h1 id="자연어-전처리">자연어 전처리</h1>
<ul>
  <li>목표(Task) 설계</li>
  <li>필요 데이터 수직</li>
  <li>통계학적 분석</li>
  <li>전처리</li>
  <li>Tagging - 라벨 달아 주기</li>
  <li>Tokenizing - 문장 쪼개기</li>
  <li>모델 설계</li>
  <li>모델 구현</li>
  <li>성능 평가</li>
</ul>

<p>자연어 전처리를 잘하기 위해서는 python string 함수를 잘 사용할 수 있어야 합니다.</p>

<h2 id="실전">실전</h2>
<p>newpaper3 라이버리를 쓰시살.</p>

<p><br /><br /><br /><br /></p>

<h1 id="bert-언어모델">BERT 언어모델</h1>

<p><br /><br /><br /><br /></p>

<h1 id="gpt-언어모델과-최신-연구">GPT 언어모델과 최신 연구</h1>

<h1 id="최신-연구">최신 연구</h1>
<h2 id="멀티-모달">멀티 모달</h2>

<table>
  <thead>
    <tr>
      <th style="text-align: center">AI</th>
      <th style="text-align: center">인간지능</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">pre-training</td>
      <td style="text-align: center">유전체</td>
    </tr>
    <tr>
      <td style="text-align: center">fine-tuning</td>
      <td style="text-align: center">한 인간의 삶</td>
    </tr>
  </tbody>
</table>]]></content><author><name>최윤진</name></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">컴퓨터 비전의 모든 것</title><link href="http://localhost:4000/aitech_knowledge/post-cv/" rel="alternate" type="text/html" title="컴퓨터 비전의 모든 것" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-cv</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-cv/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="컴퓨터-비전의-역사">컴퓨터 비전의 역사</h1>
<p>딥러닝은 빠르게 변하는 분야이기 때문에 손 놓고 남들이 해놓은 자료만 보려고 하다가는 뒤쳐지게 됩니다. 우리는 영어에 익숙해져야 합니다. 거꾸로 돌려져있는 인간의 초상화 를 본 적 있습니까. 우리는 거꾸로 뒤집힌 인간의 얼굴을 올바르게 보는 능력을 가지고 있지 않습니다. 결국 인간도 편향적으로 학습이 된 것이죠.</p>

<p>컴퓨터 비전은 많은 곳에서 쓰이고 있습니다. 객체 탐지(by semantic segmentation), 그림 생성, cctv 등이 있죠. 이러한 성과는 딥러닝을 이용한 컴퓨터 비전에 따라 굉장한 성능 향상에 따라 그렇습니다. 그 전에는 사람이 일일이 특성을 잡아내는 일을 해서 인식을 했답니다.</p>

<ul>
  <li>매의 눈
    <ul>
      <li>모든 것을 확실하게 분류하는 이상적 모델</li>
    </ul>
  </li>
  <li>MLU
    <ul>
      <li>착오의 한계</li>
    </ul>
  </li>
  <li>CNN</li>
  <li>AlexNet : 굉장한 발전</li>
  <li>VGGNET : 작은 컨볼루션 신경망을 사용함으로써 일반화를 만들어냈다.</li>
  <li>GOOGLE NET :</li>
  <li>ResNet</li>
</ul>

<h1 id="데이터-부족-문제">데이터 부족 문제</h1>
<h2 id="data-argumentation">Data Argumentation</h2>
<p>인간이 촬영한 사진은 문제가 있습니다. 편향이 담겼기 때문이죠. 그렇다면 데이터에 bias가 존재하는 것이 왜 문제가 될까요?
그것은 정확한 정보가 아니기 때문이죠. 우리는 다양한 방법을 통해 bias 를 제거하고 성능을 향상 시킬 수 있습니다. 이런 방법들을 통해 부족한 데이터를 생성시키는 것이죠.</p>

<p>우리는 데이터를 학습시킬 때 상하 좌우를 바꿉니다.  특정 부분을 확대해서 학습시키기도 한다. affine transform 을 적용 시켜줄 수 도 있다.(대응 쌍을 줍니다) cutmix 방법도 있습니다. 두개의 물체의 상반신을 조합해서 학습을 시키는 방법이죠. 아래  추가적인 방법을 인식하세요 ㅣ</p>

<p>identify
rotate
posterize
sharpness
traslate-x
autoContrast
solarize
contrast
shear-x</p>

<h2 id="pre-trained">pre-trained</h2>
<p>Transfer Learning 한 데이터셋에서 학습하며 배웠던 지식을 다른 데이터셋에서 활용하는 기술 -&gt; 데이터 부족 문제를 해결합니다.</p>

<h1 id="또-다른-발전">또 다른 발전</h1>
<ul>
  <li>
    <p>과연 네트워크를 단순히 깊게 쌓는다고 해서 무조건 성능이 향상될까
Gradient Vanishing/Exploding 문제 발생</p>
  </li>
  <li>GoogLeNet</li>
  <li>ResNet
    <ul>
      <li>Skip Connection 을 도입</li>
    </ul>
  </li>
  <li>DenseNet</li>
  <li>SENet</li>
  <li>EfficientNet</li>
  <li>Deformable Convolution</li>
</ul>

<h1 id="segmantation--detection">Segmantation &amp; Detection</h1>

<ul>
  <li>
    <p>Object Detection
오브젝트 탐지 문제는 컴퓨터 비전 분야에서 굉장히 활발한 분야다.</p>
  </li>
  <li>
    <p>R-CNN</p>
  </li>
  <li>
    <p>YOLO</p>
  </li>
  <li>
    <p>SSD</p>
  </li>
  <li>
    <p>Focal Loss</p>
  </li>
  <li>
    <p>RetinaNet</p>
  </li>
  <li>
    <p>DETR</p>
  </li>
</ul>

<h1 id="cnn-visualization">CNN Visualization</h1>
<ul>
  <li>CNN Visualization이라는 것을 말그대로 Convoultional Neural Network를 시각화한다는 뜻</li>
  <li></li>
</ul>

<h1 id="filter-weight-visualization">Filter Weight Visualization</h1>

<h1 id="instance-segmentation">Instance Segmentation</h1>
<p>단순히 픽셀 마다의 클래스를 분류하는 semantic segmentation은 동일한 클래스에 속하는 개별 물체를 구분하지 못합니다. 이와 달리 Instance Segmentation은 영상 내에 동일한 물체가 여러 개 존재하는 경우에 각각의 물체를 구분하며 동시에 픽셀 단위의 mask도 예측하는 방법</p>

<h1 id="panoptic-segmentation">panoptic segmentation</h1>

<h2 id="panoptic-segmentation-1">Panoptic Segmentation</h2>

<h2 id="upsnet">UPSNet</h2>

<h2 id="vpsnet">VPSNet</h2>

<h2 id="landmark-localization">Landmark Localization</h2>

<h2 id="hourglass-network">Hourglass network</h2>

<h1 id="bounding-box가-아니라-키-포인트들을-기반으로-물체를-탐지하는-방법">bounding box가 아니라 키 포인트들을 기반으로 물체를 탐지하는 방법</h1>
<h2 id="cornernet">CornerNet</h2>
<h2 id="centernet">CenterNet</h2>

<h1 id="conditional-generative-model">Conditional Generative Model</h1>
<h2 id="generative-model">Generative Model</h2>
<h2 id="conditional-generative-model-1">Conditional Generative Model</h2>
<h2 id="generative-adversarial-networks-gan">Generative Adversarial Networks (GAN)</h2>
<h2 id="image-translation">Image Translation</h2>
<h2 id="super-resolution">Super Resolution</h2>]]></content><author><name>최윤진</name></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">recsys</title><link href="http://localhost:4000/aitech_knowledge/post-recsys/" rel="alternate" type="text/html" title="recsys" /><published>2023-03-26T00:00:00+09:00</published><updated>2023-03-27T06:20:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-recsys</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-recsys/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>]]></content><author><name>최윤진</name></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[이코테]이코테 5장(DFS &amp;amp; BFS)</title><link href="http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5-BFS-&-DFS/" rel="alternate" type="text/html" title="[이코테]이코테 5장(DFS &amp;amp; BFS)" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-25T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5%20BFS%20&amp;%20DFS</id><content type="html" xml:base="http://localhost:4000/ps/post-ps_study_%EC%9D%B4%EC%BD%94%ED%85%8C5%EC%9E%A5-BFS-&amp;-DFS/"><![CDATA[<h1 id="dfs--bfs">DFS &amp; BFS</h1>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[DFS &amp; BFS]]></summary></entry><entry><title type="html">[ai tech 5기] [회고] 3주차를 보내며…</title><link href="http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8/" rel="alternate" type="text/html" title="[ai tech 5기] [회고] 3주차를 보내며…" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-13T06:20:02+09:00</updated><id>http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8</id><content type="html" xml:base="http://localhost:4000/aitech_weekly/post-3%EC%A3%BC%EC%B0%A8/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="3주차를-보내며">[3주차를 보내며]</h1>

<blockquote>
  <ul>
    <li>강의 정리
      <blockquote>

      </blockquote>
    </li>
    <li><a href="https://yunjinchoidev.github.io/aitech_knowledge/post-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%98-%EB%AA%A8%EB%93%A0%EA%B2%83-copy/">딥러닝 Basic 강의록 정리</a></li>
  </ul>
</blockquote>

<h1 id="5f">5F</h1>

<h2 id="사실-facts-">사실 (Facts) :</h2>

<p>이번주에는 딥러닝 기초 강좌와 data visualization 강의를 들었습니다. CNN, RNN, LSTM, Transfomer, GAN, matplotlib 을 배웠습니다. 이 모델들을 가지고 간단한 모델을
구현해보았습니다. matplotlib을 통해서 데이터를 visualization 을 해봤습니다. 좋습니다. 점점 많은 것을 배우고 있다는 것을 실감하고 있습니다. 양이 쌓이고 정리해야 할 내용은 산떠미 같이 늘어나고
있습니다.</p>

<p>팀원들과 코딩테스트 문제를 2문제씩 풀어가고 있습니다. 잘 진행되고 있어서 기분이 좋습니다. 이대로 8월 초까지 쭉 한다면 분명 좋은 결과가 있을거라고 믿습니다. 골드 1 까지 풀 수 있는 실력을 갖추게 된다면
어떨까요. 꽤 신날겁니다.</p>

<p>월요일에는 팀원들과 논문 리뷰를 진행했습니다. <code class="language-plaintext highlighter-rouge">A Survey of the Usages of Deep Learning for Natural Language Processing(2017)</code> 논문이었은데 NLP 역사의
개괄적인 내용과 NLP 의 활용 분야에 대한 survey 논문이었습니다. 저자는 최근에는 전이학습, Transfomer 가 대세이니 이것을 강조하고 있었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<p>최신 NLP 모델들에서 사용되고 있는 Transfomer 모델은 구조 자체가 꽤 이해하기 어려웠습니다. Self-Attention 과 Mulit-head Attention 개념, Encoder-Decoder,
Positional Encoding 쪽도 난해했습니다. 확률분포를 근사하는 모델을 만드는 GAN 도 수식적인 내용이 많았습니다.</p>

<p>이번주 마스터 클래스는 최성준 마스터님의 <code class="language-plaintext highlighter-rouge">가르치며 성장하기 (Teaching By Learning)</code>이라는 주제였습니다. 사실 누군가를 가르치며 배운다는 것은 되게 유명한 말입니다. 하지만 열린 마음으로 강연을
듣다 보니 다시 듣게 되더군요. 좋습니다. 그래서 저는 유튜브 채널을 개설했고 벌써 영상을 두 개 !
올렸씁니다. <a href="https://www.youtube.com/channel/UC7B4c49J4XFzoety13KYuDg">링크</a>. 두 개를 올렸는데 뭔가 남는 기분이 남아서 좋더군요. 구독자가 1명만 생겨도 재미있는
감정일 거 같습니다.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<p>하지만 이런 모형들이 내는 결과는 놀랍기만 합니다. 점점 인간의 인지 능력을 뛰어넘는 AI 는 이 모델로부터 나오기 때문이죠.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<p>코테 문제는 꾸준히 풀 문제입니다. 주말동안 다시 알고리즘 공부를 할 생각이고 다음 주에는 동료들에게 좋은 모습을 보여주고 싶습니다. 동시에 Transfomer, Word2Vec, GAN 에 대해서 공부를
해야겠네요. 논문을 좀 읽어야 겠습니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>잘 쉬어야 겠습니다.</p>]]></content><author><name>최윤진</name></author><category term="aitech_weekly" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day15</title><link href="http://localhost:4000/aitech_daily/post-day15/" rel="alternate" type="text/html" title="ai tech - Day15" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-25T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day15</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day15/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[백준][3190][뱀]</title><link href="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/" rel="alternate" type="text/html" title="[백준][3190][뱀]" /><published>2023-03-24T00:00:00+09:00</published><updated>2023-03-25T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-%5B%EB%B0%B1%EC%A4%80%5D%5B3190%5D%5B%EB%B1%80%5D</id><content type="html" xml:base="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%80-3190-%EB%B1%80/"><![CDATA[<p><img src="../../../image/ps.png" alt="paper.png" /></p>

<h1 id="해결-전략">해결 전략</h1>

<p>전형적인 시뮬레이션 문제입니다. 문제를 잘 읽고 step 을 구현합시다. 동서남북 이동과 방향이동에 주의합시다. 사과조건과 뱀의 trace 를 잘 표시해야 합니다.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/afC0h53Ib1o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p><br />
<br />
<br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import sys
input = sys.stdin.readline

N = int(input())
apple_cnt = int(input())

# 사과 표시하기
apple_map = [[False for i in range(N)] for j in range(N)]
for i in range(apple_cnt):
    r, c = list(map(int, input().split()))
    apple_map[r-1][c-1] = True

# 회전하기
turn_cnt = int(input())
turns = []
for i in range(turn_cnt):
    turns.append(list(map(str, input().split())))

# 뱀이 갈 수 있는 맵 선언
snake_able_map = [[True for i in range(N)] for j in range(N)]


turn_idx = 0
time = 0
row, col = 0, 0

# 동, 남, 서, 북
direction = [(0, 1), (1, 0), (0, -1), (-1, 0)]

direction_idx = 0

tail_row, tail_col = 0, 0

# 뱀이 현재 위치하고 있는 영역을 보관한 리스트
trace = []
turn_time = int(turns[turn_idx][0])
trace.append([0, 0])

while True:

    # 주어진 방향대로 일단 이동한다.
    nrow = row + direction[direction_idx][0]
    ncol = col + direction[direction_idx][1]

    # 유효성 검사 1) 이동할려는 칸이 밖이라면 break
    if nrow &lt; 0 or nrow &gt;= N or ncol &lt; 0 or ncol &gt;= N:
        time += 1
        break

    # 유효성 검사 2) 자기 몸을 밟는 지 확인한다.
    if not snake_able_map[nrow][ncol]:
        # print("G")
        time += 1
        break

    # 이제 이동해도 된다.


    # 새로운 머리 위치 snake_able_map 에 표시하고 이동할 위치를 trace 에 기록
    snake_able_map[nrow][ncol] = False
    trace.append([nrow, ncol])


    # 사과 먹었는지 확인한다.
    if apple_map[nrow][ncol] == True:
        # 사과 먹음 처리
        apple_map[nrow][ncol] = False
    else:

        # 사과를 안먹었다면 trace 에서 먼저 들어온것을 제거하고, 이제 갈 수 있는 영역이다.
        tail_row, tail_col = trace.pop(0)
        snake_able_map[tail_row][tail_col] = True


    # 실제 이동 처리
    row = nrow
    col = ncol
    time += 1

    # 이동까지 마치고 난 후 회전을 해야 한다면 회전한다.
    if time &lt;= int(turns[-1][0]):

        # 움직이는 지 확인 검사.
        if time == turn_time:
            # 시계방향
            if turns[turn_idx][1] == 'D':
                direction_idx = (direction_idx + 1) % 4

            # 반시계 방향
            if turns[turn_idx][1] == 'L':
                direction_idx = (direction_idx - 1) % 4

            if turn_idx &lt; len(turns)-1:
                turn_idx += 1
                turn_time = int(turns[turn_idx][0])

print(time)
</code></pre></div></div>]]></content><author><name>최윤진</name></author><category term="ps" /><summary type="html"><![CDATA[]]></summary></entry></feed>