<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-03-20T19:35:49+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Reinvent love! - Democratization of Love</title><subtitle>NLP 쪼렙입니다.</subtitle><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><entry><title type="html">Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)</title><link href="http://localhost:4000/paper/post-A-Brief-Historical-Review/" rel="alternate" type="text/html" title="Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-21T02:20:02+09:00</updated><id>http://localhost:4000/paper/post-A%20Brief%20Historical%20Review</id><content type="html" xml:base="http://localhost:4000/paper/post-A-Brief-Historical-Review/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<p><br /><br /><br /><br /></p>

<h1 id="deep-learnings-most-important-ideas---a-brief-historical-review2020">Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)</h1>
<p><br /><br /><br /><br /></p>

<h1 id="deep-learnings-most-important-ideas---a-brief-historical-review">Deep Learning’s Most Important Ideas - A Brief Historical Review</h1>

<h1 id="혁신들">혁신들</h1>

<h2 id="2012--alexnet">2012 – AlexNet</h2>

<p>AlexNet은 2012년 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 개발한 심층 컨볼루션 신경망(CNN<code class="language-plaintext highlighter-rouge">) 아키텍처다. 오류율은 15.3%로 두 번째로 좋은 모델보다 훨씬 뛰어나다.</code></p>

<p><code class="language-plaintext highlighter-rouge">AlexNet은 8개의 계층으로 구성되어 있다. 5개의 컨볼루션 계층과 3개의 완전 연결 계층이 있습니다. 이 네트워크는 ReLU(Rectified Linear Unit) 활성화 함수를 사용하여 시그모이드 또는 tanh와 같은 기존 활성화 함수에 비해 더 빠르게 훈련할 수 있습니다. 또한 AlexNet은 최대 풀링 계층, 로컬 응답 정규화(LRN) 및 드롭아웃 정규화를 사용하여 과적합을 방지합니다.</code></p>

<p><code class="language-plaintext highlighter-rouge">AlexNet의 성공은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 광범위한 컴퓨터 비전 작업을 위한 딥 러닝, 특히 CNN에 대한 관심의 물결을 촉발시켰습니다. 오늘날 AlexNet은 VGG, ResNet 및 Inception과 같은 고급 아키텍처를 위한 길을 닦은 기본 모델로 간주됩니다.</code></p>

<h2 id="2013--dqn">2013 – DQN</h2>

<p>DQN(Deep Q-Network)은 2013년 <code class="language-plaintext highlighter-rouge">DeepMind</code> 연구원들이 개발한 강화 학습 알고리즘입니다. 인기 있는 무모델 강화 학습 방법인 Q-러닝과 심층 신경망을 결합하여 원시에서 직접 학습할 수 있는 강력한 알고리즘을 만듭니다. 복잡한 환경의 픽셀 데이터. DQN은 여러 게임에서 인간 수준의 성능을 달성한 Atari 2600 게임에서 처음 시연되었습니다.</p>

<p><code class="language-plaintext highlighter-rouge">DQN의 주요 혁신은 주어진 상태에서 행동을 취하는 데 대한 예상되는 미래 보상을 예측하는 행동-가치 함수 또는 Q-함수를 추정하기 위한 함수 근사값으로 심층 신경망을 사용하는 것</code>입니다. DQN은 두 가지 주요 기술을 도입하여 강화 학습을 위한 심층 신경망 훈련에서 종종 발생하는 불안정성과 발산 문제를 해결합니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">경험 재생:</code> 순차적 경험에서 학습하는 대신 DQN은 경험(상태, 작업, 보상 및 다음 상태)을 재생 버퍼에 저장하고 훈련 중에 이 버퍼에서 임의의 미니 배치를 샘플링합니다. 이것은 연속 경험 간의 상관 관계를 깨고 보다 안정적인 학습으로 이어집니다.</li>
  <li><code class="language-plaintext highlighter-rouge">대상 네트워크:</code> DQN은 메인 네트워크의 가중치로 주기적으로 업데이트되는 별도의 대상 네트워크를 사용합니다. 이렇게 하면 지속적으로 변화하는 목표 값으로 인해 발생하는 진동 및 발산 가능성을 줄여 학습 프로세스를 안정화하는 데 도움이 됩니다.</li>
</ol>

<p>DQN은 Double DQN, Dueling DQN 및 Prioritized Experience Replay와 같은 많은 확장 및 개선 사항에 영감을 주어 심층 강화 학습 분야에서 영향력 있는 알고리즘이었습니다.</p>

<p>알파고를 만든 알고리즘 입니다.</p>

<h2 id="2014--encoderdecoder-adam">2014 – Encoder/Decoder, Adam</h2>

<p>인코더/디코더:</p>

<p><code class="language-plaintext highlighter-rouge">인코더-디코더 아키텍처는 특히 기계 번역, 텍스트 요약 및 이미지 캡션과 같은 시퀀스 간(seq2seq) 작업을 위한 딥 러닝에서 널리 사용되는 프레임워크</code>입니다. 아키텍처는 두 가지 주요 구성 요소로 구성됩니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">인코더</code>: <code class="language-plaintext highlighter-rouge">인코더는 입력 시퀀스를 처리하고 이를 고정 크기 컨텍스트 벡터 또는 잠재 표현으로 압축하는 신경망(일반적으로 RNN 또는 LSTM)입니다.</code> <code class="language-plaintext highlighter-rouge">이 벡터는 디코딩 프로세스에 필요한 입력 시퀀스에서 필수 정보를 캡처</code>합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">디코더</code>: 디코더는 인코더에서 <code class="language-plaintext highlighter-rouge">생성된 컨텍스트 벡터를 가져와 단계적으로 출력 시퀀스를 생성하는 또 다른 신경망(일반적으로 RNN 또는 LSTM)입니다.</code> 컨텍스트 벡터와 이전 예측을 기반으로 출력 시퀀스의 <code class="language-plaintext highlighter-rouge">다음 요소를 예측합니다.</code></li>
</ol>

<p>인코더-디코더 아키텍처는 디코더가 디코딩 프로세스 중에 입력 시퀀스의 특정 부분에 집중할 수 있게 하여 긴 시퀀스에서 성능을 향상시키는 어텐션 메커니즘과 결합되는 경우가 많습니다.</p>

<p>Adam(적응 모멘트 추정):</p>

<p>Adam은 2014년에 Diederik Kingma와 Jimmy Ba가 소개한 신경망의 기울기 기반 최적화를 위한 최적화 알고리즘입니다. 이것은 확률적 기울기 하강(SGD) 방법의 확장이며 각 매개변수에 대한 학습 속도를 개별적으로 조정하도록 설계되었습니다. <code class="language-plaintext highlighter-rouge">Adam은 그래디언트의 1차 모멘트(평균)와 2차 모멘트(비중심 분산)를 모두 계산하여 두 가지 인기 있는 적응형 학습 속도 기술인 AdaGrad 및 RMSProp의 이점을 결합</code>합니다.</p>

<p>Adam의 주요 기능은 다음과 같습니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">적응형 학습 속도</code>: Adam은 기울기의 첫 번째 및 두 번째 모멘트를 기반으로 각 매개변수에 대한 학습 속도를 조정하여 표준 SGD에 비해 더 빠른 수렴 및 개선된 일반화로 이어질 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">모멘텀</code>: Adam은 기울기의 지수 이동 평균을 사용하여 모멘텀을 통합하여 수렴을 가속화하고 최적화 환경에서 로컬 최소값 또는 안장 지점을 극복하는 데 도움이 될 수 있습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">편향 보정</code>: Adam은 모멘트가 0으로 편향될 수 있는 훈련 시작 시 첫 번째 및 두 번째 모멘트의 정확한 추정을 보장하기 위해 편향 수정 항을 포함합니다.</li>
</ol>

<p>Adam은 구현 용이성, 빠른 수렴, 다양한 신경망 아키텍처 및 문제에 대한 견고성으로 인해 딥 러닝에서 널리 사용되는 최적화 알고리즘이 되었습니다.</p>

<h2 id="2015--gan-resnet">2015 – GAN, ResNet</h2>

<p>GAN(생성적 적대 신경망):
GAN은 2014년 이안 굿펠로우(Ian Goodfellow)와 그의 동료들이 소개한 생성 모델입니다. 두 개의 신경망인 생성기와 판별기로 구성되며 경쟁 환경에서 동시에 훈련됩니다. Generator는 합성 데이터 샘플을 생성하고 Discriminator는 실제 샘플과 생성된 샘플을 구별하는 방법을 학습합니다. 교육 과정은 현실적인 샘플을 생성하는 생성기의 능력과 진짜와 가짜 샘플을 정확하게 식별하는 판별기의 능력을 향상시키는 것을 목표로 합니다. 훈련이 진행됨에 따라 생성기는 점점 더 사실적인 샘플을 생성하는 능력이 향상되어 판별자가 실제 데이터와 가짜 데이터를 구별하기가 더 어려워집니다. GAN은 이미지 합성, 스타일 전송, 데이터 확장 및 도메인 적응을 포함한 다양한 응용 분야에서 널리 사용되었습니다.</p>

<p>ResNet(잔여 네트워크):
ResNet은 2015년 Kaiming He와 그의 동료들이 소개한 심층 합성곱 신경망(CNN) 아키텍처입니다. 심층 신경망의 훈련을 방해하는 기울기 소멸 문제를 해결하도록 설계되었습니다. ResNet은 그라디언트가 네트워크를 통해 보다 효과적으로 흐를 수 있도록 건너뛰기 연결 또는 바로가기 연결을 도입했습니다. 이러한 연결은 블록의 입력과 출력 사이의 잔차 함수를 학습하는 잔차 블록을 생성합니다. 이 아키텍처는 정확도를 유지하고 기울기 소실 문제를 완화하면서 훨씬 더 깊은 네트워크(원본 논문에서 최대 152개 계층)의 교육을 가능하게 합니다. ResNet은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 다양한 컴퓨터 비전 작업에서 최첨단 결과를 달성했으며 딥 러닝 아키텍처의 수많은 변형 및 개선에 영감을 주었습니다.</p>

<h2 id="2016-">2016 –</h2>

<h2 id="2017--transformer">2017 – Transformer</h2>

<h2 id="2018--bert">2018 – Bert</h2>

<h2 id="2019--big-language-modelsgpt-x">2019 – Big Language Models(GPT-X)</h2>

<h2 id="2020--self-supervised-learning">2020 – Self-Supervised Learning</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Post: 컴퓨터 비전의 중요한 7가지 모델</title><link href="http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/" rel="alternate" type="text/html" title="Post: 컴퓨터 비전의 중요한 7가지 모델" /><published>2023-03-20T00:00:00+09:00</published><updated>2023-03-10T10:20:02+09:00</updated><id>http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0%20%EB%B9%84%EC%A0%84%EC%9D%98%20%EC%A4%91%EC%9A%94%ED%95%9C%207%EA%B0%80%EC%A7%80%20%EB%AA%A8%EB%8D%B8</id><content type="html" xml:base="http://localhost:4000/ai/post-%EC%BB%B4%ED%93%A8%ED%84%B0-%EB%B9%84%EC%A0%84%EC%9D%98-%EC%A4%91%EC%9A%94%ED%95%9C-7%EA%B0%80%EC%A7%80-%EB%AA%A8%EB%8D%B8/"><![CDATA[<p align="center">
<img src="../../../image/ai.png" width="400" height="400" />
</p>

<h1 id="ai">ai</h1>
<h1 id="컴퓨터-비전의-중요한-7가지-모델">컴퓨터 비전의 중요한 7가지 모델</h1>

<p>컴퓨터 비전 분야에는 몇 가지 영향력 있는 모델과 아키텍처가 있으며, 그 중 다수는 이 분야를 발전시키는 데 중요한 역할을 했습니다. 다음은 7가지 중요한 모델입니다.</p>

<ol>
  <li><code class="language-plaintext highlighter-rouge">LeNet-5:</code> 1990년대에 Yann LeCun이 개발한 LeNet-5는 필기 숫자 인식을 위해 설계된 선구적인 컨볼루션 신경망(CNN)입니다. 이는 많은 미래 CNN 아키텍처의 토대를 마련했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">AlexNet</code>: Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 만든 AlexNet은 2012 ImageNet Large Scale Visual Recognition Challenge(ILSVRC)에서 우승했습니다. 심층 CNN 아키텍처는 다른 모델을 훨씬 능가하여 컴퓨터 비전에서 딥 러닝의 전환점이 되었습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">VGGNet</code>: 옥스포드 대학의 Visual Geometry Group에서 개발한 VGGNet은 다중 컨벌루션 레이어가 있는 심층 아키텍처로 유명합니다. VGGNet은 2014 ILSVRC에서 2위를 차지했으며 여전히 다양한 컴퓨터 비전 작업의 벤치마크로 사용되고 있습니다.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">인셉션(GoogLeNet):</code> GoogLeNet으로도 알려진 인셉션은 2014년 Google의 연구원들이 소개했습니다. 매우 깊은 네트워크를 효율적으로 훈련할 수 있는 혁신적인 인셉션 모듈로 2014 ILSVRC에서 우승했습니다.</p>

    <p>Inception 블록은 이미지 인식 작업을 위해 컨벌루션 신경망에 사용되는 빌딩 블록입니다. Inception 블록의 주요 이점은 동일한 레이어 내에서 다양한 규모와 복잡성의 기능을 추출하고 결합하는 기능입니다.</p>

    <p>전통적으로 컨볼루션 신경망은 서로 다른 규모의 특징을 추출하기 위해 별도의 계층을 가지고 있어 더 많은 계산 리소스와 훈련 시간이 필요합니다. 인셉션 블록은 크기가 다른 여러 필터(1x1, 3x3, 5x5)를 사용하고 동일한 레이어 내에서 작업을 풀링하여 이를 보다 효율적으로 달성할 수 있습니다. 이를 통해 네트워크는 다양한 수준의 추상화에서 기능을 학습하고 추출할 수 있으며 동시에 모델을 교육하는 데 필요한 매개변수의 수를 줄일 수 있습니다.</p>

    <p>또한 Inception 블록 내에서 1x1 컨볼루션 필터를 사용하면 3x3 및 5x5 컨볼루션과 같이 계산 비용이 더 많이 드는 작업을 적용하기 전에 기능 맵의 채널 수를 줄임으로써 네트워크의 계산 비용을 줄이는 데 도움이 될 수 있습니다. 이 기술을 차원 축소라고 합니다.</p>

    <p>전반적으로 Inception 블록은 이미지 인식 작업에서 컨볼루션 신경망의 성능을 개선하는 동시에 훈련에 필요한 계산 비용과 매개변수 수를 줄이는 것으로 나타났습니다.</p>

    <p>인셉션 블록의 맥락에서 “인셉션”이라는 용어는 새로운 것을 시작하거나 처음부터 무언가를 만드는 아이디어를 의미합니다. Inception 블록은 신경망이 미리 정의된 필터나 손으로 만든 기능에 의존하지 않고 처음부터 다양한 규모와 복잡성의 기능을 학습하고 추출할 수 있도록 설계되었기 때문에 이 이름이 붙여졌습니다.</p>

    <p>인셉션 블록은 각 인형 안에 작은 인형이 들어 있는 러시아 인형의 아이디어에서 영감을 받았습니다. 마찬가지로 Inception 블록에는 필터 크기가 다른 더 작은 레이어와 더 큰 레이어 내부의 풀링 작업이 포함되어 있습니다.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">ResNet</code>: Microsoft Research에서 개발한 ResNet(Residual Network)이 2015 ILSVRC에서 우승했습니다. 기울기 소실 문제를 겪지 않고 훨씬 더 깊은 네트워크(최대 152개 계층)를 훈련할 수 있는 잔류 연결(연결 건너뛰기)을 도입했습니다.</li>
  <li><code class="language-plaintext highlighter-rouge">YOLO</code>(You Only Look Once): YOLO는 Joseph Redmon, Santosh Divvala, Ross Girshick 및 Ali Farhadi가 만든 실시간 객체 감지 시스템입니다. 속도와 정확성으로 유명하여 실시간 응용 프로그램에 적합합니다.</li>
  <li><code class="language-plaintext highlighter-rouge">Mask R-CNN</code>: Kaiming He, Georgia Gkioxari, Piotr Dollár 및 Ross Girshick이 소개한 Mask R-CNN은 Faster R-CNN 객체 감지 모델의 확장입니다. 분할 마스크를 예측하기 위한 분기를 추가하여 이미지 내에서 개체를 동시에 감지하고 분할하는 작업인 인스턴스 분할을 활성화합니다.</li>
</ol>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ai" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">A Survey of the Usages of Deep Learning for Natural Language Processing</title><link href="http://localhost:4000/paper/post-surveyNLP/" rel="alternate" type="text/html" title="A Survey of the Usages of Deep Learning for Natural Language Processing" /><published>2023-03-19T00:00:00+09:00</published><updated>2023-03-20T10:20:02+09:00</updated><id>http://localhost:4000/paper/post-surveyNLP</id><content type="html" xml:base="http://localhost:4000/paper/post-surveyNLP/"><![CDATA[<p><img src="../../../image/paper.png" alt="paper.png" /></p>

<p><br /><br /><br /><br /></p>

<h1 id="a-survey-of-the-usages-of-deep-learning-for-natural-language-processing">A Survey of the Usages of Deep Learning for Natural Language Processing</h1>

<p><br /><br /><br /><br /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>💡 2018년

1. Introduction
2. Fundamentals of Deep Learning and NLP
2.1 Deep Learning
2.2 Natural Language Processing
3. Deep Learning Architectures for NLP
3.1 Convolutional Neural Networks
3.2 Recurrent Neural Networks
3.3 Transformers
4. Use Cases of Deep Learning for NLP
4.1 Language Modeling
4.2 Sentiment Analysis
4.3 Text Classification
4.4 Machine Translation
4.5 Question Answering
5. Challenges and Future Directions
5.1 Challenges
5.2 Future Directions
6. Conclusion
7. References

</code></pre></div></div>

<ul>
  <li>1장
    <ul>
      <li>딥러닝에 대한 간략한 소개와 딥 러닝 아키텍처 및 방법에 대한 간략한 개요를 제공 (딥 러닝, 신경망, 자연어 처리, 컴퓨터 언어학, 기계 학습)</li>
      <li></li>
    </ul>
  </li>
  <li>
    <p>2장</p>

    <p># 2장</p>

    <ul>
      <li>딥 러닝 및 자연어 처리(NLP)의 기본 개념을 소개합니다. 이 장은 인공 신경망, 역전파 및 활성화 기능과 같은 딥 러닝 개념에 대한 개요로 시작</li>
      <li>이러한 개념을 텍스트 분류 및 감정 분석과 같은 NLP 작업에 어떻게 적용할 수 있는지 설명</li>
      <li>토큰화, 형태소 분석 및 불용어 제거와 같은 데이터 전처리 기술을 포함하여 NLP의 기본 사항을 다룹니다. 저자는 이러한 기술을 사용하여 텍스트 데이터를 딥 러닝 모델에 공급하기 전에 정리하고 사전 처리하는 방법을 설명</li>
      <li>데이터 전처리, 기능 추출 및 모델 훈련과 같은 NLP를 위한 일반적인 딥 러닝 파이프라인의 다양한 구성 요소를 설명</li>
      <li>저자는 컨볼루션 신경망(CNN) 및 순환 신경망(RNN)과 같은 NLP에 사용되는 일반적인 딥 러닝 아키텍처의 예를 제공</li>
      <li>
        <p>이 장에서는 주석이 달린 대량의 데이터가 필요하고 결과 모델을 해석하는 어려움과 같이 NLP에 딥러닝을 사용하는 것과 관련된 문제에 대해 논의하면서 결론을 내립</p>
      </li>
      <li>자연어 처리 분야는 컴퓨터 언어학이라고도 하며, 인간 언어를 이해하는 데 있어 실질적인 문제를 해결하기 위한 계산 모델과 프로세스의 엔지니어링을 포함한다</li>
      <li>핵심 영역은 자연적으로 발생하는 단어 간의 정량화 연관성을 강조하는 언어 모델링, 단어의 의미 있는 구성 요소의 분할 및 사용된 단어의 실제 발화 부분을 식별하는 형태학적 처리와 같은 근본적인 문제를 다룬다</li>
      <li>Currently, NLP is primarily a data-driven field using sta- tistical and probabilistic computations along with machine learning.</li>
      <li></li>
    </ul>
  </li>
  <li>3장</li>
  <li>4장</li>
  <li>5장 V. APPLICATIONS OF NATURAL LANGUAGE PROCESSING USING DEEP LEARNING
    <ul>
      <li><em>Information Retrieval</em>
        <ul>
          <li>기존 정보 검색 시스템을 ..</li>
          <li>맥아베니 외. [171] 사전 훈련된 두 가지 상황별 언어 모델인 ELMo [70]와 BERT [71]에서 쿼리 용어 표현을 추출하고, 표현을 사용하여 애드혹 문서 순위를 위해 기존의 3개의 경쟁 신경 순위 아키텍처를 보강했다. 그 중 하나는 DRMM [169]이다. 그들은 또한 BERT의 분류 벡터를 이러한 아키텍처와 결합하여 두 가지 접근법의 이점을 얻는 공동 모델을 제시했다. MacAveney의 CEDR(문서 랭킹을 위한 컨텍스트 임베딩)이라는 시스템은 이전 모델 세 가지 모두의 성능을 향상시켰고, BERT의 토큰 표현을 사용하여 최첨단 결과를 생성했습니다</li>
        </ul>
      </li>
      <li>Sentiment analysis
        <ul>
          <li></li>
        </ul>
      </li>
      <li>Machine translation</li>
      <li>Text classification</li>
      <li>Question answering</li>
      <li>Named entity recognition</li>
      <li>Summarization</li>
      <li>Conversational agents</li>
      <li>Text generation</li>
    </ul>
  </li>
  <li>V. CONCLUSIONS
    <ul>
      <li>자연어 처리(NLP)를 위한 딥 러닝 사용에 대한 개요를 제공하고 이 분야의 최근 진행 상황을 강조합니다. 딥 러닝 기술은 감정 분석, 기계 번역, 텍스트 분류 및 질문 답변과 같은 NLP 작업에서 큰 성공을 거두었습니다. 그러나 딥 러닝 모델의 해석 가능성 부족과 많은 양의 데이터 및 계산 리소스가 필요하다는 문제가 남아 있습니다. 이 논문은 복잡한 모델을 위한 고도로 전문화된 구성 요소를 개발하는 것보다 사전 교육 방법론에 더 많은 연구 노력을 기울여야 한다고 제안합니다. 또한 이 백서는 향후 작업이 보다 다양한 언어와 분석되지 않은 언어를 사용하는 NLP 모델의 유효성 검사로 향할 것을 권장합니다. 딥 러닝 모델은 데이터가 매우 부족하지만 사전 훈련 및 전이 학습이 매우 영향력 있는 역할을 수행하면서 컴퓨터 언어학의 표준이 될 것으로 예상됩니다. 마지막으로, 이 논문은 뉴로모픽 칩과 같은 계산 장비의 발전이 NLP의 지속적인 발전에 도움이 될 것이라고 제안합니다.</li>
      <li>매우 최근에는 인코더 및 종종 디코더로서 주의력을 동력으로 하는 <code class="language-plaintext highlighter-rouge">트랜스포머</code> 유닛의 스택이 NLP 필드의 풍부하고 다양한 지형에서 일관되게 우수한 결과를 생성했다.</li>
      <li>이 최종 관찰 이후, 복잡한 모델에서 마지막 성능 드롭을 짜내기 위해 고도로 전문화된 구성 요소를 개발하는 것보다 <code class="language-plaintext highlighter-rouge">사전 훈련 방법론에 더 많은 연구 노력을 기울이는 것이 유용</code>할 수 있다.</li>
      <li><strong><em>인간의 언어 능력이 우리의 감성의 한 부분에 불과하듯이, 언어 처리도 인공지능의 작은 한 부분에 불과하다.</em></strong> 이러한 구성 요소가 어떻게 상호 연관되어 있는지 이해하는 것은 보다 완벽한 AI 시스템을 구성하는 데 중요하며, 통합된 NLP 아키텍처를 만드는 것은 이러한 시스템을 현실화하기 위한 또 다른 단계이다.</li>
      <li>그러나 딥 러닝 모델의 해석 가능성 부족과 많은 양의 데이터 및 계산 리소스가 필요하다는 문제가 남아 있습니다.</li>
      <li>GPU 의 발전</li>
    </ul>
  </li>
</ul>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="paper" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">전이학습</title><link href="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/" rel="alternate" type="text/html" title="전이학습" /><published>2023-03-18T00:00:00+09:00</published><updated>2023-03-18T23:09:02+09:00</updated><id>http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5</id><content type="html" xml:base="http://localhost:4000/aitech_knowledge/post-%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="전이학습">전이학습</h1>

<p>위키백과에 의하면 전이학습은 <code class="language-plaintext highlighter-rouge">한 분야의 문제를 해결하기 위해서 얻은 지식과 정보를 다른 문제를 푸는데 사용하는 방식</code>을 말합니다.</p>

<p>전이 학습은 하나의 작업에 대해 훈련된 모델을 사용하여 다른 관련 작업의 성능을 향상시킬 수 있는 기계 학습 기술입니다. 전이 학습에서는 처음부터 시작하는 대신 사전 훈련된 모델을 새로운 작업의 시작점으로 사용합니다. 사전 훈련된 모델은 이미 대규모 데이터 세트에서 일반적인 기능을 학습했으며 이 지식을 새로운 작업으로 이전하여 정확도를 높이고 훈련에 필요한 데이터 양을 줄일 수 있습니다. 전이 학습은 모델이 사전 훈련 단계에서 더 큰 데이터 세트에서 얻은 지식을 활용할 수 있도록 하므로 새 작업에 사용 가능한 데이터가 제한적일 때 특히 유용합니다. 전이 학습은 자연어 처리, 컴퓨터 비전 및 기타 기계 학습 영역에서 널리 사용됩니다.</p>

<blockquote>
  <p>앤드류 응 曰 “지도학습 이후로 전이학습이 머신러닝에서 대세가 될 것이다.”</p>
</blockquote>

<p>전이학습은 사실 우리 인간들이 사용하는 학습법 중 하나입니다. 우리는 과거에 이런저런 문제들을 해결하면서 축적된 경험을 토대로 그것과 유사한 문제를 해결하지 않나요? 이것이 바로 전이학습의 본질입니다. <a href="https://bskyvision.com/entry/%EC%A0%84%EC%9D%B4%ED%95%99%EC%8A%B5transfer-learning-%EC%9E%AC%EB%B0%8C%EA%B3%A0-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0">[출처]</a></p>

<p>특히나 기계의 시각적 이해를 목표로 하는 컴퓨터 비전의 영역에서 전이 학습으로 수행된 모델들이 높은 성능을 보이고 있어 가장 많이 사용되는 방법 중에 하나입니다.</p>

<p>아래 캐글 노트북을 추천합니다. <code class="language-plaintext highlighter-rouge">Advanced Transfer Learning Starter Notebook</code> <a href="https://www.kaggle.com/code/aakashns/advanced-transfer-learning-starter-notebook/notebook">[링크]</a></p>

<h2 id="source-tasks에서-학습된-지식을-target-task-을-로-이전">“Source Tasks”에서 학습된 지식을 “Target Task” 을 로 이전</h2>

<h2 id="fine-tuning">“Fine-Tuning”</h2>

<h2 id="가중치-초기화-weight-initialization">가중치 초기화 (Weight Initialization)</h2>
<p><a href="https://reniew.github.io/13/">[출처]</a></p>

<p>가중치를 잘못 설정할 경우 기울기 소실 문제나 표현력의 한계를 갖는 등 여러 문제를 야기하게 된다. 또한 딥러닝의 학습의 문제가 non-convex 이기 때문에 초기값을 잘못 설정할 경우 local minimum에 수렴할 가능성이 커지게 됨.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1) 초기값을 모두 0으로 설정
-&gt; 문제 가 있음
2) LeCun Initialization
3) Xavier Initialization
4) He Initialization
</code></pre></div></div>

<h1 id="ray">Ray</h1>
<p>Ray는 Distributed application을 만들기 위한 프레임워크로, 분산 컴퓨팅 환경에서 많이 사용합니다.</p>

<p>Ray를 사용한 전이 학습은 Ray 분산 컴퓨팅 프레임워크를 사용하여 전이 학습을 대규모 데이터 세트로 확장하는 기계 학습 기술입니다. Ray는 분산 애플리케이션 구축을 위한 인기 있는 오픈 소스 프레임워크이며 확장 가능한 기계 학습 파이프라인 구축을 위한 라이브러리 및 도구 세트를 제공합니다.</p>

<p>Ray를 사용한 전이 학습을 사용하면 사전 훈련된 모델이 클러스터의 여러 노드에 분산되고 분산 방식으로 새 데이터에 대해 모델을 미세 조정할 수 있습니다. 이를 통해 대규모 데이터 세트로 작업할 때 학습 시간이 단축되고 확장성이 향상됩니다.</p>

<p>Ray는 또한 하이퍼파라미터 튜닝을 위한 Ray Tune 및 분산 확률적 경사 하강을 위한 Ray SGD와 같은 전이 학습 작업을 위한 라이브러리 및 도구 세트를 제공합니다. 이러한 도구는 전이 학습 프로세스를 간소화하고 확장 가능한 고성능 기계 학습 모델을 보다 쉽게 ​​구축할 수 있도록 도와줍니다.</p>

<p>전반적으로 Ray를 사용한 전이 학습은 전이 학습을 대규모 데이터 세트로 확장하고 확장 가능한 기계 학습 파이프라인을 구축하기 위한 강력한 기술입니다. Ray는 분산 컴퓨팅의 성능을 활용하여 전이 학습 모델의 속도, 효율성 및 정확도를 개선하는 데 도움을 줄 수 있습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_knowledge" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">[백준][14916] 거스름돈</title><link href="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90/" rel="alternate" type="text/html" title="[백준][14916] 거스름돈" /><published>2023-03-18T00:00:00+09:00</published><updated>2023-03-19T06:20:02+09:00</updated><id>http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90</id><content type="html" xml:base="http://localhost:4000/ps/post-%EB%B0%B1%EC%A4%8013164%ED%96%89%EB%B3%B5%EC%9C%A0%EC%B9%98%EC%9B%90/"><![CDATA[<p><img src="../../../image/ps.png" alt="paper.png" /></p>

<h1 id="해결-전략">해결 전략</h1>

<p>그리디 알고리즘으로 풉니다. 앞 사람과의 키차이를 <code class="language-plaintext highlighter-rouge">gabs</code>
라는 리스트에 저장해줍니다. 문제에서 요구하는 것은 최소 비용으로 M 개의 그룹을 만드는 것을 요구합니다. gab 리스트에서 특정 하나를 제거한다는 것은 그 구간을 통합한다는 개념이고 그룹 수를 하나 줄인다는 것입니다. (N-1 개의 갭이 있는 <code class="language-plaintext highlighter-rouge">gabs</code>는 M개의 그룹이 최초로 세팅되어 있다고 이해하면 됩니다.)</p>

<p>이런 아이디어로부터 <code class="language-plaintext highlighter-rouge">gabs</code> 리스트를 내림차순으로 정렬하고  M-1 부터 저장해주게 되면 최솟 값을 구할 수 있습니다.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import sys

input = sys.stdin.readline

N, M = map(int, input().split())
numbers = list(map(int, input().split()))

gabs = []

for i in range(1, len(numbers)):
    gabs.append(numbers[i]-numbers[i-1])

gabs.sort(reverse=True)

print(sum(gabs[M-1:]))
</code></pre></div></div>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="ps" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day10</title><link href="http://localhost:4000/aitech_daily/post-day10/" rel="alternate" type="text/html" title="ai tech -Day10" /><published>2023-03-17T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day10</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day10/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day09</title><link href="http://localhost:4000/aitech_daily/post-day09/" rel="alternate" type="text/html" title="ai tech -Day09" /><published>2023-03-16T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day09</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day09/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day08</title><link href="http://localhost:4000/aitech_daily/post-day08/" rel="alternate" type="text/html" title="ai tech -Day08" /><published>2023-03-15T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day08</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day08/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>과제1, 과제 2을 풀었습니다. 강의와 <code class="language-plaintext highlighter-rouge">딥러닝 파이토치 교과서</code> 라는 책을 병행하면서 과제를 풀고 있습니다. 팀원들과 그리디 알고리즘 2 문제를 풀었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech -Day07</title><link href="http://localhost:4000/aitech_daily/post-day07/" rel="alternate" type="text/html" title="ai tech -Day07" /><published>2023-03-14T00:00:00+09:00</published><updated>2023-03-08T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day07</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day07/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>파이토치 autograd, dataset, dataLoader 에 대해 공부했습니다. 구글링을 하지 않고 과제를 풀었습니다. 파이토치 공식 문서를 하루 종일 보면서 몇 문제를 남겨놓고 어찌어찌 풀긴 풀었습니다. 기분이 좋기도 하지만 그 과정이 너무 힘들었습니다. 지문이 상당히 많은데 복습하는데 시간을 써야 겠습니다. DataLoader 부분을 현재 풀고 있는데 좌절감이 듭니다. 하나부터 열까지 머리를 지끈지끈하게 합니다. 이런 노력의 결과가 피와 살이 될꺼라는 것을 알고 있지만 고통스럽네요.</p>

<p>오후 피어세션 동안은 팀원들과 [이것이 코딩 테스트다] 책의 <code class="language-plaintext highlighter-rouge">그리디 알고리즘</code> 을 풀었습니다. PR 방식으로 서로 코멘트를 남겨주는 방식으로 진행했는데요. 상당히 깔끔했습니다. 다들 열심히 풀었고 리뷰도 잘 해줘서 이대로 쭉 진행하면 큰 성장이 있을 것 같습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>
<p>결국 기본이 탄탄해야 합니다. 파이토치를 잘 할 수 있다는 것은 파이썬을 잘 다룬다는 것이고 수학적 지식이 탄단하다는 것입니다. 다음 딥러닝 구현 공부에 들어갈 때는 단단한 파이토치 실력이 있어야 겠지요. 실력은 하루 아침에 생기는 것이 아닙니다. 바닥 부터 천천히 쌓아나갈 때 <code class="language-plaintext highlighter-rouge">비로소 내가 해냈구나</code> 라는 감정이 들겠지요.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>
<p>꾸준함입니다. 결국 지금의 어려운 과제들도 시간을 들이면 풀 수 있다고 생각합니다. 활용 하기 위해선, 딥러닝을 내가 구축하기 위해선 이런 classic 한 것들을 잘 다룰 수 있어야 합니다.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>
<p>파이토치 강좌에 너무 연연하지 말고 순수 공부 시간을 늘려야 겠습니다. 좋은 강의 이지만 강의에 집중하다가는 지식을 제대로 못 쌓을 확률이 높습니다. 펜을 들고 공부해야 겠습니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>다시 드는 생각입니다. 체력 관리가 중요합니다. 오늘 따라 굉장히 피곤했습니다. 잘 쉬고 잘 공부해야 겠습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">ai tech - Day06</title><link href="http://localhost:4000/aitech_daily/post-day06/" rel="alternate" type="text/html" title="ai tech - Day06" /><published>2023-03-13T00:00:00+09:00</published><updated>2023-03-14T06:20:02+09:00</updated><id>http://localhost:4000/aitech_daily/post-day06</id><content type="html" xml:base="http://localhost:4000/aitech_daily/post-day06/"><![CDATA[<p><img src="../../../image/aitech.png" alt="image" /></p>

<h1 id="5f">5F</h1>
<h2 id="그날의-사실-facts-">그날의 사실 (Facts) :</h2>
<p>파이토치 수업을 시작했습니다. 본격적인 딥러닝 구현을 들어가서 설렜습니다. 월요일 9시가 되고 과제를 열어보니 난이도가 꽤 있어서 걱정이 조금 되었습니다. 수요일 까지 최대한 빨리 끝내놓고 한 주의 마무리를 잘 해야 겠다는 다짐을 했습니다.</p>

<p>팀원들과 코딩테스트 스터디를 시작했습니다. [이것이 취업을 위한 코딩테스트다.] 라는 책으로 시작하게 되었는데요. 그리디 알고리즘 개념 공부와 함께 있는 3 문제를 같이 풀었습니다.</p>

<h2 id="느낌-feeling-">느낌 (Feeling) :</h2>
<p>강제로 코드를 치다 보니 손에 익는 것은 분명 있습니다. 파이토치 공부를 하면서 매번 눈으로만 배우는 습관을 가지고 있었는데 이번에는 마음을 다잡고 하나 하나 쳐가면서 공부를 하고 있습니다. 코드는 역시 쳐서 돌려봐야 내것이 되나 봅니다.</p>

<h2 id="배운점-findings-">배운점 (Findings) :</h2>
<p>pytoch를 사용하는 이유, 기초 사용법, Documentation 읽는 법 등을 배웠습니다.</p>

<h2 id="미래의-행동계획-future-">미래의 행동계획 (Future) :</h2>
<p>코딩테스트 문제는 하루에 2 문제 씩 계속 풀려고 합니다.</p>

<h2 id="피드백-feedback-">피드백 (Feedback) :</h2>
<p>휴식 시간을 잘 가져야겠습니다. 그리고 식사는 저녁까지 계속 굶다가 저녁에 한 끼만 먹는 것이 좋겠습니다.</p>]]></content><author><name>최윤진</name><email>yunjinchoidev@gmail.com</email></author><category term="aitech_daily" /><summary type="html"><![CDATA[]]></summary></entry></feed>