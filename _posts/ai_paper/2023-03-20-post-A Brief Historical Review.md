---
title: "[논문리뷰] Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)"
last_modified_at: 2023-03-20T12:20:02-05:00
categories:
    - ai_paper
tages:
    - aitech
    - nlp
toc: true
toc_sticky: true
toc_label: "목차"
---

![paper.png](../../../image/paper.png)


<br><br><br><br>


# Deep Learning’s Most Important Ideas - A Brief Historical Review(2020)
<br><br><br><br>



## 2012 – AlexNet

AlexNet은 2012년 Alex Krizhevsky, Ilya Sutskever 및 Geoffrey Hinton이 개발한 심층 컨볼루션 신경망(CNN`) 아키텍처다. 오류율은 15.3%로 두 번째로 좋은 모델보다 훨씬 뛰어나다.`

`AlexNet은 8개의 계층으로 구성되어 있다. 5개의 컨볼루션 계층과 3개의 완전 연결 계층이 있습니다. 이 네트워크는 ReLU(Rectified Linear Unit) 활성화 함수를 사용하여 시그모이드 또는 tanh와 같은 기존 활성화 함수에 비해 더 빠르게 훈련할 수 있습니다. 또한 AlexNet은 최대 풀링 계층, 로컬 응답 정규화(LRN) 및 드롭아웃 정규화를 사용하여 과적합을 방지합니다.`

`AlexNet의 성공은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 광범위한 컴퓨터 비전 작업을 위한 딥 러닝, 특히 CNN에 대한 관심의 물결을 촉발시켰습니다. 오늘날 AlexNet은 VGG, ResNet 및 Inception과 같은 고급 아키텍처를 위한 길을 닦은 기본 모델로 간주됩니다.`

## 2013 – DQN

DQN(Deep Q-Network)은 2013년 `DeepMind` 연구원들이 개발한 강화 학습 알고리즘입니다. 인기 있는 무모델 강화 학습 방법인 Q-러닝과 심층 신경망을 결합하여 원시에서 직접 학습할 수 있는 강력한 알고리즘을 만듭니다. 복잡한 환경의 픽셀 데이터. DQN은 여러 게임에서 인간 수준의 성능을 달성한 Atari 2600 게임에서 처음 시연되었습니다.

`DQN의 주요 혁신은 주어진 상태에서 행동을 취하는 데 대한 예상되는 미래 보상을 예측하는 행동-가치 함수 또는 Q-함수를 추정하기 위한 함수 근사값으로 심층 신경망을 사용하는 것`입니다. DQN은 두 가지 주요 기술을 도입하여 강화 학습을 위한 심층 신경망 훈련에서 종종 발생하는 불안정성과 발산 문제를 해결합니다.

1. `경험 재생:` 순차적 경험에서 학습하는 대신 DQN은 경험(상태, 작업, 보상 및 다음 상태)을 재생 버퍼에 저장하고 훈련 중에 이 버퍼에서 임의의 미니 배치를 샘플링합니다. 이것은 연속 경험 간의 상관 관계를 깨고 보다 안정적인 학습으로 이어집니다.
2. `대상 네트워크:` DQN은 메인 네트워크의 가중치로 주기적으로 업데이트되는 별도의 대상 네트워크를 사용합니다. 이렇게 하면 지속적으로 변화하는 목표 값으로 인해 발생하는 진동 및 발산 가능성을 줄여 학습 프로세스를 안정화하는 데 도움이 됩니다.

DQN은 Double DQN, Dueling DQN 및 Prioritized Experience Replay와 같은 많은 확장 및 개선 사항에 영감을 주어 심층 강화 학습 분야에서 영향력 있는 알고리즘이었습니다.

알파고를 만든 알고리즘 입니다.

## 2014 – Encoder/Decoder, Adam

인코더/디코더:

`인코더-디코더 아키텍처는 특히 기계 번역, 텍스트 요약 및 이미지 캡션과 같은 시퀀스 간(seq2seq) 작업을 위한 딥 러닝에서 널리 사용되는 프레임워크`입니다. 아키텍처는 두 가지 주요 구성 요소로 구성됩니다.

1. `인코더`: `인코더는 입력 시퀀스를 처리하고 이를 고정 크기 컨텍스트 벡터 또는 잠재 표현으로 압축하는 신경망(일반적으로 RNN 또는 LSTM)입니다.` `이 벡터는 디코딩 프로세스에 필요한 입력 시퀀스에서 필수 정보를 캡처`합니다.
2. `디코더`: 디코더는 인코더에서 `생성된 컨텍스트 벡터를 가져와 단계적으로 출력 시퀀스를 생성하는 또 다른 신경망(일반적으로 RNN 또는 LSTM)입니다.` 컨텍스트 벡터와 이전 예측을 기반으로 출력 시퀀스의 `다음 요소를 예측합니다.`

인코더-디코더 아키텍처는 디코더가 디코딩 프로세스 중에 입력 시퀀스의 특정 부분에 집중할 수 있게 하여 긴 시퀀스에서 성능을 향상시키는 어텐션 메커니즘과 결합되는 경우가 많습니다.

Adam(적응 모멘트 추정):

Adam은 2014년에 Diederik Kingma와 Jimmy Ba가 소개한 신경망의 기울기 기반 최적화를 위한 최적화 알고리즘입니다. 이것은 확률적 기울기 하강(SGD) 방법의 확장이며 각 매개변수에 대한 학습 속도를 개별적으로 조정하도록 설계되었습니다. `Adam은 그래디언트의 1차 모멘트(평균)와 2차 모멘트(비중심 분산)를 모두 계산하여 두 가지 인기 있는 적응형 학습 속도 기술인 AdaGrad 및 RMSProp의 이점을 결합`합니다.

Adam의 주요 기능은 다음과 같습니다.

1. `적응형 학습 속도`: Adam은 기울기의 첫 번째 및 두 번째 모멘트를 기반으로 각 매개변수에 대한 학습 속도를 조정하여 표준 SGD에 비해 더 빠른 수렴 및 개선된 일반화로 이어질 수 있습니다.
2. `모멘텀`: Adam은 기울기의 지수 이동 평균을 사용하여 모멘텀을 통합하여 수렴을 가속화하고 최적화 환경에서 로컬 최소값 또는 안장 지점을 극복하는 데 도움이 될 수 있습니다.
3. `편향 보정`: Adam은 모멘트가 0으로 편향될 수 있는 훈련 시작 시 첫 번째 및 두 번째 모멘트의 정확한 추정을 보장하기 위해 편향 수정 항을 포함합니다.

Adam은 구현 용이성, 빠른 수렴, 다양한 신경망 아키텍처 및 문제에 대한 견고성으로 인해 딥 러닝에서 널리 사용되는 최적화 알고리즘이 되었습니다.

Adam 이 그냥 잘 나온다. (경험적)

## 2015 – GAN, ResNet

GAN(생성적 적대 신경망):

GAN은 2014년 `이안 굿펠로우(Ian Goodfellow)`와 그의 동료들이 소개한 생성 모델입니다. 두 개의 신경망인 생성기와 판별기로 구성되며 경쟁 환경에서 동시에 훈련됩니다. Generator는 합성 데이터 샘플을 생성하고 Discriminator는 실제 샘플과 생성된 샘플을 구별하는 방법을 학습합니다. 교육 과정은 현실적인 샘플을 생성하는 생성기의 능력과 `진짜와 가짜 샘플을 정확하게 식별하는 판별기의 능력을 향상시키는 것을 목표로` 합니다. `훈련이 진행됨에 따라 생성기는 점점 더 사실적인 샘플을 생성하는 능력이 향상되어 판별자가 실제 데이터와 가짜 데이터를 구별하기가 더 어려워집니다. GAN은 이미지 합성, 스타일 전송, 데이터 확장 및 도메인 적응을 포함한 다양한 응용 분야에서 널리 사용`되었습니다.

ResNet(잔차 네트워크):

ResNet은 2015년 Kaiming He와 그의 동료들이 소개한 심층 합성곱 신경망(CNN) 아키텍처입니다. 심층 신경망의 훈련을 방해하는 `기울기 소멸 문제를 해결하도록 설계`되었습니다. ResNet은 그라디언트가 네트워크를 통해 보다 효과적으로 흐를 수 있도록 `건너뛰기 연결 또는 바로가기 연결을 도입`했습니다. `이러한 연결은 블록의 입력과 출력 사이의 잔차 함수를 학습하는 잔차 블록을 생성합니다`. 이 아키텍처는 정확도를 유지하고 기울기 소실 문제를 완화하면서 `훨씬 더 깊은 네트워크(원본 논문에서 최대 152개 계층)의 교육을 가능하게 합니다`. `ResNet은 이미지 분류, 객체 감지 및 의미론적 분할과 같은 다양한 컴퓨터 비전 작업에서 최첨단 결과를 달성했으며 딥 러닝 아키텍처의 수많은 변형 및 개선에 영감을 주었습니다.`

## 2016 –

## 2017 – Transformer

`Attention is All you need`

Transformer는 Vaswani 등이 도입한 신경망 아키텍처입니다. 2017년에 기계 번역과 같은 시퀀스 간 작업을 위해 설계되었습니다. 자가 주의 메커니즘을 사용하여 순환 신경망(RNN)의 한계를 극복하여 더 효율적인 병렬화와 장거리 종속성을 더 잘 처리할 수 있습니다. `트랜스포머는 인코더와 디코더로 구성되어 있으며 각각 여러 레이어의 자체 주의 및 피드포워드 하위 레이어가 있어 모델이 입력 및 출력 시퀀스의 요소 간의 복잡한 관계를 학습`할 수 있습니다.

> Attention 구조를 이해하는 게 정말 중요하다.
> 

## 2018 – Bert

BERT (Bidirectional Encoder Representations from Transformers):

BERT는 2018년 Google에서 도입한 사전 학습된 Transformer 기반 언어 모델입니다. `양방향 컨텍스트를 사용`하여 레이블이 지정되지 않은 텍스트 데이터에서 풍부한 언어 표현을 학습함으로써 자연어 처리(NLP)에 혁명을 일으켰습니다. `BERT는 마스킹된 언어 모델링 및 다음 문장 예측 작업을 사용하여 대규모 비지도 데이터에 대해 사전 훈련`됩니다. 감정 분석 또는 명명된 엔터티 인식과 같은 특정 다운스트림 작업에서 `BERT를 미세 조정하면 상대적으로 최소한의 추가 교육으로 최첨단 성능`을 얻을 수 있습니다.

> Find Tuning 의 시초
> 

## 2019 – Big Language Models(GPT-X)

GPT(Generative Pre-trained Transformer):
GPT는 OpenAI에서 개발한 일련의 Transformer 기반 언어 모델이며, GPT-3는 2021년 9월 제 지식 컷오프 당시 가장 강력한 최신 버전입니다. `GPT는 다음 단어를 예측하는 단방향 자동 회귀 접근 방식을 사용하여 훈련`됩니다. `이전 단어를 기반으로 순서대로. 방대한 양의 텍스트 데이터에 대해 사전 훈련된 GPT`는 `강력한 일반화 기능`을 나타내`며 텍스트 생성, 요약, 번역 및 질문 답변과 같은 다양한 NLP 작업에 대해 미세 조정할 수 있`습니다.

## 2020 – Self-Supervised Learning

Self-Supervised Learning 자기 지도 학습:
`자기 지도 학습은 모델이 명시적으로 레이블이 지정된 데이터를 사용하지 않고 데이터 자체에서 유용한 표현이나 기능을 학습하는 일종의 비지도 학습`입니다. 대신 문장에서 누락된 단어를 예측(마스킹된 언어 모델링)하거나 두 문장의 상대적 위치를 예측(다음 문장 예측)하는 등 데이터에서 감독 신호를 생성하도록 설계된 작업인 `프리텍스트 작업을 사용`합니다. 자기 지도 학습은 BERT 및 GPT와 같은 모델이 레이블이 지정되지 않은 방대한 양의 데이터에서 풍부하고 전송 가능한 표현을 학습할 수 있도록 하므로 딥 러닝, 특히 NLP에서 점점 인기를 얻고 있습니다.